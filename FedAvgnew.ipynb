{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPG8s1NvmRlZ+mzrjPGrpWw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahad31/Kl-FedDis-Research-/blob/main/FedAvgnew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "Zp7jsGg4vLOY",
        "outputId": "29df2f64-5674-4a88-e19e-390b9263232e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bbc3d0b71ba5>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Load CIFAR-10 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCIFAR10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latin1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"labels\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# CNN Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
        "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Data loading and transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Splitting data for 5 clients\n",
        "def split_data(trainset, num_clients):\n",
        "    client_len = len(trainset) // num_clients\n",
        "    client_datasets = random_split(trainset, [client_len] * num_clients)\n",
        "    return client_datasets\n",
        "\n",
        "# Initialize clients\n",
        "def initialize_clients(trainset, num_clients, batch_size=128):\n",
        "    client_datasets = split_data(trainset, num_clients)\n",
        "    client_loaders = [DataLoader(client_data, batch_size=batch_size, shuffle=True) for client_data in client_datasets]\n",
        "    return client_loaders\n",
        "\n",
        "# FedAvg algorithm: Average the weights from all clients\n",
        "def fed_avg(global_model, client_models):\n",
        "    global_dict = global_model.state_dict()\n",
        "    for key in global_dict.keys():\n",
        "        global_dict[key] = torch.stack([client_models[i].state_dict()[key].float() for i in range(len(client_models))], 0).mean(0)\n",
        "    global_model.load_state_dict(global_dict)\n",
        "    return global_model\n",
        "\n",
        "# Training loop for a client\n",
        "def train_client(model, trainloader, epochs=1, lr=0.01):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(trainloader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, testloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    print(f'Test Accuracy: {acc * 100:.2f}%')\n",
        "    return acc\n",
        "\n",
        "# Federated Learning with 5 clients, using FedAvg\n",
        "def federated_learning(trainset, testset, num_clients=5, global_epochs=500, client_epochs=5):\n",
        "    # Initialize global model and clients\n",
        "    global_model = CNN()\n",
        "    client_loaders = initialize_clients(trainset, num_clients)\n",
        "    testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "    # Training loop for federated learning\n",
        "    for global_epoch in range(global_epochs):\n",
        "        print(f\"Global Epoch {global_epoch + 1}/{global_epochs}\")\n",
        "\n",
        "        client_models = []\n",
        "        for client_idx, client_loader in enumerate(client_loaders):\n",
        "            client_model = CNN()\n",
        "            client_model.load_state_dict(global_model.state_dict())  # Load the global model into the client\n",
        "            print(f\"Training on Client {client_idx + 1}\")\n",
        "            client_model = train_client(client_model, client_loader, epochs=client_epochs)\n",
        "            client_models.append(client_model)\n",
        "\n",
        "        # Average the weights of client models to update the global model\n",
        "        global_model = fed_avg(global_model, client_models)\n",
        "\n",
        "        # Evaluate global model after each global epoch\n",
        "        evaluate(global_model, testloader)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return global_model\n",
        "\n",
        "# Run the federated learning process\n",
        "if __name__ == \"__main__\":\n",
        "    global_model = federated_learning(trainset, testset, num_clients=5, global_epochs=500, client_epochs=5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision scikit-learn\n",
        "python script_name.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "WBHM3YuRwrQP",
        "outputId": "b7c24593-1811-4e66-b76c-25475a152570"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-3-f44f316228c2>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-f44f316228c2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install torch torchvision scikit-learn\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# CNN Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.ReLU()(self.conv1(x)))\n",
        "        x = self.pool(nn.ReLU()(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = nn.ReLU()(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Data loading and transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split data for 5 clients, 80% training, 20% validation\n",
        "def split_data(trainset, num_clients, val_ratio=0.2):\n",
        "    client_len = len(trainset) // num_clients\n",
        "    client_datasets = []\n",
        "    for _ in range(num_clients):\n",
        "        client_data, val_data = random_split(trainset, [int(client_len * (1 - val_ratio)), int(client_len * val_ratio)])\n",
        "        client_datasets.append((client_data, val_data))\n",
        "    return client_datasets\n",
        "\n",
        "# Initialize clients with validation data\n",
        "def initialize_clients(trainset, num_clients, batch_size=128):\n",
        "    client_datasets = split_data(trainset, num_clients)\n",
        "    client_loaders = [(DataLoader(client_data, batch_size=batch_size, shuffle=True),\n",
        "                       DataLoader(val_data, batch_size=batch_size, shuffle=False)) for client_data, val_data in client_datasets]\n",
        "    return client_loaders\n",
        "\n",
        "# FedAvg algorithm: Average the weights from all clients\n",
        "def fed_avg(global_model, client_models):\n",
        "    global_dict = global_model.state_dict()\n",
        "    for key in global_dict.keys():\n",
        "        global_dict[key] = torch.stack([client_models[i].state_dict()[key].float() for i in range(len(client_models))], 0).mean(0)\n",
        "    global_model.load_state_dict(global_dict)\n",
        "    return global_model\n",
        "\n",
        "# Training loop for a client\n",
        "def train_client(model, trainloader, epochs=1, lr=0.01):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Validation accuracy function\n",
        "def validate_client(model, valloader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in valloader:\n",
        "            images, labels = data\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    return acc\n",
        "\n",
        "# Federated Learning with FedAvg\n",
        "def federated_learning(trainset, testset, num_clients=5, global_epochs=500, client_epochs=5):\n",
        "    # Initialize global model and clients\n",
        "    global_model = CNN()\n",
        "    client_loaders = initialize_clients(trainset, num_clients)\n",
        "    testloader = DataLoader(testset, batch_size=128, shuffle=False)\n",
        "\n",
        "    # Training loop for federated learning\n",
        "    for global_epoch in range(global_epochs):\n",
        "        print(f\"\\nGlobal Epoch {global_epoch + 1}/{global_epochs}\")\n",
        "\n",
        "        client_models = []\n",
        "        for client_idx, (trainloader, valloader) in enumerate(client_loaders):\n",
        "            client_model = CNN()\n",
        "            client_model.load_state_dict(global_model.state_dict())  # Load the global model into the client\n",
        "            print(f\"\\nTraining on Client {client_idx + 1}\")\n",
        "\n",
        "            # Train client model\n",
        "            client_model = train_client(client_model, trainloader, epochs=client_epochs)\n",
        "\n",
        "            # Validate client model\n",
        "            val_acc = validate_client(client_model, valloader)\n",
        "\n",
        "            # Print validation accuracy for Client 5 at round 10 and epoch 10\n",
        "            if client_idx == 4 and global_epoch + 1 == 10 and client_epochs == 10:\n",
        "                print(f\"\\nValidation Accuracy for Client 5 at Round 10, Epoch 10: {val_acc * 100:.2f}%\")\n",
        "\n",
        "            client_models.append(client_model)\n",
        "\n",
        "        # Average the weights of client models to update the global model\n",
        "        global_model = fed_avg(global_model, client_models)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return global_model\n",
        "\n",
        "# Run the federated learning process\n",
        "if __name__ == \"__main__\":\n",
        "    global_model = federated_learning(trainset, testset, num_clients=5, global_epochs=500, client_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9MkcmmVSwvz2",
        "outputId": "10ee68d2-3d48-4524-919b-2eec601994e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Sum of input lengths does not equal the length of the input dataset!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7702a73327ec>\u001b[0m in \u001b[0;36m<cell line: 134>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;31m# Run the federated learning process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_learning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-7702a73327ec>\u001b[0m in \u001b[0;36mfederated_learning\u001b[0;34m(trainset, testset, num_clients, global_epochs, client_epochs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Initialize global model and clients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mglobal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mclient_loaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_clients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7702a73327ec>\u001b[0m in \u001b[0;36minitialize_clients\u001b[0;34m(trainset, num_clients, batch_size)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Initialize clients with validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitialize_clients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mclient_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     client_loaders = [(DataLoader(client_data, batch_size=batch_size, shuffle=True),\n\u001b[1;32m     53\u001b[0m                        DataLoader(val_data, batch_size=batch_size, shuffle=False)) for client_data, val_data in client_datasets]\n",
            "\u001b[0;32m<ipython-input-4-7702a73327ec>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(trainset, num_clients, val_ratio)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mclient_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clients\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mclient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mval_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_len\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mval_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mclient_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclient_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36mrandom_split\u001b[0;34m(dataset, lengths, generator)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;31m# Cannot verify that dataset is Sized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    481\u001b[0m             \u001b[0;34m\"Sum of input lengths does not equal the length of the input dataset!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initial dataset provided by the user\n",
        "FedAvg_accuracy = [\n",
        "    9.31, 9.48, 9.64, 9.95, 9.98, 10.87, 13.12, 14.64, 15.58, 15.98,\n",
        "    9.20, 11.76, 13.48, 13.44, 13.01, 12.11, 13.28, 13.38, 13.33, 13.23,\n",
        "    9.15, 11.68, 14.19, 15.63, 16.14, 16.61, 16.70, 16.66, 16.81, 16.69,\n",
        "    9.34, 10.89, 13.42, 14.48, 15.96, 16.06, 16.49, 16.93, 17.51, 17.35,\n",
        "    9.45, 10.70, 11.54, 14.37, 15.37, 16.07, 16.58, 16.80, 17.09, 17.26,\n",
        "    16.99, 17.40, 16.93, 16.25, 16.00, 16.07, 16.87, 17.79, 18.72, 19.15,\n",
        "    20.59, 16.87, 16.46, 16.28, 16.40, 16.76, 17.69, 19.04, 20.20, 21.82,\n",
        "    22.65, 16.93, 16.75, 16.56, 16.44, 16.91, 18.01, 19.42, 20.74, 21.73,\n",
        "    22.61, 16.91, 16.69, 16.60, 16.46, 16.93, 17.63, 18.58, 20.05, 20.80,\n",
        "    21.63, 17.02, 16.84, 16.79, 16.96, 17.23, 18.15, 19.26, 20.65, 21.62,\n",
        "    22.50, 22.37, 22.89, 22.86, 23.78, 24.81, 25.58, 25.56, 25.79, 26.59,\n",
        "    27.01, 26.74, 23.03, 22.82, 24.33, 24.11, 25.25, 25.84, 26.34, 26.54,\n",
        "    26.85, 27.61, 23.12, 23.84, 24.45, 24.88, 25.69, 25.91, 25.91, 26.71,\n",
        "    27.13, 27.32, 23.25, 23.58, 24.44, 24.85, 24.71, 25.79, 25.96, 26.20,\n",
        "    27.27, 27.64, 23.06, 23.78, 24.24, 24.51, 25.40, 25.79, 26.25, 26.61,\n",
        "    26.81, 27.65, 27.74, 27.24, 28.80, 28.58, 29.54, 29.22, 30.59, 31.44,\n",
        "    31.34, 32.81, 33.60, 27.85, 28.44, 29.03, 29.06, 30.40, 30.77, 31.32,\n",
        "    31.94, 32.58, 33.33, 27.89, 28.23, 29.24, 29.70, 30.34, 30.84, 31.19,\n",
        "    32.34, 32.11, 32.91, 27.76, 28.76, 28.88, 29.40, 30.29, 30.68, 31.43,\n",
        "    31.65, 33.27, 32.69, 28.16, 28.51, 29.56, 29.94, 31.07, 30.55, 31.77,\n",
        "    32.16, 33.40, 33.37, 33.70, 34.14, 35.13, 35.16, 35.40, 36.56, 37.01,\n",
        "    37.70, 38.11, 38.66, 39.09, 33.81, 34.42, 35.61, 35.89, 36.64, 36.81,\n",
        "    37.58, 37.13, 38.04, 38.77, 34.17, 34.85, 35.21, 36.24, 36.41, 36.78,\n",
        "    37.41, 36.94, 38.47, 38.77, 34.27, 34.31, 34.80, 35.84, 35.61, 36.77,\n",
        "    37.15, 36.87, 38.29, 38.76, 34.29, 34.46, 35.52,35.53, 36.54, 36.73,\n",
        "    37.42\n",
        "]\n",
        "\n",
        "# Method 1: Extrapolation\n",
        "# Calculate the trend in the last 10 values and use it to extend the series\n",
        "last_values = np.array(FedAvg_accuracy[-10:])\n",
        "trend = np.mean(np.diff(last_values))  # Approximate trend based on the last few values\n",
        "extension_extrapolation = list(last_values + np.arange(1, 101) * trend)\n",
        "\n",
        "# Method 2: Repetition\n",
        "extension_repetition = FedAvg_accuracy[:100]  # Repeat the first 100 values\n",
        "\n",
        "# Combine both extended datasets to make them 500 values long\n",
        "extended_extrapolation = FedAvg_accuracy + extension_extrapolation[:500-len(FedAvg_accuracy)]\n",
        "extended_repetition = FedAvg_accuracy + extension_repetition[:500-len(FedAvg_accuracy)]\n",
        "\n",
        "extended_extrapolation, extended_repetition\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ALFSxI9cxoE3",
        "outputId": "dd119e93-a09b-4272-e8fd-e9346cbceebe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (10,) (100,) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-85807df4e616>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFedAvg_accuracy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mtrend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Approximate trend based on the last few values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mextension_extrapolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m101\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Method 2: Repetition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,) (100,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split training data among 5 clients\n",
        "def split_data(dataset, num_clients=5):\n",
        "    split_size = len(dataset) // num_clients\n",
        "    lengths = [split_size] * num_clients\n",
        "    if len(dataset) % num_clients != 0:\n",
        "        lengths[-1] += len(dataset) % num_clients\n",
        "    return random_split(dataset, lengths)\n",
        "\n",
        "# Create DataLoaders for clients\n",
        "def create_client_loaders(client_datasets, batch_size=128):\n",
        "    return [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in client_datasets]\n",
        "\n",
        "client_datasets = split_data(train_dataset)\n",
        "client_loaders = create_client_loaders(client_datasets)\n",
        "\n",
        "# DataLoader for validation (test) set\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Train function for one client\n",
        "def train_client(model, train_loader, criterion, optimizer, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# Federated averaging function (FedAvg)\n",
        "def federated_avg(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.mean(torch.stack([client_model.state_dict()[key].float() for client_model in client_models]), dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Validation function\n",
        "def validate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Initialize models for clients and global model\n",
        "global_model = Net()\n",
        "client_models = [Net() for _ in range(5)]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "num_rounds = 10  # Total number of communication rounds\n",
        "num_epochs_per_client = 10  # Number of epochs per client per round\n",
        "total_epochs = num_rounds * num_epochs_per_client  # 500 total epochs (if num_rounds * num_epochs = 500)\n",
        "\n",
        "# Training loop\n",
        "FedAvg_accuracy = []\n",
        "optimizer_list = [optim.SGD(client_model.parameters(), lr=0.001, momentum=0.9) for client_model in client_models]\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Train each client model on its respective data\n",
        "    for client_idx, client_loader in enumerate(client_loaders):\n",
        "        print(f\"Training client {client_idx + 1}\")\n",
        "        train_client(client_models[client_idx], client_loader, criterion, optimizer_list[client_idx], epochs=num_epochs_per_client)\n",
        "\n",
        "    # Perform FedAvg (aggregate models)\n",
        "    federated_avg(global_model, client_models)\n",
        "\n",
        "    # Update client models with the aggregated global model\n",
        "    for client_model in client_models:\n",
        "        client_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Validate the global model\n",
        "    val_acc = validate_model(global_model, val_loader)\n",
        "    FedAvg_accuracy.append(val_acc)\n",
        "    print(f\"Validation Accuracy after round {round_num + 1}: {val_acc:.2f}%\")\n",
        "\n",
        "# After all rounds, print the final trend and validation accuracies\n",
        "\n",
        "# Method 1: Trend extrapolation based on the last 10 validation accuracies\n",
        "last_values = np.array(FedAvg_accuracy[-10:])\n",
        "trend = np.mean(np.diff(last_values))  # Approximate trend based on the last few values\n",
        "extension_extrapolation = list(last_values[-1] + np.arange(1, 101) * trend)\n",
        "\n",
        "print(\"Final validation accuracies over rounds:\", FedAvg_accuracy)\n",
        "print(\"Extrapolated validation accuracies based on recent trend:\", extension_extrapolation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "9AbSItnayil-",
        "outputId": "d58e867a-02cb-485a-c0f8-491c881d84bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Training client 1\n",
            "Epoch 1, Loss: 2.3036\n",
            "Epoch 2, Loss: 2.3025\n",
            "Epoch 3, Loss: 2.3014\n",
            "Epoch 4, Loss: 2.3002\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-422817ca9ce7>\u001b[0m in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclient_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_loaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training client {client_idx + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mtrain_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs_per_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Perform FedAvg (aggregate models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-422817ca9ce7>\u001b[0m in \u001b[0;36mtrain_client\u001b[0;34m(model, train_loader, criterion, optimizer, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# handle PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mmode_to_nptype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"I\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"I;16\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"little\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"I;16B\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"F\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_to_nptype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network model (Classification Model)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split training data among 5 clients\n",
        "def split_data(dataset, num_clients=5):\n",
        "    split_size = len(dataset) // num_clients\n",
        "    lengths = [split_size] * num_clients\n",
        "    if len(dataset) % num_clients != 0:\n",
        "        lengths[-1] += len(dataset) % num_clients\n",
        "    return random_split(dataset, lengths)\n",
        "\n",
        "# Create DataLoaders for clients\n",
        "def create_client_loaders(client_datasets, batch_size=128):\n",
        "    return [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in client_datasets]\n",
        "\n",
        "client_datasets = split_data(train_dataset)\n",
        "client_loaders = create_client_loaders(client_datasets)\n",
        "\n",
        "# DataLoader for validation (test) set\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Train function for one client\n",
        "def train_client(model, train_loader, criterion, optimizer, scheduler, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "# Federated averaging function (FedAvg)\n",
        "def federated_avg(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.mean(torch.stack([client_model.state_dict()[key].float() for client_model in client_models]), dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Validation function\n",
        "def validate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Initialize models for clients and global model\n",
        "global_model = Net()\n",
        "client_models = [Net() for _ in range(5)]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "num_rounds = 10  # Total number of communication rounds\n",
        "num_epochs_per_client = 10  # Number of epochs per client per round (classification model train = 10)\n",
        "\n",
        "# Optimizer and scheduler setup (as per Table 2)\n",
        "optimizer_list = [optim.SGD(client_model.parameters(), lr=0.001, momentum=0.9) for client_model in client_models]\n",
        "scheduler_list = [optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5) for optimizer in optimizer_list]\n",
        "\n",
        "# Training loop\n",
        "FedAvg_accuracy = []\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Train each client model on its respective data\n",
        "    for client_idx, client_loader in enumerate(client_loaders):\n",
        "        print(f\"Training client {client_idx + 1}\")\n",
        "        train_client(client_models[client_idx], client_loader, criterion, optimizer_list[client_idx], scheduler_list[client_idx], epochs=num_epochs_per_client)\n",
        "\n",
        "    # Perform FedAvg (aggregate models)\n",
        "    federated_avg(global_model, client_models)\n",
        "\n",
        "    # Update client models with the aggregated global model\n",
        "    for client_model in client_models:\n",
        "        client_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Validate the global model\n",
        "    val_acc = validate_model(global_model, val_loader)\n",
        "    FedAvg_accuracy.append(val_acc)\n",
        "    print(f\"Validation Accuracy after round {round_num + 1}: {val_acc:.2f}%\")\n",
        "\n",
        "# After all rounds, print the final validation accuracies\n",
        "print(\"Final validation accuracies over rounds:\", FedAvg_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "CwhaYXw0ytCm",
        "outputId": "2949f68d-56ed-41e5-a9ec-f57f5ca7a6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Training client 1\n",
            "Training client 2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-96acaae6333d>\u001b[0m in \u001b[0;36m<cell line: 101>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclient_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_loader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_loaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training client {client_idx + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtrain_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclient_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs_per_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;31m# Perform FedAvg (aggregate models)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-96acaae6333d>\u001b[0m in \u001b[0;36mtrain_client\u001b[0;34m(model, train_loader, criterion, optimizer, scheduler, epochs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/datasets/cifar.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3295\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstrides\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tobytes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3297\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3298\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tostring\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3299\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network model (Classification Model)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split training data among 5 clients\n",
        "def split_data(dataset, num_clients=5):\n",
        "    split_size = len(dataset) // num_clients\n",
        "    lengths = [split_size] * num_clients\n",
        "    if len(dataset) % num_clients != 0:\n",
        "        lengths[-1] += len(dataset) % num_clients\n",
        "    return random_split(dataset, lengths)\n",
        "\n",
        "# Create DataLoaders for clients\n",
        "def create_client_loaders(client_datasets, batch_size=128):\n",
        "    return [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in client_datasets]\n",
        "\n",
        "client_datasets = split_data(train_dataset)\n",
        "client_loaders = create_client_loaders(client_datasets)\n",
        "\n",
        "# DataLoader for validation (test) set\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Train function for one client\n",
        "def train_client(model, train_loader, criterion, optimizer, scheduler, val_loader, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        # Validate the model after every epoch\n",
        "        val_acc = validate_model(model, val_loader)\n",
        "        print(f\"Epoch {epoch + 1} - Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "# Federated averaging function (FedAvg)\n",
        "def federated_avg(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.mean(torch.stack([client_model.state_dict()[key].float() for client_model in client_models]), dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Validation function\n",
        "def validate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Initialize models for clients and global model\n",
        "global_model = Net()\n",
        "client_models = [Net() for _ in range(5)]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "num_rounds = 10  # Total number of communication rounds\n",
        "num_epochs_per_client = 10  # Number of epochs per client per round (classification model train = 10)\n",
        "\n",
        "# Optimizer and scheduler setup (as per Table 2)\n",
        "optimizer_list = [optim.SGD(client_model.parameters(), lr=0.001, momentum=0.9) for client_model in client_models]\n",
        "scheduler_list = [optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5) for optimizer in optimizer_list]\n",
        "\n",
        "# Training loop\n",
        "FedAvg_accuracy = []\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Train each client model on its respective data and print validation accuracy after each epoch\n",
        "    for client_idx, client_loader in enumerate(client_loaders):\n",
        "        print(f\"Training client {client_idx + 1}\")\n",
        "        train_client(client_models[client_idx], client_loader, criterion, optimizer_list[client_idx], scheduler_list[client_idx], val_loader, epochs=num_epochs_per_client)\n",
        "\n",
        "    # Perform FedAvg (aggregate models)\n",
        "    federated_avg(global_model, client_models)\n",
        "\n",
        "    # Update client models with the aggregated global model\n",
        "    for client_model in client_models:\n",
        "        client_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Validate the global model after each round\n",
        "    val_acc = validate_model(global_model, val_loader)\n",
        "    FedAvg_accuracy.append(val_acc)\n",
        "    print(f\"Validation Accuracy after round {round_num + 1}: {val_acc:.2f}%\")\n",
        "\n",
        "# After all rounds, print the final validation accuracies\n",
        "print(\"Final validation accuracies over rounds:\", FedAvg_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKDYIWn6z1Pm",
        "outputId": "f458ab4a-06ee-41d6-92f3-98f06cb0c489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.02%\n",
            "Epoch 2 - Validation Accuracy: 10.02%\n",
            "Epoch 3 - Validation Accuracy: 10.05%\n",
            "Epoch 4 - Validation Accuracy: 10.05%\n",
            "Epoch 5 - Validation Accuracy: 10.12%\n",
            "Epoch 6 - Validation Accuracy: 10.30%\n",
            "Epoch 7 - Validation Accuracy: 10.33%\n",
            "Epoch 8 - Validation Accuracy: 11.05%\n",
            "Epoch 9 - Validation Accuracy: 12.98%\n",
            "Epoch 10 - Validation Accuracy: 15.28%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 9.22%\n",
            "Epoch 2 - Validation Accuracy: 10.07%\n",
            "Epoch 3 - Validation Accuracy: 11.21%\n",
            "Epoch 4 - Validation Accuracy: 12.15%\n",
            "Epoch 5 - Validation Accuracy: 14.53%\n",
            "Epoch 6 - Validation Accuracy: 17.01%\n",
            "Epoch 7 - Validation Accuracy: 18.21%\n",
            "Epoch 8 - Validation Accuracy: 19.22%\n",
            "Epoch 9 - Validation Accuracy: 20.35%\n",
            "Epoch 10 - Validation Accuracy: 21.51%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.15%\n",
            "Epoch 2 - Validation Accuracy: 10.24%\n",
            "Epoch 3 - Validation Accuracy: 10.46%\n",
            "Epoch 4 - Validation Accuracy: 11.43%\n",
            "Epoch 5 - Validation Accuracy: 13.04%\n",
            "Epoch 6 - Validation Accuracy: 14.30%\n",
            "Epoch 7 - Validation Accuracy: 14.55%\n",
            "Epoch 8 - Validation Accuracy: 15.07%\n",
            "Epoch 9 - Validation Accuracy: 14.92%\n",
            "Epoch 10 - Validation Accuracy: 14.99%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 11.36%\n",
            "Epoch 3 - Validation Accuracy: 12.58%\n",
            "Epoch 4 - Validation Accuracy: 13.68%\n",
            "Epoch 5 - Validation Accuracy: 16.16%\n",
            "Epoch 6 - Validation Accuracy: 17.75%\n",
            "Epoch 7 - Validation Accuracy: 18.64%\n",
            "Epoch 8 - Validation Accuracy: 19.15%\n",
            "Epoch 9 - Validation Accuracy: 19.97%\n",
            "Epoch 10 - Validation Accuracy: 21.57%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.14%\n",
            "Epoch 3 - Validation Accuracy: 13.28%\n",
            "Epoch 4 - Validation Accuracy: 13.47%\n",
            "Epoch 5 - Validation Accuracy: 14.00%\n",
            "Epoch 6 - Validation Accuracy: 16.63%\n",
            "Epoch 7 - Validation Accuracy: 18.21%\n",
            "Epoch 8 - Validation Accuracy: 20.25%\n",
            "Epoch 9 - Validation Accuracy: 21.42%\n",
            "Epoch 10 - Validation Accuracy: 21.76%\n",
            "Validation Accuracy after round 1: 10.00%\n",
            "Round 2/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.01%\n",
            "Epoch 7 - Validation Accuracy: 10.56%\n",
            "Epoch 8 - Validation Accuracy: 14.58%\n",
            "Epoch 9 - Validation Accuracy: 13.82%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 11.69%\n",
            "Epoch 4 - Validation Accuracy: 13.72%\n",
            "Epoch 5 - Validation Accuracy: 13.38%\n",
            "Epoch 6 - Validation Accuracy: 10.01%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.76%\n",
            "Epoch 2 - Validation Accuracy: 11.87%\n",
            "Epoch 3 - Validation Accuracy: 10.10%\n",
            "Epoch 4 - Validation Accuracy: 12.14%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 11.47%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 2: 10.21%\n",
            "Round 3/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.08%\n",
            "Epoch 5 - Validation Accuracy: 10.41%\n",
            "Epoch 6 - Validation Accuracy: 12.12%\n",
            "Epoch 7 - Validation Accuracy: 13.55%\n",
            "Epoch 8 - Validation Accuracy: 16.87%\n",
            "Epoch 9 - Validation Accuracy: 16.90%\n",
            "Epoch 10 - Validation Accuracy: 15.29%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.01%\n",
            "Epoch 10 - Validation Accuracy: 10.21%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 12.32%\n",
            "Epoch 2 - Validation Accuracy: 13.82%\n",
            "Epoch 3 - Validation Accuracy: 14.10%\n",
            "Epoch 4 - Validation Accuracy: 13.02%\n",
            "Epoch 5 - Validation Accuracy: 11.65%\n",
            "Epoch 6 - Validation Accuracy: 11.49%\n",
            "Epoch 7 - Validation Accuracy: 11.20%\n",
            "Epoch 8 - Validation Accuracy: 10.80%\n",
            "Epoch 9 - Validation Accuracy: 10.14%\n",
            "Epoch 10 - Validation Accuracy: 11.13%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 13.27%\n",
            "Epoch 2 - Validation Accuracy: 16.46%\n",
            "Epoch 3 - Validation Accuracy: 14.29%\n",
            "Epoch 4 - Validation Accuracy: 13.59%\n",
            "Epoch 5 - Validation Accuracy: 10.44%\n",
            "Epoch 6 - Validation Accuracy: 9.99%\n",
            "Epoch 7 - Validation Accuracy: 9.98%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.33%\n",
            "Epoch 3 - Validation Accuracy: 11.20%\n",
            "Epoch 4 - Validation Accuracy: 11.69%\n",
            "Epoch 5 - Validation Accuracy: 10.29%\n",
            "Epoch 6 - Validation Accuracy: 9.99%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 3: 13.30%\n",
            "Round 4/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 13.61%\n",
            "Epoch 2 - Validation Accuracy: 13.83%\n",
            "Epoch 3 - Validation Accuracy: 15.11%\n",
            "Epoch 4 - Validation Accuracy: 17.52%\n",
            "Epoch 5 - Validation Accuracy: 18.28%\n",
            "Epoch 6 - Validation Accuracy: 17.77%\n",
            "Epoch 7 - Validation Accuracy: 17.52%\n",
            "Epoch 8 - Validation Accuracy: 16.59%\n",
            "Epoch 9 - Validation Accuracy: 16.22%\n",
            "Epoch 10 - Validation Accuracy: 16.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 12.58%\n",
            "Epoch 2 - Validation Accuracy: 12.11%\n",
            "Epoch 3 - Validation Accuracy: 12.30%\n",
            "Epoch 4 - Validation Accuracy: 12.06%\n",
            "Epoch 5 - Validation Accuracy: 12.42%\n",
            "Epoch 6 - Validation Accuracy: 12.52%\n",
            "Epoch 7 - Validation Accuracy: 12.84%\n",
            "Epoch 8 - Validation Accuracy: 12.67%\n",
            "Epoch 9 - Validation Accuracy: 13.11%\n",
            "Epoch 10 - Validation Accuracy: 13.52%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 12.28%\n",
            "Epoch 2 - Validation Accuracy: 13.74%\n",
            "Epoch 3 - Validation Accuracy: 13.86%\n",
            "Epoch 4 - Validation Accuracy: 13.06%\n",
            "Epoch 5 - Validation Accuracy: 12.77%\n",
            "Epoch 6 - Validation Accuracy: 12.78%\n",
            "Epoch 7 - Validation Accuracy: 13.42%\n",
            "Epoch 8 - Validation Accuracy: 13.03%\n",
            "Epoch 9 - Validation Accuracy: 13.58%\n",
            "Epoch 10 - Validation Accuracy: 13.92%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 16.65%\n",
            "Epoch 2 - Validation Accuracy: 17.44%\n",
            "Epoch 3 - Validation Accuracy: 15.43%\n",
            "Epoch 4 - Validation Accuracy: 13.67%\n",
            "Epoch 5 - Validation Accuracy: 12.53%\n",
            "Epoch 6 - Validation Accuracy: 11.05%\n",
            "Epoch 7 - Validation Accuracy: 10.02%\n",
            "Epoch 8 - Validation Accuracy: 9.98%\n",
            "Epoch 9 - Validation Accuracy: 9.98%\n",
            "Epoch 10 - Validation Accuracy: 9.97%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 13.37%\n",
            "Epoch 2 - Validation Accuracy: 13.41%\n",
            "Epoch 3 - Validation Accuracy: 12.61%\n",
            "Epoch 4 - Validation Accuracy: 11.43%\n",
            "Epoch 5 - Validation Accuracy: 12.58%\n",
            "Epoch 6 - Validation Accuracy: 10.84%\n",
            "Epoch 7 - Validation Accuracy: 11.76%\n",
            "Epoch 8 - Validation Accuracy: 11.84%\n",
            "Epoch 9 - Validation Accuracy: 12.03%\n",
            "Epoch 10 - Validation Accuracy: 11.83%\n",
            "Validation Accuracy after round 4: 16.51%\n",
            "Round 5/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 17.13%\n",
            "Epoch 2 - Validation Accuracy: 17.64%\n",
            "Epoch 3 - Validation Accuracy: 17.73%\n",
            "Epoch 4 - Validation Accuracy: 18.10%\n",
            "Epoch 5 - Validation Accuracy: 18.38%\n",
            "Epoch 6 - Validation Accuracy: 19.09%\n",
            "Epoch 7 - Validation Accuracy: 18.45%\n",
            "Epoch 8 - Validation Accuracy: 17.91%\n",
            "Epoch 9 - Validation Accuracy: 17.61%\n",
            "Epoch 10 - Validation Accuracy: 17.72%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 16.58%\n",
            "Epoch 2 - Validation Accuracy: 16.41%\n",
            "Epoch 3 - Validation Accuracy: 16.51%\n",
            "Epoch 4 - Validation Accuracy: 16.94%\n",
            "Epoch 5 - Validation Accuracy: 17.17%\n",
            "Epoch 6 - Validation Accuracy: 17.00%\n",
            "Epoch 7 - Validation Accuracy: 17.18%\n",
            "Epoch 8 - Validation Accuracy: 16.83%\n",
            "Epoch 9 - Validation Accuracy: 16.40%\n",
            "Epoch 10 - Validation Accuracy: 16.03%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 15.91%\n",
            "Epoch 2 - Validation Accuracy: 16.00%\n",
            "Epoch 3 - Validation Accuracy: 15.89%\n",
            "Epoch 4 - Validation Accuracy: 15.88%\n",
            "Epoch 5 - Validation Accuracy: 16.50%\n",
            "Epoch 6 - Validation Accuracy: 16.62%\n",
            "Epoch 7 - Validation Accuracy: 17.13%\n",
            "Epoch 8 - Validation Accuracy: 17.07%\n",
            "Epoch 9 - Validation Accuracy: 17.24%\n",
            "Epoch 10 - Validation Accuracy: 16.82%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 17.44%\n",
            "Epoch 2 - Validation Accuracy: 17.73%\n",
            "Epoch 3 - Validation Accuracy: 18.15%\n",
            "Epoch 4 - Validation Accuracy: 18.43%\n",
            "Epoch 5 - Validation Accuracy: 18.18%\n",
            "Epoch 6 - Validation Accuracy: 17.06%\n",
            "Epoch 7 - Validation Accuracy: 16.30%\n",
            "Epoch 8 - Validation Accuracy: 15.79%\n",
            "Epoch 9 - Validation Accuracy: 15.18%\n",
            "Epoch 10 - Validation Accuracy: 15.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 16.78%\n",
            "Epoch 2 - Validation Accuracy: 16.19%\n",
            "Epoch 3 - Validation Accuracy: 16.65%\n",
            "Epoch 4 - Validation Accuracy: 16.52%\n",
            "Epoch 5 - Validation Accuracy: 16.78%\n",
            "Epoch 6 - Validation Accuracy: 16.80%\n",
            "Epoch 7 - Validation Accuracy: 16.84%\n",
            "Epoch 8 - Validation Accuracy: 16.66%\n",
            "Epoch 9 - Validation Accuracy: 16.54%\n",
            "Epoch 10 - Validation Accuracy: 16.29%\n",
            "Validation Accuracy after round 5: 18.14%\n",
            "Round 6/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 18.38%\n",
            "Epoch 2 - Validation Accuracy: 18.59%\n",
            "Epoch 3 - Validation Accuracy: 19.16%\n",
            "Epoch 4 - Validation Accuracy: 19.08%\n",
            "Epoch 5 - Validation Accuracy: 19.11%\n",
            "Epoch 6 - Validation Accuracy: 19.21%\n",
            "Epoch 7 - Validation Accuracy: 19.17%\n",
            "Epoch 8 - Validation Accuracy: 18.63%\n",
            "Epoch 9 - Validation Accuracy: 18.41%\n",
            "Epoch 10 - Validation Accuracy: 18.10%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 17.93%\n",
            "Epoch 2 - Validation Accuracy: 17.83%\n",
            "Epoch 3 - Validation Accuracy: 18.08%\n",
            "Epoch 4 - Validation Accuracy: 18.17%\n",
            "Epoch 5 - Validation Accuracy: 18.21%\n",
            "Epoch 6 - Validation Accuracy: 18.20%\n",
            "Epoch 7 - Validation Accuracy: 17.60%\n",
            "Epoch 8 - Validation Accuracy: 17.51%\n",
            "Epoch 9 - Validation Accuracy: 17.24%\n",
            "Epoch 10 - Validation Accuracy: 17.29%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 18.55%\n",
            "Epoch 2 - Validation Accuracy: 19.17%\n",
            "Epoch 3 - Validation Accuracy: 19.20%\n",
            "Epoch 4 - Validation Accuracy: 19.56%\n",
            "Epoch 5 - Validation Accuracy: 19.55%\n",
            "Epoch 6 - Validation Accuracy: 19.59%\n",
            "Epoch 7 - Validation Accuracy: 18.88%\n",
            "Epoch 8 - Validation Accuracy: 19.16%\n",
            "Epoch 9 - Validation Accuracy: 19.04%\n",
            "Epoch 10 - Validation Accuracy: 18.85%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 18.59%\n",
            "Epoch 2 - Validation Accuracy: 18.62%\n",
            "Epoch 3 - Validation Accuracy: 19.23%\n",
            "Epoch 4 - Validation Accuracy: 19.54%\n",
            "Epoch 5 - Validation Accuracy: 19.37%\n",
            "Epoch 6 - Validation Accuracy: 19.53%\n",
            "Epoch 7 - Validation Accuracy: 19.38%\n",
            "Epoch 8 - Validation Accuracy: 19.09%\n",
            "Epoch 9 - Validation Accuracy: 18.77%\n",
            "Epoch 10 - Validation Accuracy: 18.94%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 18.34%\n",
            "Epoch 2 - Validation Accuracy: 18.41%\n",
            "Epoch 3 - Validation Accuracy: 18.56%\n",
            "Epoch 4 - Validation Accuracy: 18.11%\n",
            "Epoch 5 - Validation Accuracy: 18.26%\n",
            "Epoch 6 - Validation Accuracy: 18.30%\n",
            "Epoch 7 - Validation Accuracy: 18.17%\n",
            "Epoch 8 - Validation Accuracy: 17.93%\n",
            "Epoch 9 - Validation Accuracy: 17.83%\n",
            "Epoch 10 - Validation Accuracy: 17.97%\n",
            "Validation Accuracy after round 6: 18.99%\n",
            "Round 7/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 18.79%\n",
            "Epoch 2 - Validation Accuracy: 18.91%\n",
            "Epoch 3 - Validation Accuracy: 18.95%\n",
            "Epoch 4 - Validation Accuracy: 18.85%\n",
            "Epoch 5 - Validation Accuracy: 18.66%\n",
            "Epoch 6 - Validation Accuracy: 18.62%\n",
            "Epoch 7 - Validation Accuracy: 18.71%\n",
            "Epoch 8 - Validation Accuracy: 18.71%\n",
            "Epoch 9 - Validation Accuracy: 18.76%\n",
            "Epoch 10 - Validation Accuracy: 19.38%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 19.00%\n",
            "Epoch 2 - Validation Accuracy: 18.89%\n",
            "Epoch 3 - Validation Accuracy: 18.84%\n",
            "Epoch 4 - Validation Accuracy: 18.87%\n",
            "Epoch 5 - Validation Accuracy: 18.77%\n",
            "Epoch 6 - Validation Accuracy: 18.80%\n",
            "Epoch 7 - Validation Accuracy: 18.87%\n",
            "Epoch 8 - Validation Accuracy: 18.82%\n",
            "Epoch 9 - Validation Accuracy: 18.64%\n",
            "Epoch 10 - Validation Accuracy: 18.73%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 19.09%\n",
            "Epoch 2 - Validation Accuracy: 19.31%\n",
            "Epoch 3 - Validation Accuracy: 19.62%\n",
            "Epoch 4 - Validation Accuracy: 19.86%\n",
            "Epoch 5 - Validation Accuracy: 19.95%\n",
            "Epoch 6 - Validation Accuracy: 20.02%\n",
            "Epoch 7 - Validation Accuracy: 20.15%\n",
            "Epoch 8 - Validation Accuracy: 20.02%\n",
            "Epoch 9 - Validation Accuracy: 20.24%\n",
            "Epoch 10 - Validation Accuracy: 20.55%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 19.05%\n",
            "Epoch 2 - Validation Accuracy: 19.08%\n",
            "Epoch 3 - Validation Accuracy: 19.36%\n",
            "Epoch 4 - Validation Accuracy: 19.41%\n",
            "Epoch 5 - Validation Accuracy: 19.76%\n",
            "Epoch 6 - Validation Accuracy: 19.89%\n",
            "Epoch 7 - Validation Accuracy: 20.02%\n",
            "Epoch 8 - Validation Accuracy: 20.14%\n",
            "Epoch 9 - Validation Accuracy: 20.21%\n",
            "Epoch 10 - Validation Accuracy: 20.40%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 18.76%\n",
            "Epoch 2 - Validation Accuracy: 18.81%\n",
            "Epoch 3 - Validation Accuracy: 18.77%\n",
            "Epoch 4 - Validation Accuracy: 18.83%\n",
            "Epoch 5 - Validation Accuracy: 18.86%\n",
            "Epoch 6 - Validation Accuracy: 18.77%\n",
            "Epoch 7 - Validation Accuracy: 18.70%\n",
            "Epoch 8 - Validation Accuracy: 18.69%\n",
            "Epoch 9 - Validation Accuracy: 18.66%\n",
            "Epoch 10 - Validation Accuracy: 18.67%\n",
            "Validation Accuracy after round 7: 18.91%\n",
            "Round 8/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 18.88%\n",
            "Epoch 2 - Validation Accuracy: 18.99%\n",
            "Epoch 3 - Validation Accuracy: 19.04%\n",
            "Epoch 4 - Validation Accuracy: 18.79%\n",
            "Epoch 5 - Validation Accuracy: 18.70%\n",
            "Epoch 6 - Validation Accuracy: 18.86%\n",
            "Epoch 7 - Validation Accuracy: 19.07%\n",
            "Epoch 8 - Validation Accuracy: 19.04%\n",
            "Epoch 9 - Validation Accuracy: 19.17%\n",
            "Epoch 10 - Validation Accuracy: 19.27%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 18.79%\n",
            "Epoch 2 - Validation Accuracy: 18.75%\n",
            "Epoch 3 - Validation Accuracy: 18.85%\n",
            "Epoch 4 - Validation Accuracy: 18.79%\n",
            "Epoch 5 - Validation Accuracy: 18.74%\n",
            "Epoch 6 - Validation Accuracy: 18.57%\n",
            "Epoch 7 - Validation Accuracy: 18.69%\n",
            "Epoch 8 - Validation Accuracy: 18.75%\n",
            "Epoch 9 - Validation Accuracy: 18.74%\n",
            "Epoch 10 - Validation Accuracy: 18.73%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 19.17%\n",
            "Epoch 2 - Validation Accuracy: 19.40%\n",
            "Epoch 3 - Validation Accuracy: 19.63%\n",
            "Epoch 4 - Validation Accuracy: 19.80%\n",
            "Epoch 5 - Validation Accuracy: 19.80%\n",
            "Epoch 6 - Validation Accuracy: 19.90%\n",
            "Epoch 7 - Validation Accuracy: 19.99%\n",
            "Epoch 8 - Validation Accuracy: 19.83%\n",
            "Epoch 9 - Validation Accuracy: 20.21%\n",
            "Epoch 10 - Validation Accuracy: 20.63%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 19.03%\n",
            "Epoch 2 - Validation Accuracy: 19.13%\n",
            "Epoch 3 - Validation Accuracy: 19.32%\n",
            "Epoch 4 - Validation Accuracy: 19.43%\n",
            "Epoch 5 - Validation Accuracy: 19.72%\n",
            "Epoch 6 - Validation Accuracy: 19.69%\n",
            "Epoch 7 - Validation Accuracy: 19.72%\n",
            "Epoch 8 - Validation Accuracy: 19.80%\n",
            "Epoch 9 - Validation Accuracy: 19.83%\n",
            "Epoch 10 - Validation Accuracy: 19.96%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 18.62%\n",
            "Epoch 2 - Validation Accuracy: 18.73%\n",
            "Epoch 3 - Validation Accuracy: 18.83%\n",
            "Epoch 4 - Validation Accuracy: 18.78%\n",
            "Epoch 5 - Validation Accuracy: 18.76%\n",
            "Epoch 6 - Validation Accuracy: 18.68%\n",
            "Epoch 7 - Validation Accuracy: 18.72%\n",
            "Epoch 8 - Validation Accuracy: 18.76%\n",
            "Epoch 9 - Validation Accuracy: 18.70%\n",
            "Epoch 10 - Validation Accuracy: 18.75%\n",
            "Validation Accuracy after round 8: 18.96%\n",
            "Round 9/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 19.00%\n",
            "Epoch 2 - Validation Accuracy: 19.13%\n",
            "Epoch 3 - Validation Accuracy: 19.16%\n",
            "Epoch 4 - Validation Accuracy: 19.08%\n",
            "Epoch 5 - Validation Accuracy: 19.13%\n",
            "Epoch 6 - Validation Accuracy: 19.07%\n",
            "Epoch 7 - Validation Accuracy: 18.92%\n",
            "Epoch 8 - Validation Accuracy: 19.01%\n",
            "Epoch 9 - Validation Accuracy: 19.02%\n",
            "Epoch 10 - Validation Accuracy: 18.96%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 18.98%\n",
            "Epoch 2 - Validation Accuracy: 18.86%\n",
            "Epoch 3 - Validation Accuracy: 18.85%\n",
            "Epoch 4 - Validation Accuracy: 18.81%\n",
            "Epoch 5 - Validation Accuracy: 18.90%\n",
            "Epoch 6 - Validation Accuracy: 18.84%\n",
            "Epoch 7 - Validation Accuracy: 18.89%\n",
            "Epoch 8 - Validation Accuracy: 18.88%\n",
            "Epoch 9 - Validation Accuracy: 18.94%\n",
            "Epoch 10 - Validation Accuracy: 18.97%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 18.97%\n",
            "Epoch 2 - Validation Accuracy: 19.08%\n",
            "Epoch 3 - Validation Accuracy: 19.10%\n",
            "Epoch 4 - Validation Accuracy: 19.28%\n",
            "Epoch 5 - Validation Accuracy: 19.28%\n",
            "Epoch 6 - Validation Accuracy: 19.37%\n",
            "Epoch 7 - Validation Accuracy: 19.68%\n",
            "Epoch 8 - Validation Accuracy: 19.68%\n",
            "Epoch 9 - Validation Accuracy: 19.66%\n",
            "Epoch 10 - Validation Accuracy: 19.75%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 19.07%\n",
            "Epoch 2 - Validation Accuracy: 19.19%\n",
            "Epoch 3 - Validation Accuracy: 19.23%\n",
            "Epoch 4 - Validation Accuracy: 19.22%\n",
            "Epoch 5 - Validation Accuracy: 19.31%\n",
            "Epoch 6 - Validation Accuracy: 19.45%\n",
            "Epoch 7 - Validation Accuracy: 19.55%\n",
            "Epoch 8 - Validation Accuracy: 19.55%\n",
            "Epoch 9 - Validation Accuracy: 19.65%\n",
            "Epoch 10 - Validation Accuracy: 19.65%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 18.95%\n",
            "Epoch 2 - Validation Accuracy: 18.88%\n",
            "Epoch 3 - Validation Accuracy: 18.95%\n",
            "Epoch 4 - Validation Accuracy: 18.89%\n",
            "Epoch 5 - Validation Accuracy: 18.96%\n",
            "Epoch 6 - Validation Accuracy: 19.02%\n",
            "Epoch 7 - Validation Accuracy: 18.93%\n",
            "Epoch 8 - Validation Accuracy: 18.90%\n",
            "Epoch 9 - Validation Accuracy: 18.90%\n",
            "Epoch 10 - Validation Accuracy: 18.80%\n",
            "Validation Accuracy after round 9: 19.01%\n",
            "Round 10/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 19.07%\n",
            "Epoch 2 - Validation Accuracy: 19.12%\n",
            "Epoch 3 - Validation Accuracy: 19.12%\n",
            "Epoch 4 - Validation Accuracy: 19.03%\n",
            "Epoch 5 - Validation Accuracy: 19.03%\n",
            "Epoch 6 - Validation Accuracy: 19.06%\n",
            "Epoch 7 - Validation Accuracy: 19.16%\n",
            "Epoch 8 - Validation Accuracy: 19.08%\n",
            "Epoch 9 - Validation Accuracy: 19.06%\n",
            "Epoch 10 - Validation Accuracy: 19.01%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 19.00%\n",
            "Epoch 2 - Validation Accuracy: 18.93%\n",
            "Epoch 3 - Validation Accuracy: 18.93%\n",
            "Epoch 4 - Validation Accuracy: 18.92%\n",
            "Epoch 5 - Validation Accuracy: 18.93%\n",
            "Epoch 6 - Validation Accuracy: 18.94%\n",
            "Epoch 7 - Validation Accuracy: 18.99%\n",
            "Epoch 8 - Validation Accuracy: 18.95%\n",
            "Epoch 9 - Validation Accuracy: 18.98%\n",
            "Epoch 10 - Validation Accuracy: 18.95%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 19.12%\n",
            "Epoch 2 - Validation Accuracy: 19.21%\n",
            "Epoch 3 - Validation Accuracy: 19.25%\n",
            "Epoch 4 - Validation Accuracy: 19.26%\n",
            "Epoch 5 - Validation Accuracy: 19.26%\n",
            "Epoch 6 - Validation Accuracy: 19.40%\n",
            "Epoch 7 - Validation Accuracy: 19.52%\n",
            "Epoch 8 - Validation Accuracy: 19.52%\n",
            "Epoch 9 - Validation Accuracy: 19.62%\n",
            "Epoch 10 - Validation Accuracy: 19.70%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 19.05%\n",
            "Epoch 2 - Validation Accuracy: 19.08%\n",
            "Epoch 3 - Validation Accuracy: 19.20%\n",
            "Epoch 4 - Validation Accuracy: 19.25%\n",
            "Epoch 5 - Validation Accuracy: 19.29%\n",
            "Epoch 6 - Validation Accuracy: 19.35%\n",
            "Epoch 7 - Validation Accuracy: 19.43%\n",
            "Epoch 8 - Validation Accuracy: 19.43%\n",
            "Epoch 9 - Validation Accuracy: 19.42%\n",
            "Epoch 10 - Validation Accuracy: 19.37%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 19.05%\n",
            "Epoch 2 - Validation Accuracy: 18.92%\n",
            "Epoch 3 - Validation Accuracy: 18.97%\n",
            "Epoch 4 - Validation Accuracy: 19.01%\n",
            "Epoch 5 - Validation Accuracy: 19.09%\n",
            "Epoch 6 - Validation Accuracy: 18.99%\n",
            "Epoch 7 - Validation Accuracy: 18.98%\n",
            "Epoch 8 - Validation Accuracy: 18.92%\n",
            "Epoch 9 - Validation Accuracy: 18.93%\n",
            "Epoch 10 - Validation Accuracy: 18.94%\n",
            "Validation Accuracy after round 10: 18.97%\n",
            "Final validation accuracies over rounds: [10.0, 10.21, 13.3, 16.51, 18.14, 18.99, 18.91, 18.96, 19.01, 18.97]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xmbp89cDK5hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network model (Classification Model)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split training data among 5 clients\n",
        "def split_data(dataset, num_clients=5):\n",
        "    split_size = len(dataset) // num_clients\n",
        "    lengths = [split_size] * num_clients\n",
        "    if len(dataset) % num_clients != 0:\n",
        "        lengths[-1] += len(dataset) % num_clients\n",
        "    return random_split(dataset, lengths)\n",
        "\n",
        "# Create DataLoaders for clients\n",
        "def create_client_loaders(client_datasets, batch_size=128):\n",
        "    return [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in client_datasets]\n",
        "\n",
        "client_datasets = split_data(train_dataset)\n",
        "client_loaders = create_client_loaders(client_datasets)\n",
        "\n",
        "# DataLoader for validation (test) set\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Train function for one client\n",
        "def train_client(model, train_loader, criterion, optimizer, scheduler, val_loader, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        # Validate the model after every epoch\n",
        "        val_acc = validate_model(model, val_loader)\n",
        "        print(f\"Epoch {epoch + 1} - Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "# Federated averaging function (FedAvg)\n",
        "def federated_avg(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.mean(torch.stack([client_model.state_dict()[key].float() for client_model in client_models]), dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Validation function\n",
        "def validate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Initialize models for clients and global model\n",
        "global_model = Net()\n",
        "client_models = [Net() for _ in range(5)]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "num_rounds = 10  # Total number of communication rounds\n",
        "num_epochs_per_client = 10  # Number of epochs per client per round (classification model train = 10)\n",
        "\n",
        "# Optimizer and scheduler setup (as per Table 2)\n",
        "optimizer_list = [optim.SGD(client_model.parameters(), lr=0.001, momentum=0.9) for client_model in client_models]\n",
        "scheduler_list = [optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5) for optimizer in optimizer_list]\n",
        "\n",
        "# Training loop\n",
        "FedAvg_accuracy = []\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Train each client model on its respective data and print validation accuracy after each epoch\n",
        "    for client_idx, client_loader in enumerate(client_loaders):\n",
        "        print(f\"Training client {client_idx + 1}\")\n",
        "        train_client(client_models[client_idx], client_loader, criterion, optimizer_list[client_idx], scheduler_list[client_idx], val_loader, epochs=num_epochs_per_client)\n",
        "\n",
        "    # Perform FedAvg (aggregate models)\n",
        "    federated_avg(global_model, client_models)\n",
        "\n",
        "    # Update client models with the aggregated global model\n",
        "    for client_model in client_models:\n",
        "        client_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Validate the global model after each round\n",
        "    val_acc = validate_model(global_model, val_loader)\n",
        "    FedAvg_accuracy.append(val_acc)\n",
        "    print(f\"Validation Accuracy after round {round_num + 1}: {val_acc:.2f}%\")\n",
        "\n",
        "# After all rounds, print the final validation accuracies\n",
        "print(\"Final validation accuracies over rounds:\", FedAvg_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a0a9243-fa52-469c-907e-86bebb5b79de",
        "id": "ztHo0oNAK6Bp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 53.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 9.72%\n",
            "Epoch 2 - Validation Accuracy: 9.34%\n",
            "Epoch 3 - Validation Accuracy: 9.19%\n",
            "Epoch 4 - Validation Accuracy: 9.79%\n",
            "Epoch 5 - Validation Accuracy: 9.94%\n",
            "Epoch 6 - Validation Accuracy: 10.01%\n",
            "Epoch 7 - Validation Accuracy: 10.06%\n",
            "Epoch 8 - Validation Accuracy: 9.99%\n",
            "Epoch 9 - Validation Accuracy: 10.04%\n",
            "Epoch 10 - Validation Accuracy: 10.61%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 9.38%\n",
            "Epoch 2 - Validation Accuracy: 9.84%\n",
            "Epoch 3 - Validation Accuracy: 12.00%\n",
            "Epoch 4 - Validation Accuracy: 12.25%\n",
            "Epoch 5 - Validation Accuracy: 12.53%\n",
            "Epoch 6 - Validation Accuracy: 12.55%\n",
            "Epoch 7 - Validation Accuracy: 13.08%\n",
            "Epoch 8 - Validation Accuracy: 14.38%\n",
            "Epoch 9 - Validation Accuracy: 16.26%\n",
            "Epoch 10 - Validation Accuracy: 16.64%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 9.99%\n",
            "Epoch 9 - Validation Accuracy: 10.10%\n",
            "Epoch 10 - Validation Accuracy: 12.42%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 11.10%\n",
            "Epoch 2 - Validation Accuracy: 12.07%\n",
            "Epoch 3 - Validation Accuracy: 11.75%\n",
            "Epoch 4 - Validation Accuracy: 12.06%\n",
            "Epoch 5 - Validation Accuracy: 11.66%\n",
            "Epoch 6 - Validation Accuracy: 11.96%\n",
            "Epoch 7 - Validation Accuracy: 11.76%\n",
            "Epoch 8 - Validation Accuracy: 12.73%\n",
            "Epoch 9 - Validation Accuracy: 14.26%\n",
            "Epoch 10 - Validation Accuracy: 16.01%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 12.16%\n",
            "Epoch 2 - Validation Accuracy: 13.01%\n",
            "Epoch 3 - Validation Accuracy: 14.06%\n",
            "Epoch 4 - Validation Accuracy: 14.74%\n",
            "Epoch 5 - Validation Accuracy: 16.24%\n",
            "Epoch 6 - Validation Accuracy: 17.61%\n",
            "Epoch 7 - Validation Accuracy: 19.02%\n",
            "Epoch 8 - Validation Accuracy: 21.94%\n",
            "Epoch 9 - Validation Accuracy: 21.21%\n",
            "Epoch 10 - Validation Accuracy: 18.36%\n",
            "Validation Accuracy after round 1: 10.00%\n",
            "Round 2/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 9.42%\n",
            "Epoch 4 - Validation Accuracy: 10.26%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.01%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 9.45%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 2: 10.00%\n",
            "Round 3/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.57%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.01%\n",
            "Epoch 10 - Validation Accuracy: 10.18%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 9.59%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.12%\n",
            "Epoch 5 - Validation Accuracy: 10.01%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 3: 10.00%\n",
            "Round 4/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.10%\n",
            "Epoch 2 - Validation Accuracy: 10.13%\n",
            "Epoch 3 - Validation Accuracy: 10.26%\n",
            "Epoch 4 - Validation Accuracy: 10.77%\n",
            "Epoch 5 - Validation Accuracy: 12.04%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.38%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 13.91%\n",
            "Epoch 4 - Validation Accuracy: 10.01%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 4: 10.08%\n",
            "Round 5/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.44%\n",
            "Epoch 2 - Validation Accuracy: 11.18%\n",
            "Epoch 3 - Validation Accuracy: 13.14%\n",
            "Epoch 4 - Validation Accuracy: 12.87%\n",
            "Epoch 5 - Validation Accuracy: 13.31%\n",
            "Epoch 6 - Validation Accuracy: 13.48%\n",
            "Epoch 7 - Validation Accuracy: 13.61%\n",
            "Epoch 8 - Validation Accuracy: 13.79%\n",
            "Epoch 9 - Validation Accuracy: 14.70%\n",
            "Epoch 10 - Validation Accuracy: 14.68%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.04%\n",
            "Epoch 2 - Validation Accuracy: 10.08%\n",
            "Epoch 3 - Validation Accuracy: 10.03%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.04%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.00%\n",
            "Epoch 7 - Validation Accuracy: 10.00%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.28%\n",
            "Epoch 2 - Validation Accuracy: 9.75%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 9.93%\n",
            "Epoch 5 - Validation Accuracy: 10.01%\n",
            "Epoch 6 - Validation Accuracy: 10.25%\n",
            "Epoch 7 - Validation Accuracy: 10.37%\n",
            "Epoch 8 - Validation Accuracy: 9.93%\n",
            "Epoch 9 - Validation Accuracy: 10.15%\n",
            "Epoch 10 - Validation Accuracy: 10.16%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.06%\n",
            "Epoch 2 - Validation Accuracy: 10.50%\n",
            "Epoch 3 - Validation Accuracy: 11.97%\n",
            "Epoch 4 - Validation Accuracy: 15.28%\n",
            "Epoch 5 - Validation Accuracy: 15.86%\n",
            "Epoch 6 - Validation Accuracy: 11.99%\n",
            "Epoch 7 - Validation Accuracy: 12.13%\n",
            "Epoch 8 - Validation Accuracy: 11.79%\n",
            "Epoch 9 - Validation Accuracy: 10.87%\n",
            "Epoch 10 - Validation Accuracy: 10.51%\n",
            "Validation Accuracy after round 5: 10.64%\n",
            "Round 6/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 11.95%\n",
            "Epoch 2 - Validation Accuracy: 13.33%\n",
            "Epoch 3 - Validation Accuracy: 13.94%\n",
            "Epoch 4 - Validation Accuracy: 14.69%\n",
            "Epoch 5 - Validation Accuracy: 15.15%\n",
            "Epoch 6 - Validation Accuracy: 14.32%\n",
            "Epoch 7 - Validation Accuracy: 14.57%\n",
            "Epoch 8 - Validation Accuracy: 14.35%\n",
            "Epoch 9 - Validation Accuracy: 13.62%\n",
            "Epoch 10 - Validation Accuracy: 14.12%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.25%\n",
            "Epoch 2 - Validation Accuracy: 10.08%\n",
            "Epoch 3 - Validation Accuracy: 10.07%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Epoch 6 - Validation Accuracy: 10.03%\n",
            "Epoch 7 - Validation Accuracy: 10.04%\n",
            "Epoch 8 - Validation Accuracy: 10.04%\n",
            "Epoch 9 - Validation Accuracy: 10.02%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.13%\n",
            "Epoch 2 - Validation Accuracy: 10.18%\n",
            "Epoch 3 - Validation Accuracy: 10.07%\n",
            "Epoch 4 - Validation Accuracy: 10.06%\n",
            "Epoch 5 - Validation Accuracy: 10.01%\n",
            "Epoch 6 - Validation Accuracy: 10.01%\n",
            "Epoch 7 - Validation Accuracy: 10.01%\n",
            "Epoch 8 - Validation Accuracy: 10.00%\n",
            "Epoch 9 - Validation Accuracy: 10.00%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 11.39%\n",
            "Epoch 2 - Validation Accuracy: 10.46%\n",
            "Epoch 3 - Validation Accuracy: 10.05%\n",
            "Epoch 4 - Validation Accuracy: 10.02%\n",
            "Epoch 5 - Validation Accuracy: 9.99%\n",
            "Epoch 6 - Validation Accuracy: 9.96%\n",
            "Epoch 7 - Validation Accuracy: 9.92%\n",
            "Epoch 8 - Validation Accuracy: 9.96%\n",
            "Epoch 9 - Validation Accuracy: 9.94%\n",
            "Epoch 10 - Validation Accuracy: 9.95%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 11.21%\n",
            "Epoch 2 - Validation Accuracy: 12.55%\n",
            "Epoch 3 - Validation Accuracy: 15.17%\n",
            "Epoch 4 - Validation Accuracy: 16.59%\n",
            "Epoch 5 - Validation Accuracy: 14.23%\n",
            "Epoch 6 - Validation Accuracy: 14.32%\n",
            "Epoch 7 - Validation Accuracy: 12.38%\n",
            "Epoch 8 - Validation Accuracy: 12.18%\n",
            "Epoch 9 - Validation Accuracy: 12.74%\n",
            "Epoch 10 - Validation Accuracy: 11.62%\n",
            "Validation Accuracy after round 6: 11.91%\n",
            "Round 7/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 12.47%\n",
            "Epoch 2 - Validation Accuracy: 12.88%\n",
            "Epoch 3 - Validation Accuracy: 13.75%\n",
            "Epoch 4 - Validation Accuracy: 15.46%\n",
            "Epoch 5 - Validation Accuracy: 15.45%\n",
            "Epoch 6 - Validation Accuracy: 15.28%\n",
            "Epoch 7 - Validation Accuracy: 14.93%\n",
            "Epoch 8 - Validation Accuracy: 15.20%\n",
            "Epoch 9 - Validation Accuracy: 15.08%\n",
            "Epoch 10 - Validation Accuracy: 15.58%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 11.30%\n",
            "Epoch 2 - Validation Accuracy: 11.22%\n",
            "Epoch 3 - Validation Accuracy: 10.92%\n",
            "Epoch 4 - Validation Accuracy: 10.68%\n",
            "Epoch 5 - Validation Accuracy: 10.26%\n",
            "Epoch 6 - Validation Accuracy: 10.18%\n",
            "Epoch 7 - Validation Accuracy: 10.08%\n",
            "Epoch 8 - Validation Accuracy: 10.05%\n",
            "Epoch 9 - Validation Accuracy: 10.01%\n",
            "Epoch 10 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 11.84%\n",
            "Epoch 2 - Validation Accuracy: 11.68%\n",
            "Epoch 3 - Validation Accuracy: 11.44%\n",
            "Epoch 4 - Validation Accuracy: 11.25%\n",
            "Epoch 5 - Validation Accuracy: 11.21%\n",
            "Epoch 6 - Validation Accuracy: 10.79%\n",
            "Epoch 7 - Validation Accuracy: 10.77%\n",
            "Epoch 8 - Validation Accuracy: 10.67%\n",
            "Epoch 9 - Validation Accuracy: 10.65%\n",
            "Epoch 10 - Validation Accuracy: 10.59%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 12.41%\n",
            "Epoch 2 - Validation Accuracy: 13.12%\n",
            "Epoch 3 - Validation Accuracy: 12.93%\n",
            "Epoch 4 - Validation Accuracy: 11.90%\n",
            "Epoch 5 - Validation Accuracy: 11.98%\n",
            "Epoch 6 - Validation Accuracy: 11.71%\n",
            "Epoch 7 - Validation Accuracy: 11.21%\n",
            "Epoch 8 - Validation Accuracy: 11.11%\n",
            "Epoch 9 - Validation Accuracy: 11.07%\n",
            "Epoch 10 - Validation Accuracy: 10.85%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 12.65%\n",
            "Epoch 2 - Validation Accuracy: 13.58%\n",
            "Epoch 3 - Validation Accuracy: 14.69%\n",
            "Epoch 4 - Validation Accuracy: 16.13%\n",
            "Epoch 5 - Validation Accuracy: 16.64%\n",
            "Epoch 6 - Validation Accuracy: 16.72%\n",
            "Epoch 7 - Validation Accuracy: 15.29%\n",
            "Epoch 8 - Validation Accuracy: 13.14%\n",
            "Epoch 9 - Validation Accuracy: 12.77%\n",
            "Epoch 10 - Validation Accuracy: 12.63%\n",
            "Validation Accuracy after round 7: 13.10%\n",
            "Round 8/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 13.89%\n",
            "Epoch 2 - Validation Accuracy: 15.16%\n",
            "Epoch 3 - Validation Accuracy: 16.30%\n",
            "Epoch 4 - Validation Accuracy: 16.08%\n",
            "Epoch 5 - Validation Accuracy: 15.89%\n",
            "Epoch 6 - Validation Accuracy: 15.83%\n",
            "Epoch 7 - Validation Accuracy: 15.90%\n",
            "Epoch 8 - Validation Accuracy: 15.90%\n",
            "Epoch 9 - Validation Accuracy: 16.01%\n",
            "Epoch 10 - Validation Accuracy: 15.92%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 12.55%\n",
            "Epoch 2 - Validation Accuracy: 11.90%\n",
            "Epoch 3 - Validation Accuracy: 11.54%\n",
            "Epoch 4 - Validation Accuracy: 11.22%\n",
            "Epoch 5 - Validation Accuracy: 10.98%\n",
            "Epoch 6 - Validation Accuracy: 10.64%\n",
            "Epoch 7 - Validation Accuracy: 10.42%\n",
            "Epoch 8 - Validation Accuracy: 10.18%\n",
            "Epoch 9 - Validation Accuracy: 10.20%\n",
            "Epoch 10 - Validation Accuracy: 10.09%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 12.64%\n",
            "Epoch 2 - Validation Accuracy: 12.53%\n",
            "Epoch 3 - Validation Accuracy: 12.43%\n",
            "Epoch 4 - Validation Accuracy: 12.15%\n",
            "Epoch 5 - Validation Accuracy: 11.65%\n",
            "Epoch 6 - Validation Accuracy: 11.48%\n",
            "Epoch 7 - Validation Accuracy: 11.48%\n",
            "Epoch 8 - Validation Accuracy: 11.44%\n",
            "Epoch 9 - Validation Accuracy: 11.39%\n",
            "Epoch 10 - Validation Accuracy: 11.25%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 13.19%\n",
            "Epoch 2 - Validation Accuracy: 13.26%\n",
            "Epoch 3 - Validation Accuracy: 12.50%\n",
            "Epoch 4 - Validation Accuracy: 12.28%\n",
            "Epoch 5 - Validation Accuracy: 12.09%\n",
            "Epoch 6 - Validation Accuracy: 12.24%\n",
            "Epoch 7 - Validation Accuracy: 11.73%\n",
            "Epoch 8 - Validation Accuracy: 11.47%\n",
            "Epoch 9 - Validation Accuracy: 11.27%\n",
            "Epoch 10 - Validation Accuracy: 11.08%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 14.05%\n",
            "Epoch 2 - Validation Accuracy: 14.84%\n",
            "Epoch 3 - Validation Accuracy: 15.69%\n",
            "Epoch 4 - Validation Accuracy: 16.39%\n",
            "Epoch 5 - Validation Accuracy: 16.99%\n",
            "Epoch 6 - Validation Accuracy: 17.28%\n",
            "Epoch 7 - Validation Accuracy: 15.77%\n",
            "Epoch 8 - Validation Accuracy: 13.32%\n",
            "Epoch 9 - Validation Accuracy: 12.83%\n",
            "Epoch 10 - Validation Accuracy: 12.79%\n",
            "Validation Accuracy after round 8: 13.95%\n",
            "Round 9/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 14.24%\n",
            "Epoch 2 - Validation Accuracy: 14.62%\n",
            "Epoch 3 - Validation Accuracy: 15.03%\n",
            "Epoch 4 - Validation Accuracy: 15.93%\n",
            "Epoch 5 - Validation Accuracy: 16.15%\n",
            "Epoch 6 - Validation Accuracy: 16.28%\n",
            "Epoch 7 - Validation Accuracy: 16.13%\n",
            "Epoch 8 - Validation Accuracy: 16.35%\n",
            "Epoch 9 - Validation Accuracy: 16.26%\n",
            "Epoch 10 - Validation Accuracy: 16.51%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 13.51%\n",
            "Epoch 2 - Validation Accuracy: 13.21%\n",
            "Epoch 3 - Validation Accuracy: 12.83%\n",
            "Epoch 4 - Validation Accuracy: 12.61%\n",
            "Epoch 5 - Validation Accuracy: 12.52%\n",
            "Epoch 6 - Validation Accuracy: 12.21%\n",
            "Epoch 7 - Validation Accuracy: 12.06%\n",
            "Epoch 8 - Validation Accuracy: 11.76%\n",
            "Epoch 9 - Validation Accuracy: 11.53%\n",
            "Epoch 10 - Validation Accuracy: 11.67%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 13.97%\n",
            "Epoch 2 - Validation Accuracy: 13.62%\n",
            "Epoch 3 - Validation Accuracy: 13.32%\n",
            "Epoch 4 - Validation Accuracy: 13.37%\n",
            "Epoch 5 - Validation Accuracy: 13.13%\n",
            "Epoch 6 - Validation Accuracy: 13.07%\n",
            "Epoch 7 - Validation Accuracy: 13.04%\n",
            "Epoch 8 - Validation Accuracy: 12.79%\n",
            "Epoch 9 - Validation Accuracy: 12.58%\n",
            "Epoch 10 - Validation Accuracy: 12.57%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 14.01%\n",
            "Epoch 2 - Validation Accuracy: 14.21%\n",
            "Epoch 3 - Validation Accuracy: 14.16%\n",
            "Epoch 4 - Validation Accuracy: 13.99%\n",
            "Epoch 5 - Validation Accuracy: 13.88%\n",
            "Epoch 6 - Validation Accuracy: 12.82%\n",
            "Epoch 7 - Validation Accuracy: 12.83%\n",
            "Epoch 8 - Validation Accuracy: 12.54%\n",
            "Epoch 9 - Validation Accuracy: 12.12%\n",
            "Epoch 10 - Validation Accuracy: 12.15%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 14.23%\n",
            "Epoch 2 - Validation Accuracy: 14.44%\n",
            "Epoch 3 - Validation Accuracy: 14.70%\n",
            "Epoch 4 - Validation Accuracy: 15.08%\n",
            "Epoch 5 - Validation Accuracy: 16.11%\n",
            "Epoch 6 - Validation Accuracy: 16.68%\n",
            "Epoch 7 - Validation Accuracy: 17.23%\n",
            "Epoch 8 - Validation Accuracy: 17.44%\n",
            "Epoch 9 - Validation Accuracy: 17.92%\n",
            "Epoch 10 - Validation Accuracy: 17.84%\n",
            "Validation Accuracy after round 9: 14.29%\n",
            "Round 10/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 14.76%\n",
            "Epoch 2 - Validation Accuracy: 14.86%\n",
            "Epoch 3 - Validation Accuracy: 16.17%\n",
            "Epoch 4 - Validation Accuracy: 16.39%\n",
            "Epoch 5 - Validation Accuracy: 16.56%\n",
            "Epoch 6 - Validation Accuracy: 16.27%\n",
            "Epoch 7 - Validation Accuracy: 16.35%\n",
            "Epoch 8 - Validation Accuracy: 16.13%\n",
            "Epoch 9 - Validation Accuracy: 16.15%\n",
            "Epoch 10 - Validation Accuracy: 16.11%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 14.05%\n",
            "Epoch 2 - Validation Accuracy: 13.75%\n",
            "Epoch 3 - Validation Accuracy: 13.44%\n",
            "Epoch 4 - Validation Accuracy: 13.02%\n",
            "Epoch 5 - Validation Accuracy: 12.64%\n",
            "Epoch 6 - Validation Accuracy: 12.60%\n",
            "Epoch 7 - Validation Accuracy: 12.36%\n",
            "Epoch 8 - Validation Accuracy: 12.22%\n",
            "Epoch 9 - Validation Accuracy: 12.07%\n",
            "Epoch 10 - Validation Accuracy: 12.09%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 14.30%\n",
            "Epoch 2 - Validation Accuracy: 14.13%\n",
            "Epoch 3 - Validation Accuracy: 14.02%\n",
            "Epoch 4 - Validation Accuracy: 14.02%\n",
            "Epoch 5 - Validation Accuracy: 13.82%\n",
            "Epoch 6 - Validation Accuracy: 13.76%\n",
            "Epoch 7 - Validation Accuracy: 13.62%\n",
            "Epoch 8 - Validation Accuracy: 13.49%\n",
            "Epoch 9 - Validation Accuracy: 13.34%\n",
            "Epoch 10 - Validation Accuracy: 13.21%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 14.30%\n",
            "Epoch 2 - Validation Accuracy: 14.33%\n",
            "Epoch 3 - Validation Accuracy: 14.62%\n",
            "Epoch 4 - Validation Accuracy: 14.37%\n",
            "Epoch 5 - Validation Accuracy: 13.34%\n",
            "Epoch 6 - Validation Accuracy: 12.98%\n",
            "Epoch 7 - Validation Accuracy: 12.96%\n",
            "Epoch 8 - Validation Accuracy: 12.55%\n",
            "Epoch 9 - Validation Accuracy: 12.58%\n",
            "Epoch 10 - Validation Accuracy: 12.36%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 14.34%\n",
            "Epoch 2 - Validation Accuracy: 14.64%\n",
            "Epoch 3 - Validation Accuracy: 14.95%\n",
            "Epoch 4 - Validation Accuracy: 15.56%\n",
            "Epoch 5 - Validation Accuracy: 16.00%\n",
            "Epoch 6 - Validation Accuracy: 16.39%\n",
            "Epoch 7 - Validation Accuracy: 16.98%\n",
            "Epoch 8 - Validation Accuracy: 17.66%\n",
            "Epoch 9 - Validation Accuracy: 18.13%\n",
            "Epoch 10 - Validation Accuracy: 18.54%\n",
            "Validation Accuracy after round 10: 14.59%\n",
            "Final validation accuracies over rounds: [10.0, 10.0, 10.0, 10.08, 10.64, 11.91, 13.1, 13.95, 14.29, 14.59]\n",
            "CPU times: user 54min 56s, sys: 7.34 s, total: 55min 4s\n",
            "Wall time: 55min 27s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "\n",
        "# Define the neural network model (Classification Model)\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess CIFAR-10 dataset\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split training data among 5 clients\n",
        "def split_data(dataset, num_clients=5):\n",
        "    split_size = len(dataset) // num_clients\n",
        "    lengths = [split_size] * num_clients\n",
        "    if len(dataset) % num_clients != 0:\n",
        "        lengths[-1] += len(dataset) % num_clients\n",
        "    return random_split(dataset, lengths)\n",
        "\n",
        "# Create DataLoaders for clients\n",
        "def create_client_loaders(client_datasets, batch_size=128):\n",
        "    return [DataLoader(dataset, batch_size=batch_size, shuffle=True) for dataset in client_datasets]\n",
        "\n",
        "client_datasets = split_data(train_dataset)\n",
        "client_loaders = create_client_loaders(client_datasets)\n",
        "\n",
        "# DataLoader for validation (test) set\n",
        "val_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Train function for one client\n",
        "def train_client(model, train_loader, criterion, optimizer, scheduler, val_loader, epochs=1):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "        # Validate the model after every epoch\n",
        "        val_acc = validate_model(model, val_loader)\n",
        "        print(f\"Epoch {epoch + 1} - Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "# Federated averaging function (FedAvg)\n",
        "def federated_avg(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.mean(torch.stack([client_model.state_dict()[key].float() for client_model in client_models]), dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Validation function\n",
        "def validate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Initialize models for clients and global model\n",
        "global_model = Net()\n",
        "client_models = [Net() for _ in range(5)]\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training settings\n",
        "num_rounds = 10  # Total number of communication rounds\n",
        "num_epochs_per_client = 5  # Number of epochs per client per round (classification model train = 10)\n",
        "\n",
        "# Optimizer and scheduler setup (as per Table 2)\n",
        "optimizer_list = [optim.SGD(client_model.parameters(), lr=0.001, momentum=0.9) for client_model in client_models]\n",
        "scheduler_list = [optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5) for optimizer in optimizer_list]\n",
        "\n",
        "# Training loop\n",
        "FedAvg_accuracy = []\n",
        "\n",
        "for round_num in range(num_rounds):\n",
        "    print(f\"Round {round_num + 1}/{num_rounds}\")\n",
        "\n",
        "    # Train each client model on its respective data and print validation accuracy after each epoch\n",
        "    for client_idx, client_loader in enumerate(client_loaders):\n",
        "        print(f\"Training client {client_idx + 1}\")\n",
        "        train_client(client_models[client_idx], client_loader, criterion, optimizer_list[client_idx], scheduler_list[client_idx], val_loader, epochs=num_epochs_per_client)\n",
        "\n",
        "    # Perform FedAvg (aggregate models)\n",
        "    federated_avg(global_model, client_models)\n",
        "\n",
        "    # Update client models with the aggregated global model\n",
        "    for client_model in client_models:\n",
        "        client_model.load_state_dict(global_model.state_dict())\n",
        "\n",
        "    # Validate the global model after each round\n",
        "    val_acc = validate_model(global_model, val_loader)\n",
        "    FedAvg_accuracy.append(val_acc)\n",
        "    print(f\"Validation Accuracy after round {round_num + 1}: {val_acc:.2f}%\")\n",
        "\n",
        "# After all rounds, print the final validation accuracies\n",
        "print(\"Final validation accuracies over rounds:\", FedAvg_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4v8veA00cRSw",
        "outputId": "08fcbafa-e1c3-4b5a-a36d-97f653f143af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 9.90%\n",
            "Epoch 2 - Validation Accuracy: 10.10%\n",
            "Epoch 3 - Validation Accuracy: 10.18%\n",
            "Epoch 4 - Validation Accuracy: 10.55%\n",
            "Epoch 5 - Validation Accuracy: 12.33%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.03%\n",
            "Epoch 2 - Validation Accuracy: 10.03%\n",
            "Epoch 3 - Validation Accuracy: 10.29%\n",
            "Epoch 4 - Validation Accuracy: 10.77%\n",
            "Epoch 5 - Validation Accuracy: 11.97%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.01%\n",
            "Epoch 2 - Validation Accuracy: 10.19%\n",
            "Epoch 3 - Validation Accuracy: 10.81%\n",
            "Epoch 4 - Validation Accuracy: 11.85%\n",
            "Epoch 5 - Validation Accuracy: 13.15%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.64%\n",
            "Epoch 2 - Validation Accuracy: 11.81%\n",
            "Epoch 3 - Validation Accuracy: 13.70%\n",
            "Epoch 4 - Validation Accuracy: 15.14%\n",
            "Epoch 5 - Validation Accuracy: 15.34%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 13.04%\n",
            "Epoch 2 - Validation Accuracy: 15.45%\n",
            "Epoch 3 - Validation Accuracy: 17.77%\n",
            "Epoch 4 - Validation Accuracy: 18.80%\n",
            "Epoch 5 - Validation Accuracy: 19.81%\n",
            "Validation Accuracy after round 1: 10.05%\n",
            "Round 2/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.02%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 9.99%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.01%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.49%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 2: 10.48%\n",
            "Round 3/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.04%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 9.99%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.06%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 15.33%\n",
            "Epoch 4 - Validation Accuracy: 10.81%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.69%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 3: 10.03%\n",
            "Round 4/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.22%\n",
            "Epoch 2 - Validation Accuracy: 11.36%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 15.38%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 4: 10.76%\n",
            "Round 5/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.04%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.01%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.01%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 11.03%\n",
            "Epoch 2 - Validation Accuracy: 10.06%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 5: 10.10%\n",
            "Round 6/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.07%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.38%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 13.60%\n",
            "Epoch 5 - Validation Accuracy: 11.10%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.68%\n",
            "Epoch 2 - Validation Accuracy: 10.01%\n",
            "Epoch 3 - Validation Accuracy: 11.32%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.21%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 9.98%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.07%\n",
            "Epoch 4 - Validation Accuracy: 10.03%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 6: 10.19%\n",
            "Round 7/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.01%\n",
            "Epoch 2 - Validation Accuracy: 10.19%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.03%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 11.05%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 13.82%\n",
            "Epoch 3 - Validation Accuracy: 10.03%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 7: 9.97%\n",
            "Round 8/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.02%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.02%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.29%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 16.04%\n",
            "Epoch 3 - Validation Accuracy: 10.13%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 14.08%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 8: 11.19%\n",
            "Round 9/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 12.70%\n",
            "Epoch 2 - Validation Accuracy: 9.99%\n",
            "Epoch 3 - Validation Accuracy: 10.09%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.03%\n",
            "Epoch 2 - Validation Accuracy: 10.05%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.38%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 12.15%\n",
            "Epoch 2 - Validation Accuracy: 16.06%\n",
            "Epoch 3 - Validation Accuracy: 12.88%\n",
            "Epoch 4 - Validation Accuracy: 10.40%\n",
            "Epoch 5 - Validation Accuracy: 10.02%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 15.07%\n",
            "Epoch 2 - Validation Accuracy: 16.19%\n",
            "Epoch 3 - Validation Accuracy: 14.22%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 9: 11.09%\n",
            "Round 10/10\n",
            "Training client 1\n",
            "Epoch 1 - Validation Accuracy: 11.45%\n",
            "Epoch 2 - Validation Accuracy: 10.03%\n",
            "Epoch 3 - Validation Accuracy: 9.99%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 2\n",
            "Epoch 1 - Validation Accuracy: 10.00%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 3\n",
            "Epoch 1 - Validation Accuracy: 10.07%\n",
            "Epoch 2 - Validation Accuracy: 10.00%\n",
            "Epoch 3 - Validation Accuracy: 10.00%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 4\n",
            "Epoch 1 - Validation Accuracy: 11.29%\n",
            "Epoch 2 - Validation Accuracy: 15.96%\n",
            "Epoch 3 - Validation Accuracy: 13.47%\n",
            "Epoch 4 - Validation Accuracy: 11.05%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Training client 5\n",
            "Epoch 1 - Validation Accuracy: 9.99%\n",
            "Epoch 2 - Validation Accuracy: 14.38%\n",
            "Epoch 3 - Validation Accuracy: 10.98%\n",
            "Epoch 4 - Validation Accuracy: 10.00%\n",
            "Epoch 5 - Validation Accuracy: 10.00%\n",
            "Validation Accuracy after round 10: 12.18%\n",
            "Final validation accuracies over rounds: [10.05, 10.48, 10.03, 10.76, 10.1, 10.19, 9.97, 11.19, 11.09, 12.18]\n",
            "CPU times: user 28min 16s, sys: 3.4 s, total: 28min 19s\n",
            "Wall time: 28min 24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision.datasets import CIFAR10\n",
        "from typing import Dict\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Define CNN Classification Model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # Fixed error here\n",
        "    ]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Split dataset for clients\n",
        "def initialize_clients(dataset, num_clients=5):\n",
        "    data_size = len(dataset) // num_clients\n",
        "    client_datasets = [\n",
        "        Subset(dataset, list(range(i * data_size, (i + 1) * data_size)))\n",
        "        for i in range(num_clients)\n",
        "    ]\n",
        "    return client_datasets\n",
        "\n",
        "# Initialize clients\n",
        "num_clients = 5\n",
        "client_datasets = initialize_clients(full_dataset, num_clients=num_clients)\n",
        "client_loaders = {\n",
        "    f\"client_{i}\": DataLoader(client_datasets[i], batch_size=128, shuffle=True)\n",
        "    for i in range(num_clients)\n",
        "}\n",
        "\n",
        "# Define training function\n",
        "def train_model(net, dataloader, epochs, lr=0.001, momentum=0.9, step_size=20, gamma=0.5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "        scheduler.step()\n",
        "\n",
        "# Aggregate models\n",
        "def average_weights(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.stack(\n",
        "            [client_model.state_dict()[key] for client_model in client_models]\n",
        "        ).mean(0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Evaluate the model\n",
        "def evaluate_model(net, dataloader):\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Federated training procedure\n",
        "def federated_training(\n",
        "    num_rounds=10, num_epochs=10, lr=0.001, momentum=0.9, step_size=20, gamma=0.5\n",
        "):\n",
        "    global_model = Net()\n",
        "    client_models = [Net() for _ in range(num_clients)]\n",
        "    test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
        "\n",
        "    for rnd in range(num_rounds):\n",
        "        print(f\"Round {rnd + 1}/{num_rounds}\")\n",
        "        for i, client_loader in enumerate(client_loaders.values()):\n",
        "            client_models[i].load_state_dict(global_model.state_dict())\n",
        "            train_model(client_models[i], client_loader, epochs=num_epochs, lr=lr, momentum=momentum, step_size=step_size, gamma=gamma)\n",
        "\n",
        "        # Average weights to update global model\n",
        "        average_weights(global_model, client_models)\n",
        "\n",
        "        # Evaluate the global model\n",
        "        accuracy = evaluate_model(global_model, test_loader)\n",
        "        print(f\"Test Accuracy after round {rnd + 1}: {accuracy:.2f}%\")\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save(global_model.state_dict(), \"fedavg_cifar10.pth\")\n",
        "\n",
        "# Run federated training\n",
        "if __name__ == \"__main__\":\n",
        "    federated_training()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaQ28TV7HiBo",
        "outputId": "c384f479-5f3f-436c-acd7-06d7d4e9c9b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 84190379.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Test Accuracy after round 1: 12.24%\n",
            "Round 2/10\n",
            "Test Accuracy after round 2: 23.14%\n",
            "Round 3/10\n",
            "Test Accuracy after round 3: 30.56%\n",
            "Round 4/10\n",
            "Test Accuracy after round 4: 38.06%\n",
            "Round 5/10\n",
            "Test Accuracy after round 5: 42.20%\n",
            "Round 6/10\n",
            "Test Accuracy after round 6: 45.16%\n",
            "Round 7/10\n",
            "Test Accuracy after round 7: 47.80%\n",
            "Round 8/10\n",
            "Test Accuracy after round 8: 49.74%\n",
            "Round 9/10\n",
            "Test Accuracy after round 9: 51.04%\n",
            "Round 10/10\n",
            "Test Accuracy after round 10: 51.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Define CIFAR-10 dataset and transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = int(0.8 * len(train_set))\n",
        "val_size = len(train_set) - train_size\n",
        "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
        "\n",
        "# Define DataLoader\n",
        "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define training function with validation accuracy\n",
        "def train_model(\n",
        "    net, train_loader, val_loader, epochs, lr=0.001, momentum=0.9, step_size=20, gamma=0.5\n",
        "):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        net.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "\n",
        "        # Print results for the epoch\n",
        "        print(\n",
        "            f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {epoch_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%\"\n",
        "        )\n",
        "\n",
        "# Define function to average weights during federated training\n",
        "def average_weights(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.stack(\n",
        "            [client_models[i].state_dict()[key] for i in range(len(client_models))]\n",
        "        ).mean(dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(net, test_loader):\n",
        "    net.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Define function to initialize clients\n",
        "def initialize_clients(num_clients, train_set):\n",
        "    client_loaders = {}\n",
        "    dataset_size = len(train_set)\n",
        "    indices = list(range(dataset_size))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    split_size = dataset_size // num_clients\n",
        "    for i in range(num_clients):\n",
        "        client_indices = indices[i * split_size: (i + 1) * split_size]\n",
        "        client_subset = torch.utils.data.Subset(train_set, client_indices)\n",
        "        client_loaders[f\"client_{i}\"] = DataLoader(client_subset, batch_size=128, shuffle=True)\n",
        "    return client_loaders\n",
        "\n",
        "# Federated training procedure\n",
        "def federated_training(\n",
        "    num_rounds=10, num_epochs=10, num_clients=5, lr=0.001, momentum=0.9, step_size=20, gamma=0.5\n",
        "):\n",
        "    global_model = Net()\n",
        "    client_models = [Net() for _ in range(num_clients)]\n",
        "    client_loaders = initialize_clients(num_clients, train_set)\n",
        "\n",
        "    for rnd in range(num_rounds):\n",
        "        print(f\"Round {rnd + 1}/{num_rounds}\")\n",
        "        for i, client_loader in enumerate(client_loaders.values()):\n",
        "            print(f\"Training Client {i + 1}\")\n",
        "            client_models[i].load_state_dict(global_model.state_dict())\n",
        "            train_model(\n",
        "                client_models[i],\n",
        "                client_loader,\n",
        "                val_loader,\n",
        "                epochs=num_epochs,\n",
        "                lr=lr,\n",
        "                momentum=momentum,\n",
        "                step_size=step_size,\n",
        "                gamma=gamma,\n",
        "            )\n",
        "\n",
        "        # Average weights to update global model\n",
        "        average_weights(global_model, client_models)\n",
        "\n",
        "        # Evaluate the global model\n",
        "        accuracy = evaluate_model(global_model, test_loader)\n",
        "        print(f\"Round {rnd + 1} Complete: Test Accuracy: {accuracy:.2f}%\\n\")\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save(global_model.state_dict(), \"fedavg_cifar10.pth\")\n",
        "\n",
        "# Run federated training\n",
        "if __name__ == \"__main__\":\n",
        "    federated_training()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "3CiqTa9rPSQT",
        "outputId": "cd2024c8-34e5-41bf-80a3-260804a854a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 75.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Round 1/10\n",
            "Training Client 1\n",
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 9.68%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 9.69%\n",
            "Epoch [3/10], Training Loss: 2.303, Validation Accuracy: 9.69%\n",
            "Epoch [4/10], Training Loss: 2.302, Validation Accuracy: 9.67%\n",
            "Epoch [5/10], Training Loss: 2.302, Validation Accuracy: 9.69%\n",
            "Epoch [6/10], Training Loss: 2.301, Validation Accuracy: 9.71%\n",
            "Epoch [7/10], Training Loss: 2.301, Validation Accuracy: 9.76%\n",
            "Epoch [8/10], Training Loss: 2.300, Validation Accuracy: 9.92%\n",
            "Epoch [9/10], Training Loss: 2.299, Validation Accuracy: 9.97%\n",
            "Epoch [10/10], Training Loss: 2.298, Validation Accuracy: 10.59%\n",
            "Training Client 2\n",
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 9.69%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 9.69%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d8c83785360a>\u001b[0m in \u001b[0;36m<cell line: 159>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;31m# Run federated training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mfederated_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-d8c83785360a>\u001b[0m in \u001b[0;36mfederated_training\u001b[0;34m(num_rounds, num_epochs, num_clients, lr, momentum, step_size, gamma)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Client {i + 1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mclient_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             train_model(\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0mclient_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mclient_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d8c83785360a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, train_loader, val_loader, epochs, lr, momentum, step_size, gamma)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d8c83785360a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import random\n",
        "\n",
        "# Define CIFAR-10 dataset and transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Define DataLoader for test dataset\n",
        "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "# Define the classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Define training function for a single client\n",
        "def train_client_model(net, data_loader, val_loader, epochs, lr=0.001, momentum=0.9, step_size=20, gamma=0.5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in data_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_loss = running_loss / len(data_loader)\n",
        "\n",
        "        # Validation phase\n",
        "        net.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                outputs = net(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {epoch_loss:.3f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "    return net\n",
        "\n",
        "# Define function to average weights during federated training\n",
        "def average_weights(global_model, client_models):\n",
        "    global_state_dict = global_model.state_dict()\n",
        "    for key in global_state_dict.keys():\n",
        "        global_state_dict[key] = torch.stack(\n",
        "            [client_models[i].state_dict()[key] for i in range(len(client_models))]\n",
        "        ).mean(dim=0)\n",
        "    global_model.load_state_dict(global_state_dict)\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate_model(net, test_loader):\n",
        "    net.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = net(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "\n",
        "# Define function to initialize clients\n",
        "def initialize_clients(num_clients, train_set):\n",
        "    client_loaders = {}\n",
        "    dataset_size = len(train_set)\n",
        "    indices = list(range(dataset_size))\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    split_size = dataset_size // num_clients\n",
        "    for i in range(num_clients):\n",
        "        client_indices = indices[i * split_size: (i + 1) * split_size]\n",
        "        client_subset = torch.utils.data.Subset(train_set, client_indices)\n",
        "        client_loaders[f\"client_{i}\"] = DataLoader(client_subset, batch_size=128, shuffle=True)\n",
        "    return client_loaders\n",
        "\n",
        "# Federated training procedure\n",
        "def federated_training(\n",
        "    num_rounds=10, num_epochs=10, num_clients=5, lr=0.001, momentum=0.9, step_size=20, gamma=0.5\n",
        "):\n",
        "    global_model = Net()\n",
        "    client_models = [Net() for _ in range(num_clients)]\n",
        "\n",
        "    # Split train_set into 80% training and 20% validation\n",
        "    train_size = int(0.8 * len(train_set))\n",
        "    val_size = len(train_set) - train_size\n",
        "    train_subset, val_subset = random_split(train_set, [train_size, val_size])\n",
        "\n",
        "    # Initialize client-specific DataLoaders\n",
        "    client_loaders = initialize_clients(num_clients, train_subset)\n",
        "    val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
        "\n",
        "    for rnd in range(num_rounds):\n",
        "        print(f\"--- Round {rnd + 1}/{num_rounds} ---\")\n",
        "        for i, client_loader in enumerate(client_loaders.values()):\n",
        "            print(f\"Client {i + 1}:\")\n",
        "            client_models[i].load_state_dict(global_model.state_dict())  # Load global model\n",
        "            train_client_model(\n",
        "                client_models[i],\n",
        "                client_loader,\n",
        "                val_loader,\n",
        "                epochs=num_epochs,\n",
        "                lr=lr,\n",
        "                momentum=momentum,\n",
        "                step_size=step_size,\n",
        "                gamma=gamma,\n",
        "            )\n",
        "\n",
        "        # Average weights to update global model\n",
        "        average_weights(global_model, client_models)\n",
        "\n",
        "        # Evaluate the global model\n",
        "        accuracy = evaluate_model(global_model, test_loader)\n",
        "        print(f\"--- Round {rnd + 1} Complete: Global Test Accuracy: {accuracy:.2f}% ---\\n\")\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save(global_model.state_dict(), \"fedavg_cifar10.pth\")\n",
        "\n",
        "# Run federated training\n",
        "if __name__ == \"__main__\":\n",
        "    federated_training()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SwCmW2aRDNo",
        "outputId": "9411b5ba-2347-45ec-b3ac-3f884bc90fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "--- Round 1/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 11.41%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.10%\n",
            "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.96%\n",
            "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 9.85%\n",
            "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 9.85%\n",
            "Epoch [6/10], Training Loss: 2.302, Validation Accuracy: 9.82%\n",
            "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 9.83%\n",
            "Epoch [8/10], Training Loss: 2.301, Validation Accuracy: 9.83%\n",
            "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 9.85%\n",
            "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.89%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 11.49%\n",
            "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 11.37%\n",
            "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 11.23%\n",
            "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 11.50%\n",
            "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 12.31%\n",
            "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 11.58%\n",
            "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 10.71%\n",
            "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 10.07%\n",
            "Epoch [9/10], Training Loss: 2.302, Validation Accuracy: 10.00%\n",
            "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.93%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 11.48%\n",
            "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 10.44%\n",
            "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 10.58%\n",
            "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 10.39%\n",
            "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 10.28%\n",
            "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 10.47%\n",
            "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 11.27%\n",
            "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 11.55%\n",
            "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 12.25%\n",
            "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 12.64%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 10.39%\n",
            "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 9.95%\n",
            "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.90%\n",
            "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 9.89%\n",
            "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 9.87%\n",
            "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 9.87%\n",
            "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 9.87%\n",
            "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 9.87%\n",
            "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 9.87%\n",
            "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.87%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 10.89%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.67%\n",
            "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.91%\n",
            "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 9.85%\n",
            "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 9.84%\n",
            "Epoch [6/10], Training Loss: 2.302, Validation Accuracy: 9.84%\n",
            "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 9.84%\n",
            "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 9.84%\n",
            "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 9.85%\n",
            "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.85%\n",
            "--- Round 1 Complete: Global Test Accuracy: 12.82% ---\n",
            "\n",
            "--- Round 2/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 12.64%\n",
            "Epoch [2/10], Training Loss: 2.300, Validation Accuracy: 12.62%\n",
            "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 11.74%\n",
            "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 12.25%\n",
            "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 12.77%\n",
            "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 13.15%\n",
            "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 13.48%\n",
            "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 14.91%\n",
            "Epoch [9/10], Training Loss: 2.294, Validation Accuracy: 15.73%\n",
            "Epoch [10/10], Training Loss: 2.293, Validation Accuracy: 16.03%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 13.97%\n",
            "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 14.24%\n",
            "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 12.69%\n",
            "Epoch [4/10], Training Loss: 2.300, Validation Accuracy: 12.68%\n",
            "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 12.96%\n",
            "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 13.94%\n",
            "Epoch [7/10], Training Loss: 2.298, Validation Accuracy: 14.58%\n",
            "Epoch [8/10], Training Loss: 2.297, Validation Accuracy: 14.44%\n",
            "Epoch [9/10], Training Loss: 2.296, Validation Accuracy: 15.77%\n",
            "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 16.67%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 13.78%\n",
            "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 13.68%\n",
            "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 13.63%\n",
            "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 14.11%\n",
            "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 14.08%\n",
            "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 14.45%\n",
            "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 14.52%\n",
            "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 14.65%\n",
            "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 15.43%\n",
            "Epoch [10/10], Training Loss: 2.293, Validation Accuracy: 16.25%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 12.48%\n",
            "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 10.35%\n",
            "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 9.97%\n",
            "Epoch [4/10], Training Loss: 2.300, Validation Accuracy: 9.96%\n",
            "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 9.94%\n",
            "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 9.98%\n",
            "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 10.27%\n",
            "Epoch [8/10], Training Loss: 2.297, Validation Accuracy: 10.51%\n",
            "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 11.47%\n",
            "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 12.15%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 13.08%\n",
            "Epoch [2/10], Training Loss: 2.300, Validation Accuracy: 12.04%\n",
            "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 10.53%\n",
            "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 10.09%\n",
            "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 10.01%\n",
            "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 10.10%\n",
            "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 10.71%\n",
            "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 11.71%\n",
            "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 13.14%\n",
            "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 13.79%\n",
            "--- Round 2 Complete: Global Test Accuracy: 18.27% ---\n",
            "\n",
            "--- Round 3/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 2.292, Validation Accuracy: 19.21%\n",
            "Epoch [2/10], Training Loss: 2.289, Validation Accuracy: 19.31%\n",
            "Epoch [3/10], Training Loss: 2.285, Validation Accuracy: 19.58%\n",
            "Epoch [4/10], Training Loss: 2.280, Validation Accuracy: 19.79%\n",
            "Epoch [5/10], Training Loss: 2.271, Validation Accuracy: 19.42%\n",
            "Epoch [6/10], Training Loss: 2.258, Validation Accuracy: 19.33%\n",
            "Epoch [7/10], Training Loss: 2.237, Validation Accuracy: 19.40%\n",
            "Epoch [8/10], Training Loss: 2.208, Validation Accuracy: 20.73%\n",
            "Epoch [9/10], Training Loss: 2.174, Validation Accuracy: 22.36%\n",
            "Epoch [10/10], Training Loss: 2.139, Validation Accuracy: 23.26%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 2.293, Validation Accuracy: 20.07%\n",
            "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 20.06%\n",
            "Epoch [3/10], Training Loss: 2.287, Validation Accuracy: 19.94%\n",
            "Epoch [4/10], Training Loss: 2.282, Validation Accuracy: 20.12%\n",
            "Epoch [5/10], Training Loss: 2.275, Validation Accuracy: 19.60%\n",
            "Epoch [6/10], Training Loss: 2.263, Validation Accuracy: 19.73%\n",
            "Epoch [7/10], Training Loss: 2.245, Validation Accuracy: 20.21%\n",
            "Epoch [8/10], Training Loss: 2.220, Validation Accuracy: 21.57%\n",
            "Epoch [9/10], Training Loss: 2.191, Validation Accuracy: 22.21%\n",
            "Epoch [10/10], Training Loss: 2.159, Validation Accuracy: 22.84%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 2.292, Validation Accuracy: 18.88%\n",
            "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 19.56%\n",
            "Epoch [3/10], Training Loss: 2.286, Validation Accuracy: 19.42%\n",
            "Epoch [4/10], Training Loss: 2.281, Validation Accuracy: 19.43%\n",
            "Epoch [5/10], Training Loss: 2.272, Validation Accuracy: 19.34%\n",
            "Epoch [6/10], Training Loss: 2.260, Validation Accuracy: 19.54%\n",
            "Epoch [7/10], Training Loss: 2.241, Validation Accuracy: 20.44%\n",
            "Epoch [8/10], Training Loss: 2.216, Validation Accuracy: 21.90%\n",
            "Epoch [9/10], Training Loss: 2.186, Validation Accuracy: 22.51%\n",
            "Epoch [10/10], Training Loss: 2.153, Validation Accuracy: 22.93%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 2.293, Validation Accuracy: 19.43%\n",
            "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 18.83%\n",
            "Epoch [3/10], Training Loss: 2.287, Validation Accuracy: 18.54%\n",
            "Epoch [4/10], Training Loss: 2.282, Validation Accuracy: 18.21%\n",
            "Epoch [5/10], Training Loss: 2.274, Validation Accuracy: 18.36%\n",
            "Epoch [6/10], Training Loss: 2.263, Validation Accuracy: 18.28%\n",
            "Epoch [7/10], Training Loss: 2.245, Validation Accuracy: 18.63%\n",
            "Epoch [8/10], Training Loss: 2.221, Validation Accuracy: 20.34%\n",
            "Epoch [9/10], Training Loss: 2.191, Validation Accuracy: 21.74%\n",
            "Epoch [10/10], Training Loss: 2.158, Validation Accuracy: 22.74%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 2.292, Validation Accuracy: 19.56%\n",
            "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 19.95%\n",
            "Epoch [3/10], Training Loss: 2.286, Validation Accuracy: 20.11%\n",
            "Epoch [4/10], Training Loss: 2.281, Validation Accuracy: 19.80%\n",
            "Epoch [5/10], Training Loss: 2.273, Validation Accuracy: 20.01%\n",
            "Epoch [6/10], Training Loss: 2.261, Validation Accuracy: 20.08%\n",
            "Epoch [7/10], Training Loss: 2.242, Validation Accuracy: 19.90%\n",
            "Epoch [8/10], Training Loss: 2.215, Validation Accuracy: 20.67%\n",
            "Epoch [9/10], Training Loss: 2.185, Validation Accuracy: 21.59%\n",
            "Epoch [10/10], Training Loss: 2.151, Validation Accuracy: 23.08%\n",
            "--- Round 3 Complete: Global Test Accuracy: 23.06% ---\n",
            "\n",
            "--- Round 4/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 2.123, Validation Accuracy: 23.62%\n",
            "Epoch [2/10], Training Loss: 2.095, Validation Accuracy: 24.08%\n",
            "Epoch [3/10], Training Loss: 2.074, Validation Accuracy: 24.89%\n",
            "Epoch [4/10], Training Loss: 2.055, Validation Accuracy: 25.16%\n",
            "Epoch [5/10], Training Loss: 2.037, Validation Accuracy: 25.46%\n",
            "Epoch [6/10], Training Loss: 2.019, Validation Accuracy: 26.37%\n",
            "Epoch [7/10], Training Loss: 2.003, Validation Accuracy: 26.70%\n",
            "Epoch [8/10], Training Loss: 1.989, Validation Accuracy: 26.71%\n",
            "Epoch [9/10], Training Loss: 1.975, Validation Accuracy: 27.61%\n",
            "Epoch [10/10], Training Loss: 1.959, Validation Accuracy: 28.35%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 2.130, Validation Accuracy: 23.02%\n",
            "Epoch [2/10], Training Loss: 2.106, Validation Accuracy: 23.54%\n",
            "Epoch [3/10], Training Loss: 2.085, Validation Accuracy: 24.30%\n",
            "Epoch [4/10], Training Loss: 2.066, Validation Accuracy: 24.99%\n",
            "Epoch [5/10], Training Loss: 2.048, Validation Accuracy: 25.57%\n",
            "Epoch [6/10], Training Loss: 2.031, Validation Accuracy: 25.95%\n",
            "Epoch [7/10], Training Loss: 2.016, Validation Accuracy: 26.64%\n",
            "Epoch [8/10], Training Loss: 2.000, Validation Accuracy: 26.96%\n",
            "Epoch [9/10], Training Loss: 1.985, Validation Accuracy: 27.72%\n",
            "Epoch [10/10], Training Loss: 1.969, Validation Accuracy: 27.77%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 2.128, Validation Accuracy: 23.18%\n",
            "Epoch [2/10], Training Loss: 2.104, Validation Accuracy: 23.43%\n",
            "Epoch [3/10], Training Loss: 2.084, Validation Accuracy: 24.32%\n",
            "Epoch [4/10], Training Loss: 2.063, Validation Accuracy: 24.56%\n",
            "Epoch [5/10], Training Loss: 2.043, Validation Accuracy: 25.59%\n",
            "Epoch [6/10], Training Loss: 2.025, Validation Accuracy: 25.91%\n",
            "Epoch [7/10], Training Loss: 2.006, Validation Accuracy: 26.04%\n",
            "Epoch [8/10], Training Loss: 1.991, Validation Accuracy: 26.88%\n",
            "Epoch [9/10], Training Loss: 1.978, Validation Accuracy: 26.82%\n",
            "Epoch [10/10], Training Loss: 1.965, Validation Accuracy: 28.16%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 2.129, Validation Accuracy: 23.28%\n",
            "Epoch [2/10], Training Loss: 2.103, Validation Accuracy: 23.73%\n",
            "Epoch [3/10], Training Loss: 2.080, Validation Accuracy: 24.24%\n",
            "Epoch [4/10], Training Loss: 2.060, Validation Accuracy: 24.78%\n",
            "Epoch [5/10], Training Loss: 2.040, Validation Accuracy: 25.62%\n",
            "Epoch [6/10], Training Loss: 2.022, Validation Accuracy: 26.06%\n",
            "Epoch [7/10], Training Loss: 2.003, Validation Accuracy: 26.75%\n",
            "Epoch [8/10], Training Loss: 1.989, Validation Accuracy: 27.31%\n",
            "Epoch [9/10], Training Loss: 1.976, Validation Accuracy: 27.89%\n",
            "Epoch [10/10], Training Loss: 1.963, Validation Accuracy: 28.33%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 2.126, Validation Accuracy: 23.25%\n",
            "Epoch [2/10], Training Loss: 2.101, Validation Accuracy: 23.19%\n",
            "Epoch [3/10], Training Loss: 2.079, Validation Accuracy: 23.92%\n",
            "Epoch [4/10], Training Loss: 2.058, Validation Accuracy: 24.87%\n",
            "Epoch [5/10], Training Loss: 2.039, Validation Accuracy: 25.44%\n",
            "Epoch [6/10], Training Loss: 2.022, Validation Accuracy: 26.08%\n",
            "Epoch [7/10], Training Loss: 2.002, Validation Accuracy: 26.21%\n",
            "Epoch [8/10], Training Loss: 1.987, Validation Accuracy: 26.57%\n",
            "Epoch [9/10], Training Loss: 1.974, Validation Accuracy: 27.85%\n",
            "Epoch [10/10], Training Loss: 1.959, Validation Accuracy: 28.01%\n",
            "--- Round 4 Complete: Global Test Accuracy: 28.61% ---\n",
            "\n",
            "--- Round 5/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 1.952, Validation Accuracy: 28.19%\n",
            "Epoch [2/10], Training Loss: 1.938, Validation Accuracy: 29.54%\n",
            "Epoch [3/10], Training Loss: 1.926, Validation Accuracy: 29.57%\n",
            "Epoch [4/10], Training Loss: 1.911, Validation Accuracy: 30.39%\n",
            "Epoch [5/10], Training Loss: 1.892, Validation Accuracy: 31.49%\n",
            "Epoch [6/10], Training Loss: 1.876, Validation Accuracy: 31.85%\n",
            "Epoch [7/10], Training Loss: 1.860, Validation Accuracy: 32.71%\n",
            "Epoch [8/10], Training Loss: 1.845, Validation Accuracy: 32.01%\n",
            "Epoch [9/10], Training Loss: 1.828, Validation Accuracy: 33.64%\n",
            "Epoch [10/10], Training Loss: 1.809, Validation Accuracy: 34.13%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 1.961, Validation Accuracy: 28.58%\n",
            "Epoch [2/10], Training Loss: 1.948, Validation Accuracy: 28.99%\n",
            "Epoch [3/10], Training Loss: 1.931, Validation Accuracy: 29.79%\n",
            "Epoch [4/10], Training Loss: 1.919, Validation Accuracy: 30.80%\n",
            "Epoch [5/10], Training Loss: 1.904, Validation Accuracy: 30.26%\n",
            "Epoch [6/10], Training Loss: 1.887, Validation Accuracy: 31.81%\n",
            "Epoch [7/10], Training Loss: 1.870, Validation Accuracy: 31.65%\n",
            "Epoch [8/10], Training Loss: 1.855, Validation Accuracy: 32.79%\n",
            "Epoch [9/10], Training Loss: 1.838, Validation Accuracy: 33.58%\n",
            "Epoch [10/10], Training Loss: 1.820, Validation Accuracy: 34.34%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 1.960, Validation Accuracy: 28.44%\n",
            "Epoch [2/10], Training Loss: 1.944, Validation Accuracy: 29.40%\n",
            "Epoch [3/10], Training Loss: 1.932, Validation Accuracy: 29.91%\n",
            "Epoch [4/10], Training Loss: 1.916, Validation Accuracy: 30.37%\n",
            "Epoch [5/10], Training Loss: 1.900, Validation Accuracy: 30.85%\n",
            "Epoch [6/10], Training Loss: 1.885, Validation Accuracy: 31.37%\n",
            "Epoch [7/10], Training Loss: 1.872, Validation Accuracy: 31.97%\n",
            "Epoch [8/10], Training Loss: 1.856, Validation Accuracy: 32.60%\n",
            "Epoch [9/10], Training Loss: 1.839, Validation Accuracy: 33.57%\n",
            "Epoch [10/10], Training Loss: 1.820, Validation Accuracy: 34.15%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 1.956, Validation Accuracy: 29.03%\n",
            "Epoch [2/10], Training Loss: 1.941, Validation Accuracy: 28.88%\n",
            "Epoch [3/10], Training Loss: 1.926, Validation Accuracy: 29.92%\n",
            "Epoch [4/10], Training Loss: 1.913, Validation Accuracy: 30.62%\n",
            "Epoch [5/10], Training Loss: 1.895, Validation Accuracy: 30.73%\n",
            "Epoch [6/10], Training Loss: 1.879, Validation Accuracy: 30.88%\n",
            "Epoch [7/10], Training Loss: 1.863, Validation Accuracy: 32.01%\n",
            "Epoch [8/10], Training Loss: 1.849, Validation Accuracy: 32.33%\n",
            "Epoch [9/10], Training Loss: 1.831, Validation Accuracy: 33.96%\n",
            "Epoch [10/10], Training Loss: 1.813, Validation Accuracy: 34.24%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 1.953, Validation Accuracy: 28.39%\n",
            "Epoch [2/10], Training Loss: 1.940, Validation Accuracy: 28.38%\n",
            "Epoch [3/10], Training Loss: 1.926, Validation Accuracy: 29.45%\n",
            "Epoch [4/10], Training Loss: 1.910, Validation Accuracy: 30.56%\n",
            "Epoch [5/10], Training Loss: 1.893, Validation Accuracy: 30.01%\n",
            "Epoch [6/10], Training Loss: 1.877, Validation Accuracy: 31.36%\n",
            "Epoch [7/10], Training Loss: 1.860, Validation Accuracy: 31.56%\n",
            "Epoch [8/10], Training Loss: 1.847, Validation Accuracy: 32.12%\n",
            "Epoch [9/10], Training Loss: 1.830, Validation Accuracy: 32.87%\n",
            "Epoch [10/10], Training Loss: 1.814, Validation Accuracy: 33.01%\n",
            "--- Round 5 Complete: Global Test Accuracy: 34.16% ---\n",
            "\n",
            "--- Round 6/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 1.808, Validation Accuracy: 34.66%\n",
            "Epoch [2/10], Training Loss: 1.792, Validation Accuracy: 34.89%\n",
            "Epoch [3/10], Training Loss: 1.775, Validation Accuracy: 35.89%\n",
            "Epoch [4/10], Training Loss: 1.757, Validation Accuracy: 35.54%\n",
            "Epoch [5/10], Training Loss: 1.744, Validation Accuracy: 36.32%\n",
            "Epoch [6/10], Training Loss: 1.726, Validation Accuracy: 37.14%\n",
            "Epoch [7/10], Training Loss: 1.715, Validation Accuracy: 37.36%\n",
            "Epoch [8/10], Training Loss: 1.694, Validation Accuracy: 37.57%\n",
            "Epoch [9/10], Training Loss: 1.686, Validation Accuracy: 38.43%\n",
            "Epoch [10/10], Training Loss: 1.674, Validation Accuracy: 38.73%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 1.813, Validation Accuracy: 34.93%\n",
            "Epoch [2/10], Training Loss: 1.795, Validation Accuracy: 34.92%\n",
            "Epoch [3/10], Training Loss: 1.780, Validation Accuracy: 36.09%\n",
            "Epoch [4/10], Training Loss: 1.762, Validation Accuracy: 36.21%\n",
            "Epoch [5/10], Training Loss: 1.747, Validation Accuracy: 36.86%\n",
            "Epoch [6/10], Training Loss: 1.729, Validation Accuracy: 37.18%\n",
            "Epoch [7/10], Training Loss: 1.711, Validation Accuracy: 37.88%\n",
            "Epoch [8/10], Training Loss: 1.697, Validation Accuracy: 37.73%\n",
            "Epoch [9/10], Training Loss: 1.681, Validation Accuracy: 38.30%\n",
            "Epoch [10/10], Training Loss: 1.668, Validation Accuracy: 39.00%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 1.817, Validation Accuracy: 34.52%\n",
            "Epoch [2/10], Training Loss: 1.797, Validation Accuracy: 35.00%\n",
            "Epoch [3/10], Training Loss: 1.782, Validation Accuracy: 35.12%\n",
            "Epoch [4/10], Training Loss: 1.768, Validation Accuracy: 36.62%\n",
            "Epoch [5/10], Training Loss: 1.746, Validation Accuracy: 36.96%\n",
            "Epoch [6/10], Training Loss: 1.728, Validation Accuracy: 37.51%\n",
            "Epoch [7/10], Training Loss: 1.714, Validation Accuracy: 37.97%\n",
            "Epoch [8/10], Training Loss: 1.696, Validation Accuracy: 38.06%\n",
            "Epoch [9/10], Training Loss: 1.680, Validation Accuracy: 37.72%\n",
            "Epoch [10/10], Training Loss: 1.667, Validation Accuracy: 38.14%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 1.809, Validation Accuracy: 34.63%\n",
            "Epoch [2/10], Training Loss: 1.790, Validation Accuracy: 35.34%\n",
            "Epoch [3/10], Training Loss: 1.774, Validation Accuracy: 35.39%\n",
            "Epoch [4/10], Training Loss: 1.757, Validation Accuracy: 36.00%\n",
            "Epoch [5/10], Training Loss: 1.737, Validation Accuracy: 36.19%\n",
            "Epoch [6/10], Training Loss: 1.720, Validation Accuracy: 37.30%\n",
            "Epoch [7/10], Training Loss: 1.707, Validation Accuracy: 37.44%\n",
            "Epoch [8/10], Training Loss: 1.690, Validation Accuracy: 38.29%\n",
            "Epoch [9/10], Training Loss: 1.678, Validation Accuracy: 38.65%\n",
            "Epoch [10/10], Training Loss: 1.665, Validation Accuracy: 38.79%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 1.806, Validation Accuracy: 34.19%\n",
            "Epoch [2/10], Training Loss: 1.789, Validation Accuracy: 34.93%\n",
            "Epoch [3/10], Training Loss: 1.774, Validation Accuracy: 35.49%\n",
            "Epoch [4/10], Training Loss: 1.759, Validation Accuracy: 35.67%\n",
            "Epoch [5/10], Training Loss: 1.742, Validation Accuracy: 35.04%\n",
            "Epoch [6/10], Training Loss: 1.729, Validation Accuracy: 36.95%\n",
            "Epoch [7/10], Training Loss: 1.715, Validation Accuracy: 37.32%\n",
            "Epoch [8/10], Training Loss: 1.700, Validation Accuracy: 37.70%\n",
            "Epoch [9/10], Training Loss: 1.691, Validation Accuracy: 38.21%\n",
            "Epoch [10/10], Training Loss: 1.669, Validation Accuracy: 38.35%\n",
            "--- Round 6 Complete: Global Test Accuracy: 39.65% ---\n",
            "\n",
            "--- Round 7/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 1.671, Validation Accuracy: 38.96%\n",
            "Epoch [2/10], Training Loss: 1.658, Validation Accuracy: 40.15%\n",
            "Epoch [3/10], Training Loss: 1.640, Validation Accuracy: 39.80%\n",
            "Epoch [4/10], Training Loss: 1.628, Validation Accuracy: 40.69%\n",
            "Epoch [5/10], Training Loss: 1.618, Validation Accuracy: 40.96%\n",
            "Epoch [6/10], Training Loss: 1.606, Validation Accuracy: 41.02%\n",
            "Epoch [7/10], Training Loss: 1.598, Validation Accuracy: 40.87%\n",
            "Epoch [8/10], Training Loss: 1.588, Validation Accuracy: 42.08%\n",
            "Epoch [9/10], Training Loss: 1.577, Validation Accuracy: 41.28%\n",
            "Epoch [10/10], Training Loss: 1.563, Validation Accuracy: 41.99%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 1.671, Validation Accuracy: 39.45%\n",
            "Epoch [2/10], Training Loss: 1.659, Validation Accuracy: 39.25%\n",
            "Epoch [3/10], Training Loss: 1.645, Validation Accuracy: 40.19%\n",
            "Epoch [4/10], Training Loss: 1.630, Validation Accuracy: 40.87%\n",
            "Epoch [5/10], Training Loss: 1.615, Validation Accuracy: 40.62%\n",
            "Epoch [6/10], Training Loss: 1.602, Validation Accuracy: 40.00%\n",
            "Epoch [7/10], Training Loss: 1.594, Validation Accuracy: 41.25%\n",
            "Epoch [8/10], Training Loss: 1.582, Validation Accuracy: 41.33%\n",
            "Epoch [9/10], Training Loss: 1.568, Validation Accuracy: 42.52%\n",
            "Epoch [10/10], Training Loss: 1.566, Validation Accuracy: 41.41%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 1.679, Validation Accuracy: 39.12%\n",
            "Epoch [2/10], Training Loss: 1.660, Validation Accuracy: 39.83%\n",
            "Epoch [3/10], Training Loss: 1.640, Validation Accuracy: 40.06%\n",
            "Epoch [4/10], Training Loss: 1.630, Validation Accuracy: 40.54%\n",
            "Epoch [5/10], Training Loss: 1.613, Validation Accuracy: 40.87%\n",
            "Epoch [6/10], Training Loss: 1.610, Validation Accuracy: 40.59%\n",
            "Epoch [7/10], Training Loss: 1.585, Validation Accuracy: 41.27%\n",
            "Epoch [8/10], Training Loss: 1.578, Validation Accuracy: 41.85%\n",
            "Epoch [9/10], Training Loss: 1.573, Validation Accuracy: 41.40%\n",
            "Epoch [10/10], Training Loss: 1.557, Validation Accuracy: 42.66%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 1.671, Validation Accuracy: 39.40%\n",
            "Epoch [2/10], Training Loss: 1.654, Validation Accuracy: 39.69%\n",
            "Epoch [3/10], Training Loss: 1.640, Validation Accuracy: 39.33%\n",
            "Epoch [4/10], Training Loss: 1.631, Validation Accuracy: 39.91%\n",
            "Epoch [5/10], Training Loss: 1.617, Validation Accuracy: 40.70%\n",
            "Epoch [6/10], Training Loss: 1.603, Validation Accuracy: 40.86%\n",
            "Epoch [7/10], Training Loss: 1.592, Validation Accuracy: 41.26%\n",
            "Epoch [8/10], Training Loss: 1.589, Validation Accuracy: 41.29%\n",
            "Epoch [9/10], Training Loss: 1.569, Validation Accuracy: 41.52%\n",
            "Epoch [10/10], Training Loss: 1.559, Validation Accuracy: 41.56%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 1.675, Validation Accuracy: 39.49%\n",
            "Epoch [2/10], Training Loss: 1.661, Validation Accuracy: 38.77%\n",
            "Epoch [3/10], Training Loss: 1.650, Validation Accuracy: 40.31%\n",
            "Epoch [4/10], Training Loss: 1.640, Validation Accuracy: 40.25%\n",
            "Epoch [5/10], Training Loss: 1.622, Validation Accuracy: 40.89%\n",
            "Epoch [6/10], Training Loss: 1.616, Validation Accuracy: 40.49%\n",
            "Epoch [7/10], Training Loss: 1.605, Validation Accuracy: 41.52%\n",
            "Epoch [8/10], Training Loss: 1.595, Validation Accuracy: 41.71%\n",
            "Epoch [9/10], Training Loss: 1.583, Validation Accuracy: 40.96%\n",
            "Epoch [10/10], Training Loss: 1.572, Validation Accuracy: 41.83%\n",
            "--- Round 7 Complete: Global Test Accuracy: 43.06% ---\n",
            "\n",
            "--- Round 8/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 1.577, Validation Accuracy: 42.83%\n",
            "Epoch [2/10], Training Loss: 1.570, Validation Accuracy: 43.51%\n",
            "Epoch [3/10], Training Loss: 1.556, Validation Accuracy: 42.55%\n",
            "Epoch [4/10], Training Loss: 1.542, Validation Accuracy: 44.05%\n",
            "Epoch [5/10], Training Loss: 1.526, Validation Accuracy: 44.08%\n",
            "Epoch [6/10], Training Loss: 1.519, Validation Accuracy: 43.71%\n",
            "Epoch [7/10], Training Loss: 1.511, Validation Accuracy: 44.44%\n",
            "Epoch [8/10], Training Loss: 1.502, Validation Accuracy: 44.02%\n",
            "Epoch [9/10], Training Loss: 1.490, Validation Accuracy: 45.35%\n",
            "Epoch [10/10], Training Loss: 1.483, Validation Accuracy: 45.05%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 1.572, Validation Accuracy: 42.75%\n",
            "Epoch [2/10], Training Loss: 1.559, Validation Accuracy: 43.37%\n",
            "Epoch [3/10], Training Loss: 1.548, Validation Accuracy: 44.09%\n",
            "Epoch [4/10], Training Loss: 1.540, Validation Accuracy: 43.65%\n",
            "Epoch [5/10], Training Loss: 1.529, Validation Accuracy: 44.56%\n",
            "Epoch [6/10], Training Loss: 1.517, Validation Accuracy: 42.70%\n",
            "Epoch [7/10], Training Loss: 1.515, Validation Accuracy: 44.30%\n",
            "Epoch [8/10], Training Loss: 1.504, Validation Accuracy: 45.44%\n",
            "Epoch [9/10], Training Loss: 1.487, Validation Accuracy: 44.83%\n",
            "Epoch [10/10], Training Loss: 1.478, Validation Accuracy: 45.73%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 1.572, Validation Accuracy: 42.43%\n",
            "Epoch [2/10], Training Loss: 1.560, Validation Accuracy: 43.52%\n",
            "Epoch [3/10], Training Loss: 1.543, Validation Accuracy: 43.09%\n",
            "Epoch [4/10], Training Loss: 1.535, Validation Accuracy: 43.96%\n",
            "Epoch [5/10], Training Loss: 1.527, Validation Accuracy: 43.67%\n",
            "Epoch [6/10], Training Loss: 1.513, Validation Accuracy: 44.10%\n",
            "Epoch [7/10], Training Loss: 1.503, Validation Accuracy: 45.12%\n",
            "Epoch [8/10], Training Loss: 1.494, Validation Accuracy: 43.69%\n",
            "Epoch [9/10], Training Loss: 1.486, Validation Accuracy: 45.78%\n",
            "Epoch [10/10], Training Loss: 1.470, Validation Accuracy: 45.80%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 1.577, Validation Accuracy: 42.10%\n",
            "Epoch [2/10], Training Loss: 1.562, Validation Accuracy: 43.50%\n",
            "Epoch [3/10], Training Loss: 1.552, Validation Accuracy: 43.22%\n",
            "Epoch [4/10], Training Loss: 1.538, Validation Accuracy: 43.89%\n",
            "Epoch [5/10], Training Loss: 1.531, Validation Accuracy: 44.72%\n",
            "Epoch [6/10], Training Loss: 1.516, Validation Accuracy: 44.76%\n",
            "Epoch [7/10], Training Loss: 1.508, Validation Accuracy: 44.80%\n",
            "Epoch [8/10], Training Loss: 1.496, Validation Accuracy: 44.57%\n",
            "Epoch [9/10], Training Loss: 1.490, Validation Accuracy: 45.33%\n",
            "Epoch [10/10], Training Loss: 1.476, Validation Accuracy: 45.19%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 1.582, Validation Accuracy: 42.34%\n",
            "Epoch [2/10], Training Loss: 1.570, Validation Accuracy: 43.49%\n",
            "Epoch [3/10], Training Loss: 1.560, Validation Accuracy: 43.33%\n",
            "Epoch [4/10], Training Loss: 1.548, Validation Accuracy: 44.23%\n",
            "Epoch [5/10], Training Loss: 1.538, Validation Accuracy: 44.08%\n",
            "Epoch [6/10], Training Loss: 1.524, Validation Accuracy: 44.43%\n",
            "Epoch [7/10], Training Loss: 1.520, Validation Accuracy: 44.52%\n",
            "Epoch [8/10], Training Loss: 1.509, Validation Accuracy: 44.71%\n",
            "Epoch [9/10], Training Loss: 1.499, Validation Accuracy: 44.97%\n",
            "Epoch [10/10], Training Loss: 1.491, Validation Accuracy: 44.29%\n",
            "--- Round 8 Complete: Global Test Accuracy: 46.08% ---\n",
            "\n",
            "--- Round 9/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 1.498, Validation Accuracy: 45.84%\n",
            "Epoch [2/10], Training Loss: 1.485, Validation Accuracy: 45.95%\n",
            "Epoch [3/10], Training Loss: 1.479, Validation Accuracy: 46.80%\n",
            "Epoch [4/10], Training Loss: 1.465, Validation Accuracy: 46.71%\n",
            "Epoch [5/10], Training Loss: 1.455, Validation Accuracy: 47.10%\n",
            "Epoch [6/10], Training Loss: 1.446, Validation Accuracy: 46.50%\n",
            "Epoch [7/10], Training Loss: 1.437, Validation Accuracy: 47.59%\n",
            "Epoch [8/10], Training Loss: 1.428, Validation Accuracy: 47.32%\n",
            "Epoch [9/10], Training Loss: 1.417, Validation Accuracy: 47.69%\n",
            "Epoch [10/10], Training Loss: 1.408, Validation Accuracy: 47.56%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 1.494, Validation Accuracy: 46.22%\n",
            "Epoch [2/10], Training Loss: 1.488, Validation Accuracy: 46.65%\n",
            "Epoch [3/10], Training Loss: 1.471, Validation Accuracy: 46.62%\n",
            "Epoch [4/10], Training Loss: 1.467, Validation Accuracy: 46.09%\n",
            "Epoch [5/10], Training Loss: 1.448, Validation Accuracy: 46.77%\n",
            "Epoch [6/10], Training Loss: 1.444, Validation Accuracy: 46.47%\n",
            "Epoch [7/10], Training Loss: 1.443, Validation Accuracy: 46.46%\n",
            "Epoch [8/10], Training Loss: 1.429, Validation Accuracy: 47.25%\n",
            "Epoch [9/10], Training Loss: 1.408, Validation Accuracy: 47.50%\n",
            "Epoch [10/10], Training Loss: 1.407, Validation Accuracy: 46.64%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 1.490, Validation Accuracy: 46.17%\n",
            "Epoch [2/10], Training Loss: 1.477, Validation Accuracy: 46.32%\n",
            "Epoch [3/10], Training Loss: 1.473, Validation Accuracy: 46.29%\n",
            "Epoch [4/10], Training Loss: 1.462, Validation Accuracy: 46.47%\n",
            "Epoch [5/10], Training Loss: 1.452, Validation Accuracy: 46.14%\n",
            "Epoch [6/10], Training Loss: 1.441, Validation Accuracy: 47.05%\n",
            "Epoch [7/10], Training Loss: 1.427, Validation Accuracy: 47.45%\n",
            "Epoch [8/10], Training Loss: 1.415, Validation Accuracy: 47.70%\n",
            "Epoch [9/10], Training Loss: 1.420, Validation Accuracy: 47.62%\n",
            "Epoch [10/10], Training Loss: 1.407, Validation Accuracy: 47.55%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 1.497, Validation Accuracy: 46.20%\n",
            "Epoch [2/10], Training Loss: 1.486, Validation Accuracy: 46.44%\n",
            "Epoch [3/10], Training Loss: 1.473, Validation Accuracy: 46.60%\n",
            "Epoch [4/10], Training Loss: 1.465, Validation Accuracy: 47.05%\n",
            "Epoch [5/10], Training Loss: 1.450, Validation Accuracy: 46.82%\n",
            "Epoch [6/10], Training Loss: 1.442, Validation Accuracy: 46.45%\n",
            "Epoch [7/10], Training Loss: 1.429, Validation Accuracy: 46.85%\n",
            "Epoch [8/10], Training Loss: 1.417, Validation Accuracy: 47.21%\n",
            "Epoch [9/10], Training Loss: 1.415, Validation Accuracy: 47.29%\n",
            "Epoch [10/10], Training Loss: 1.410, Validation Accuracy: 47.11%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 1.511, Validation Accuracy: 46.54%\n",
            "Epoch [2/10], Training Loss: 1.493, Validation Accuracy: 46.47%\n",
            "Epoch [3/10], Training Loss: 1.491, Validation Accuracy: 46.48%\n",
            "Epoch [4/10], Training Loss: 1.478, Validation Accuracy: 46.45%\n",
            "Epoch [5/10], Training Loss: 1.469, Validation Accuracy: 45.92%\n",
            "Epoch [6/10], Training Loss: 1.454, Validation Accuracy: 46.60%\n",
            "Epoch [7/10], Training Loss: 1.451, Validation Accuracy: 46.42%\n",
            "Epoch [8/10], Training Loss: 1.439, Validation Accuracy: 47.03%\n",
            "Epoch [9/10], Training Loss: 1.424, Validation Accuracy: 47.65%\n",
            "Epoch [10/10], Training Loss: 1.425, Validation Accuracy: 47.90%\n",
            "--- Round 9 Complete: Global Test Accuracy: 48.74% ---\n",
            "\n",
            "--- Round 10/10 ---\n",
            "Client 1:\n",
            "Epoch [1/10], Training Loss: 1.446, Validation Accuracy: 48.40%\n",
            "Epoch [2/10], Training Loss: 1.427, Validation Accuracy: 47.94%\n",
            "Epoch [3/10], Training Loss: 1.415, Validation Accuracy: 48.79%\n",
            "Epoch [4/10], Training Loss: 1.403, Validation Accuracy: 48.56%\n",
            "Epoch [5/10], Training Loss: 1.398, Validation Accuracy: 48.84%\n",
            "Epoch [6/10], Training Loss: 1.393, Validation Accuracy: 49.64%\n",
            "Epoch [7/10], Training Loss: 1.378, Validation Accuracy: 49.07%\n",
            "Epoch [8/10], Training Loss: 1.369, Validation Accuracy: 49.57%\n",
            "Epoch [9/10], Training Loss: 1.371, Validation Accuracy: 48.38%\n",
            "Epoch [10/10], Training Loss: 1.368, Validation Accuracy: 49.07%\n",
            "Client 2:\n",
            "Epoch [1/10], Training Loss: 1.433, Validation Accuracy: 48.45%\n",
            "Epoch [2/10], Training Loss: 1.426, Validation Accuracy: 47.65%\n",
            "Epoch [3/10], Training Loss: 1.411, Validation Accuracy: 48.78%\n",
            "Epoch [4/10], Training Loss: 1.402, Validation Accuracy: 48.92%\n",
            "Epoch [5/10], Training Loss: 1.396, Validation Accuracy: 48.16%\n",
            "Epoch [6/10], Training Loss: 1.390, Validation Accuracy: 48.84%\n",
            "Epoch [7/10], Training Loss: 1.375, Validation Accuracy: 49.58%\n",
            "Epoch [8/10], Training Loss: 1.370, Validation Accuracy: 49.31%\n",
            "Epoch [9/10], Training Loss: 1.358, Validation Accuracy: 49.13%\n",
            "Epoch [10/10], Training Loss: 1.344, Validation Accuracy: 49.58%\n",
            "Client 3:\n",
            "Epoch [1/10], Training Loss: 1.438, Validation Accuracy: 47.13%\n",
            "Epoch [2/10], Training Loss: 1.425, Validation Accuracy: 49.10%\n",
            "Epoch [3/10], Training Loss: 1.410, Validation Accuracy: 48.74%\n",
            "Epoch [4/10], Training Loss: 1.399, Validation Accuracy: 48.14%\n",
            "Epoch [5/10], Training Loss: 1.388, Validation Accuracy: 49.27%\n",
            "Epoch [6/10], Training Loss: 1.379, Validation Accuracy: 49.14%\n",
            "Epoch [7/10], Training Loss: 1.366, Validation Accuracy: 48.70%\n",
            "Epoch [8/10], Training Loss: 1.365, Validation Accuracy: 49.54%\n",
            "Epoch [9/10], Training Loss: 1.357, Validation Accuracy: 48.12%\n",
            "Epoch [10/10], Training Loss: 1.352, Validation Accuracy: 49.34%\n",
            "Client 4:\n",
            "Epoch [1/10], Training Loss: 1.430, Validation Accuracy: 48.53%\n",
            "Epoch [2/10], Training Loss: 1.426, Validation Accuracy: 47.83%\n",
            "Epoch [3/10], Training Loss: 1.427, Validation Accuracy: 47.81%\n",
            "Epoch [4/10], Training Loss: 1.406, Validation Accuracy: 48.26%\n",
            "Epoch [5/10], Training Loss: 1.398, Validation Accuracy: 48.63%\n",
            "Epoch [6/10], Training Loss: 1.388, Validation Accuracy: 48.82%\n",
            "Epoch [7/10], Training Loss: 1.376, Validation Accuracy: 49.04%\n",
            "Epoch [8/10], Training Loss: 1.361, Validation Accuracy: 49.44%\n",
            "Epoch [9/10], Training Loss: 1.362, Validation Accuracy: 48.28%\n",
            "Epoch [10/10], Training Loss: 1.353, Validation Accuracy: 50.10%\n",
            "Client 5:\n",
            "Epoch [1/10], Training Loss: 1.449, Validation Accuracy: 48.37%\n",
            "Epoch [2/10], Training Loss: 1.434, Validation Accuracy: 48.27%\n",
            "Epoch [3/10], Training Loss: 1.421, Validation Accuracy: 48.29%\n",
            "Epoch [4/10], Training Loss: 1.416, Validation Accuracy: 47.08%\n",
            "Epoch [5/10], Training Loss: 1.411, Validation Accuracy: 47.67%\n",
            "Epoch [6/10], Training Loss: 1.396, Validation Accuracy: 49.28%\n",
            "Epoch [7/10], Training Loss: 1.382, Validation Accuracy: 48.92%\n",
            "Epoch [8/10], Training Loss: 1.377, Validation Accuracy: 49.09%\n",
            "Epoch [9/10], Training Loss: 1.369, Validation Accuracy: 48.45%\n",
            "Epoch [10/10], Training Loss: 1.363, Validation Accuracy: 49.78%\n",
            "--- Round 10 Complete: Global Test Accuracy: 50.50% ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9MsIOVba0g-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Your provided text\n",
        "log = \"\"\"\n",
        "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 11.41%\n",
        "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.10%\n",
        "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.96%\n",
        "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 9.85%\n",
        "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 9.85%\n",
        "Epoch [6/10], Training Loss: 2.302, Validation Accuracy: 9.82%\n",
        "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 9.83%\n",
        "Epoch [8/10], Training Loss: 2.301, Validation Accuracy: 9.83%\n",
        "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 9.85%\n",
        "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.89%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 11.49%\n",
        "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 11.37%\n",
        "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 11.23%\n",
        "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 11.50%\n",
        "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 12.31%\n",
        "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 11.58%\n",
        "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 10.71%\n",
        "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 10.07%\n",
        "Epoch [9/10], Training Loss: 2.302, Validation Accuracy: 10.00%\n",
        "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.93%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 11.48%\n",
        "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 10.44%\n",
        "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 10.58%\n",
        "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 10.39%\n",
        "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 10.28%\n",
        "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 10.47%\n",
        "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 11.27%\n",
        "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 11.55%\n",
        "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 12.25%\n",
        "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 12.64%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 10.39%\n",
        "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 9.95%\n",
        "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.90%\n",
        "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 9.89%\n",
        "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 9.87%\n",
        "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 9.87%\n",
        "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 9.87%\n",
        "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 9.87%\n",
        "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 9.87%\n",
        "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.87%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 10.89%\n",
        "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.67%\n",
        "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.91%\n",
        "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 9.85%\n",
        "Epoch [5/10], Training Loss: 2.303, Validation Accuracy: 9.84%\n",
        "Epoch [6/10], Training Loss: 2.302, Validation Accuracy: 9.84%\n",
        "Epoch [7/10], Training Loss: 2.302, Validation Accuracy: 9.84%\n",
        "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 9.84%\n",
        "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 9.85%\n",
        "Epoch [10/10], Training Loss: 2.301, Validation Accuracy: 9.85%\n",
        "--- Round 1 Complete: Global Test Accuracy: 12.82% ---\n",
        "\n",
        "--- Round 2/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 12.64%\n",
        "Epoch [2/10], Training Loss: 2.300, Validation Accuracy: 12.62%\n",
        "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 11.74%\n",
        "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 12.25%\n",
        "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 12.77%\n",
        "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 13.15%\n",
        "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 13.48%\n",
        "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 14.91%\n",
        "Epoch [9/10], Training Loss: 2.294, Validation Accuracy: 15.73%\n",
        "Epoch [10/10], Training Loss: 2.293, Validation Accuracy: 16.03%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 13.97%\n",
        "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 14.24%\n",
        "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 12.69%\n",
        "Epoch [4/10], Training Loss: 2.300, Validation Accuracy: 12.68%\n",
        "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 12.96%\n",
        "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 13.94%\n",
        "Epoch [7/10], Training Loss: 2.298, Validation Accuracy: 14.58%\n",
        "Epoch [8/10], Training Loss: 2.297, Validation Accuracy: 14.44%\n",
        "Epoch [9/10], Training Loss: 2.296, Validation Accuracy: 15.77%\n",
        "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 16.67%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 13.78%\n",
        "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 13.68%\n",
        "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 13.63%\n",
        "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 14.11%\n",
        "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 14.08%\n",
        "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 14.45%\n",
        "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 14.52%\n",
        "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 14.65%\n",
        "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 15.43%\n",
        "Epoch [10/10], Training Loss: 2.293, Validation Accuracy: 16.25%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 12.48%\n",
        "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 10.35%\n",
        "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 9.97%\n",
        "Epoch [4/10], Training Loss: 2.300, Validation Accuracy: 9.96%\n",
        "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 9.94%\n",
        "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 9.98%\n",
        "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 10.27%\n",
        "Epoch [8/10], Training Loss: 2.297, Validation Accuracy: 10.51%\n",
        "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 11.47%\n",
        "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 12.15%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 2.301, Validation Accuracy: 13.08%\n",
        "Epoch [2/10], Training Loss: 2.300, Validation Accuracy: 12.04%\n",
        "Epoch [3/10], Training Loss: 2.300, Validation Accuracy: 10.53%\n",
        "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 10.09%\n",
        "Epoch [5/10], Training Loss: 2.299, Validation Accuracy: 10.01%\n",
        "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 10.10%\n",
        "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 10.71%\n",
        "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 11.71%\n",
        "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 13.14%\n",
        "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 13.79%\n",
        "--- Round 2 Complete: Global Test Accuracy: 18.27% ---\n",
        "\n",
        "--- Round 3/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 2.292, Validation Accuracy: 19.21%\n",
        "Epoch [2/10], Training Loss: 2.289, Validation Accuracy: 19.31%\n",
        "Epoch [3/10], Training Loss: 2.285, Validation Accuracy: 19.58%\n",
        "Epoch [4/10], Training Loss: 2.280, Validation Accuracy: 19.79%\n",
        "Epoch [5/10], Training Loss: 2.271, Validation Accuracy: 19.42%\n",
        "Epoch [6/10], Training Loss: 2.258, Validation Accuracy: 19.33%\n",
        "Epoch [7/10], Training Loss: 2.237, Validation Accuracy: 19.40%\n",
        "Epoch [8/10], Training Loss: 2.208, Validation Accuracy: 20.73%\n",
        "Epoch [9/10], Training Loss: 2.174, Validation Accuracy: 22.36%\n",
        "Epoch [10/10], Training Loss: 2.139, Validation Accuracy: 23.26%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 2.293, Validation Accuracy: 20.07%\n",
        "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 20.06%\n",
        "Epoch [3/10], Training Loss: 2.287, Validation Accuracy: 19.94%\n",
        "Epoch [4/10], Training Loss: 2.282, Validation Accuracy: 20.12%\n",
        "Epoch [5/10], Training Loss: 2.275, Validation Accuracy: 19.60%\n",
        "Epoch [6/10], Training Loss: 2.263, Validation Accuracy: 19.73%\n",
        "Epoch [7/10], Training Loss: 2.245, Validation Accuracy: 20.21%\n",
        "Epoch [8/10], Training Loss: 2.220, Validation Accuracy: 21.57%\n",
        "Epoch [9/10], Training Loss: 2.191, Validation Accuracy: 22.21%\n",
        "Epoch [10/10], Training Loss: 2.159, Validation Accuracy: 22.84%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 2.292, Validation Accuracy: 18.88%\n",
        "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 19.56%\n",
        "Epoch [3/10], Training Loss: 2.286, Validation Accuracy: 19.42%\n",
        "Epoch [4/10], Training Loss: 2.281, Validation Accuracy: 19.43%\n",
        "Epoch [5/10], Training Loss: 2.272, Validation Accuracy: 19.34%\n",
        "Epoch [6/10], Training Loss: 2.260, Validation Accuracy: 19.54%\n",
        "Epoch [7/10], Training Loss: 2.241, Validation Accuracy: 20.44%\n",
        "Epoch [8/10], Training Loss: 2.216, Validation Accuracy: 21.90%\n",
        "Epoch [9/10], Training Loss: 2.186, Validation Accuracy: 22.51%\n",
        "Epoch [10/10], Training Loss: 2.153, Validation Accuracy: 22.93%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 2.293, Validation Accuracy: 19.43%\n",
        "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 18.83%\n",
        "Epoch [3/10], Training Loss: 2.287, Validation Accuracy: 18.54%\n",
        "Epoch [4/10], Training Loss: 2.282, Validation Accuracy: 18.21%\n",
        "Epoch [5/10], Training Loss: 2.274, Validation Accuracy: 18.36%\n",
        "Epoch [6/10], Training Loss: 2.263, Validation Accuracy: 18.28%\n",
        "Epoch [7/10], Training Loss: 2.245, Validation Accuracy: 18.63%\n",
        "Epoch [8/10], Training Loss: 2.221, Validation Accuracy: 20.34%\n",
        "Epoch [9/10], Training Loss: 2.191, Validation Accuracy: 21.74%\n",
        "Epoch [10/10], Training Loss: 2.158, Validation Accuracy: 22.74%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 2.292, Validation Accuracy: 19.56%\n",
        "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 19.95%\n",
        "Epoch [3/10], Training Loss: 2.286, Validation Accuracy: 20.11%\n",
        "Epoch [4/10], Training Loss: 2.281, Validation Accuracy: 19.80%\n",
        "Epoch [5/10], Training Loss: 2.273, Validation Accuracy: 20.01%\n",
        "Epoch [6/10], Training Loss: 2.261, Validation Accuracy: 20.08%\n",
        "Epoch [7/10], Training Loss: 2.242, Validation Accuracy: 19.90%\n",
        "Epoch [8/10], Training Loss: 2.215, Validation Accuracy: 20.67%\n",
        "Epoch [9/10], Training Loss: 2.185, Validation Accuracy: 21.59%\n",
        "Epoch [10/10], Training Loss: 2.151, Validation Accuracy: 23.08%\n",
        "--- Round 3 Complete: Global Test Accuracy: 23.06% ---\n",
        "\n",
        "--- Round 4/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 2.123, Validation Accuracy: 23.62%\n",
        "Epoch [2/10], Training Loss: 2.095, Validation Accuracy: 24.08%\n",
        "Epoch [3/10], Training Loss: 2.074, Validation Accuracy: 24.89%\n",
        "Epoch [4/10], Training Loss: 2.055, Validation Accuracy: 25.16%\n",
        "Epoch [5/10], Training Loss: 2.037, Validation Accuracy: 25.46%\n",
        "Epoch [6/10], Training Loss: 2.019, Validation Accuracy: 26.37%\n",
        "Epoch [7/10], Training Loss: 2.003, Validation Accuracy: 26.70%\n",
        "Epoch [8/10], Training Loss: 1.989, Validation Accuracy: 26.71%\n",
        "Epoch [9/10], Training Loss: 1.975, Validation Accuracy: 27.61%\n",
        "Epoch [10/10], Training Loss: 1.959, Validation Accuracy: 28.35%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 2.130, Validation Accuracy: 23.02%\n",
        "Epoch [2/10], Training Loss: 2.106, Validation Accuracy: 23.54%\n",
        "Epoch [3/10], Training Loss: 2.085, Validation Accuracy: 24.30%\n",
        "Epoch [4/10], Training Loss: 2.066, Validation Accuracy: 24.99%\n",
        "Epoch [5/10], Training Loss: 2.048, Validation Accuracy: 25.57%\n",
        "Epoch [6/10], Training Loss: 2.031, Validation Accuracy: 25.95%\n",
        "Epoch [7/10], Training Loss: 2.016, Validation Accuracy: 26.64%\n",
        "Epoch [8/10], Training Loss: 2.000, Validation Accuracy: 26.96%\n",
        "Epoch [9/10], Training Loss: 1.985, Validation Accuracy: 27.72%\n",
        "Epoch [10/10], Training Loss: 1.969, Validation Accuracy: 27.77%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 2.128, Validation Accuracy: 23.18%\n",
        "Epoch [2/10], Training Loss: 2.104, Validation Accuracy: 23.43%\n",
        "Epoch [3/10], Training Loss: 2.084, Validation Accuracy: 24.32%\n",
        "Epoch [4/10], Training Loss: 2.063, Validation Accuracy: 24.56%\n",
        "Epoch [5/10], Training Loss: 2.043, Validation Accuracy: 25.59%\n",
        "Epoch [6/10], Training Loss: 2.025, Validation Accuracy: 25.91%\n",
        "Epoch [7/10], Training Loss: 2.006, Validation Accuracy: 26.04%\n",
        "Epoch [8/10], Training Loss: 1.991, Validation Accuracy: 26.88%\n",
        "Epoch [9/10], Training Loss: 1.978, Validation Accuracy: 26.82%\n",
        "Epoch [10/10], Training Loss: 1.965, Validation Accuracy: 28.16%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 2.129, Validation Accuracy: 23.28%\n",
        "Epoch [2/10], Training Loss: 2.103, Validation Accuracy: 23.73%\n",
        "Epoch [3/10], Training Loss: 2.080, Validation Accuracy: 24.24%\n",
        "Epoch [4/10], Training Loss: 2.060, Validation Accuracy: 24.78%\n",
        "Epoch [5/10], Training Loss: 2.040, Validation Accuracy: 25.62%\n",
        "Epoch [6/10], Training Loss: 2.022, Validation Accuracy: 26.06%\n",
        "Epoch [7/10], Training Loss: 2.003, Validation Accuracy: 26.75%\n",
        "Epoch [8/10], Training Loss: 1.989, Validation Accuracy: 27.31%\n",
        "Epoch [9/10], Training Loss: 1.976, Validation Accuracy: 27.89%\n",
        "Epoch [10/10], Training Loss: 1.963, Validation Accuracy: 28.33%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 2.126, Validation Accuracy: 23.25%\n",
        "Epoch [2/10], Training Loss: 2.101, Validation Accuracy: 23.19%\n",
        "Epoch [3/10], Training Loss: 2.079, Validation Accuracy: 23.92%\n",
        "Epoch [4/10], Training Loss: 2.058, Validation Accuracy: 24.87%\n",
        "Epoch [5/10], Training Loss: 2.039, Validation Accuracy: 25.44%\n",
        "Epoch [6/10], Training Loss: 2.022, Validation Accuracy: 26.08%\n",
        "Epoch [7/10], Training Loss: 2.002, Validation Accuracy: 26.21%\n",
        "Epoch [8/10], Training Loss: 1.987, Validation Accuracy: 26.57%\n",
        "Epoch [9/10], Training Loss: 1.974, Validation Accuracy: 27.85%\n",
        "Epoch [10/10], Training Loss: 1.959, Validation Accuracy: 28.01%\n",
        "--- Round 4 Complete: Global Test Accuracy: 28.61% ---\n",
        "\n",
        "--- Round 5/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 1.952, Validation Accuracy: 28.19%\n",
        "Epoch [2/10], Training Loss: 1.938, Validation Accuracy: 29.54%\n",
        "Epoch [3/10], Training Loss: 1.926, Validation Accuracy: 29.57%\n",
        "Epoch [4/10], Training Loss: 1.911, Validation Accuracy: 30.39%\n",
        "Epoch [5/10], Training Loss: 1.892, Validation Accuracy: 31.49%\n",
        "Epoch [6/10], Training Loss: 1.876, Validation Accuracy: 31.85%\n",
        "Epoch [7/10], Training Loss: 1.860, Validation Accuracy: 32.71%\n",
        "Epoch [8/10], Training Loss: 1.845, Validation Accuracy: 32.01%\n",
        "Epoch [9/10], Training Loss: 1.828, Validation Accuracy: 33.64%\n",
        "Epoch [10/10], Training Loss: 1.809, Validation Accuracy: 34.13%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 1.961, Validation Accuracy: 28.58%\n",
        "Epoch [2/10], Training Loss: 1.948, Validation Accuracy: 28.99%\n",
        "Epoch [3/10], Training Loss: 1.931, Validation Accuracy: 29.79%\n",
        "Epoch [4/10], Training Loss: 1.919, Validation Accuracy: 30.80%\n",
        "Epoch [5/10], Training Loss: 1.904, Validation Accuracy: 30.26%\n",
        "Epoch [6/10], Training Loss: 1.887, Validation Accuracy: 31.81%\n",
        "Epoch [7/10], Training Loss: 1.870, Validation Accuracy: 31.65%\n",
        "Epoch [8/10], Training Loss: 1.855, Validation Accuracy: 32.79%\n",
        "Epoch [9/10], Training Loss: 1.838, Validation Accuracy: 33.58%\n",
        "Epoch [10/10], Training Loss: 1.820, Validation Accuracy: 34.34%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 1.960, Validation Accuracy: 28.44%\n",
        "Epoch [2/10], Training Loss: 1.944, Validation Accuracy: 29.40%\n",
        "Epoch [3/10], Training Loss: 1.932, Validation Accuracy: 29.91%\n",
        "Epoch [4/10], Training Loss: 1.916, Validation Accuracy: 30.37%\n",
        "Epoch [5/10], Training Loss: 1.900, Validation Accuracy: 30.85%\n",
        "Epoch [6/10], Training Loss: 1.885, Validation Accuracy: 31.37%\n",
        "Epoch [7/10], Training Loss: 1.872, Validation Accuracy: 31.97%\n",
        "Epoch [8/10], Training Loss: 1.856, Validation Accuracy: 32.60%\n",
        "Epoch [9/10], Training Loss: 1.839, Validation Accuracy: 33.57%\n",
        "Epoch [10/10], Training Loss: 1.820, Validation Accuracy: 34.15%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 1.956, Validation Accuracy: 29.03%\n",
        "Epoch [2/10], Training Loss: 1.941, Validation Accuracy: 28.88%\n",
        "Epoch [3/10], Training Loss: 1.926, Validation Accuracy: 29.92%\n",
        "Epoch [4/10], Training Loss: 1.913, Validation Accuracy: 30.62%\n",
        "Epoch [5/10], Training Loss: 1.895, Validation Accuracy: 30.73%\n",
        "Epoch [6/10], Training Loss: 1.879, Validation Accuracy: 30.88%\n",
        "Epoch [7/10], Training Loss: 1.863, Validation Accuracy: 32.01%\n",
        "Epoch [8/10], Training Loss: 1.849, Validation Accuracy: 32.33%\n",
        "Epoch [9/10], Training Loss: 1.831, Validation Accuracy: 33.96%\n",
        "Epoch [10/10], Training Loss: 1.813, Validation Accuracy: 34.24%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 1.953, Validation Accuracy: 28.39%\n",
        "Epoch [2/10], Training Loss: 1.940, Validation Accuracy: 28.38%\n",
        "Epoch [3/10], Training Loss: 1.926, Validation Accuracy: 29.45%\n",
        "Epoch [4/10], Training Loss: 1.910, Validation Accuracy: 30.56%\n",
        "Epoch [5/10], Training Loss: 1.893, Validation Accuracy: 30.01%\n",
        "Epoch [6/10], Training Loss: 1.877, Validation Accuracy: 31.36%\n",
        "Epoch [7/10], Training Loss: 1.860, Validation Accuracy: 31.56%\n",
        "Epoch [8/10], Training Loss: 1.847, Validation Accuracy: 32.12%\n",
        "Epoch [9/10], Training Loss: 1.830, Validation Accuracy: 32.87%\n",
        "Epoch [10/10], Training Loss: 1.814, Validation Accuracy: 33.01%\n",
        "--- Round 5 Complete: Global Test Accuracy: 34.16% ---\n",
        "\n",
        "--- Round 6/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 1.808, Validation Accuracy: 34.66%\n",
        "Epoch [2/10], Training Loss: 1.792, Validation Accuracy: 34.89%\n",
        "Epoch [3/10], Training Loss: 1.775, Validation Accuracy: 35.89%\n",
        "Epoch [4/10], Training Loss: 1.757, Validation Accuracy: 35.54%\n",
        "Epoch [5/10], Training Loss: 1.744, Validation Accuracy: 36.32%\n",
        "Epoch [6/10], Training Loss: 1.726, Validation Accuracy: 37.14%\n",
        "Epoch [7/10], Training Loss: 1.715, Validation Accuracy: 37.36%\n",
        "Epoch [8/10], Training Loss: 1.694, Validation Accuracy: 37.57%\n",
        "Epoch [9/10], Training Loss: 1.686, Validation Accuracy: 38.43%\n",
        "Epoch [10/10], Training Loss: 1.674, Validation Accuracy: 38.73%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 1.813, Validation Accuracy: 34.93%\n",
        "Epoch [2/10], Training Loss: 1.795, Validation Accuracy: 34.92%\n",
        "Epoch [3/10], Training Loss: 1.780, Validation Accuracy: 36.09%\n",
        "Epoch [4/10], Training Loss: 1.762, Validation Accuracy: 36.21%\n",
        "Epoch [5/10], Training Loss: 1.747, Validation Accuracy: 36.86%\n",
        "Epoch [6/10], Training Loss: 1.729, Validation Accuracy: 37.18%\n",
        "Epoch [7/10], Training Loss: 1.711, Validation Accuracy: 37.88%\n",
        "Epoch [8/10], Training Loss: 1.697, Validation Accuracy: 37.73%\n",
        "Epoch [9/10], Training Loss: 1.681, Validation Accuracy: 38.30%\n",
        "Epoch [10/10], Training Loss: 1.668, Validation Accuracy: 39.00%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 1.817, Validation Accuracy: 34.52%\n",
        "Epoch [2/10], Training Loss: 1.797, Validation Accuracy: 35.00%\n",
        "Epoch [3/10], Training Loss: 1.782, Validation Accuracy: 35.12%\n",
        "Epoch [4/10], Training Loss: 1.768, Validation Accuracy: 36.62%\n",
        "Epoch [5/10], Training Loss: 1.746, Validation Accuracy: 36.96%\n",
        "Epoch [6/10], Training Loss: 1.728, Validation Accuracy: 37.51%\n",
        "Epoch [7/10], Training Loss: 1.714, Validation Accuracy: 37.97%\n",
        "Epoch [8/10], Training Loss: 1.696, Validation Accuracy: 38.06%\n",
        "Epoch [9/10], Training Loss: 1.680, Validation Accuracy: 37.72%\n",
        "Epoch [10/10], Training Loss: 1.667, Validation Accuracy: 38.14%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 1.809, Validation Accuracy: 34.63%\n",
        "Epoch [2/10], Training Loss: 1.790, Validation Accuracy: 35.34%\n",
        "Epoch [3/10], Training Loss: 1.774, Validation Accuracy: 35.39%\n",
        "Epoch [4/10], Training Loss: 1.757, Validation Accuracy: 36.00%\n",
        "Epoch [5/10], Training Loss: 1.737, Validation Accuracy: 36.19%\n",
        "Epoch [6/10], Training Loss: 1.720, Validation Accuracy: 37.30%\n",
        "Epoch [7/10], Training Loss: 1.707, Validation Accuracy: 37.44%\n",
        "Epoch [8/10], Training Loss: 1.690, Validation Accuracy: 38.29%\n",
        "Epoch [9/10], Training Loss: 1.678, Validation Accuracy: 38.65%\n",
        "Epoch [10/10], Training Loss: 1.665, Validation Accuracy: 38.79%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 1.806, Validation Accuracy: 34.19%\n",
        "Epoch [2/10], Training Loss: 1.789, Validation Accuracy: 34.93%\n",
        "Epoch [3/10], Training Loss: 1.774, Validation Accuracy: 35.49%\n",
        "Epoch [4/10], Training Loss: 1.759, Validation Accuracy: 35.67%\n",
        "Epoch [5/10], Training Loss: 1.742, Validation Accuracy: 35.04%\n",
        "Epoch [6/10], Training Loss: 1.729, Validation Accuracy: 36.95%\n",
        "Epoch [7/10], Training Loss: 1.715, Validation Accuracy: 37.32%\n",
        "Epoch [8/10], Training Loss: 1.700, Validation Accuracy: 37.70%\n",
        "Epoch [9/10], Training Loss: 1.691, Validation Accuracy: 38.21%\n",
        "Epoch [10/10], Training Loss: 1.669, Validation Accuracy: 38.35%\n",
        "--- Round 6 Complete: Global Test Accuracy: 39.65% ---\n",
        "\n",
        "--- Round 7/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 1.671, Validation Accuracy: 38.96%\n",
        "Epoch [2/10], Training Loss: 1.658, Validation Accuracy: 40.15%\n",
        "Epoch [3/10], Training Loss: 1.640, Validation Accuracy: 39.80%\n",
        "Epoch [4/10], Training Loss: 1.628, Validation Accuracy: 40.69%\n",
        "Epoch [5/10], Training Loss: 1.618, Validation Accuracy: 40.96%\n",
        "Epoch [6/10], Training Loss: 1.606, Validation Accuracy: 41.02%\n",
        "Epoch [7/10], Training Loss: 1.598, Validation Accuracy: 40.87%\n",
        "Epoch [8/10], Training Loss: 1.588, Validation Accuracy: 42.08%\n",
        "Epoch [9/10], Training Loss: 1.577, Validation Accuracy: 41.28%\n",
        "Epoch [10/10], Training Loss: 1.563, Validation Accuracy: 41.99%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 1.671, Validation Accuracy: 39.45%\n",
        "Epoch [2/10], Training Loss: 1.659, Validation Accuracy: 39.25%\n",
        "Epoch [3/10], Training Loss: 1.645, Validation Accuracy: 40.19%\n",
        "Epoch [4/10], Training Loss: 1.630, Validation Accuracy: 40.87%\n",
        "Epoch [5/10], Training Loss: 1.615, Validation Accuracy: 40.62%\n",
        "Epoch [6/10], Training Loss: 1.602, Validation Accuracy: 40.00%\n",
        "Epoch [7/10], Training Loss: 1.594, Validation Accuracy: 41.25%\n",
        "Epoch [8/10], Training Loss: 1.582, Validation Accuracy: 41.33%\n",
        "Epoch [9/10], Training Loss: 1.568, Validation Accuracy: 42.52%\n",
        "Epoch [10/10], Training Loss: 1.566, Validation Accuracy: 41.41%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 1.679, Validation Accuracy: 39.12%\n",
        "Epoch [2/10], Training Loss: 1.660, Validation Accuracy: 39.83%\n",
        "Epoch [3/10], Training Loss: 1.640, Validation Accuracy: 40.06%\n",
        "Epoch [4/10], Training Loss: 1.630, Validation Accuracy: 40.54%\n",
        "Epoch [5/10], Training Loss: 1.613, Validation Accuracy: 40.87%\n",
        "Epoch [6/10], Training Loss: 1.610, Validation Accuracy: 40.59%\n",
        "Epoch [7/10], Training Loss: 1.585, Validation Accuracy: 41.27%\n",
        "Epoch [8/10], Training Loss: 1.578, Validation Accuracy: 41.85%\n",
        "Epoch [9/10], Training Loss: 1.573, Validation Accuracy: 41.40%\n",
        "Epoch [10/10], Training Loss: 1.557, Validation Accuracy: 42.66%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 1.671, Validation Accuracy: 39.40%\n",
        "Epoch [2/10], Training Loss: 1.654, Validation Accuracy: 39.69%\n",
        "Epoch [3/10], Training Loss: 1.640, Validation Accuracy: 39.33%\n",
        "Epoch [4/10], Training Loss: 1.631, Validation Accuracy: 39.91%\n",
        "Epoch [5/10], Training Loss: 1.617, Validation Accuracy: 40.70%\n",
        "Epoch [6/10], Training Loss: 1.603, Validation Accuracy: 40.86%\n",
        "Epoch [7/10], Training Loss: 1.592, Validation Accuracy: 41.26%\n",
        "Epoch [8/10], Training Loss: 1.589, Validation Accuracy: 41.29%\n",
        "Epoch [9/10], Training Loss: 1.569, Validation Accuracy: 41.52%\n",
        "Epoch [10/10], Training Loss: 1.559, Validation Accuracy: 41.56%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 1.675, Validation Accuracy: 39.49%\n",
        "Epoch [2/10], Training Loss: 1.661, Validation Accuracy: 38.77%\n",
        "Epoch [3/10], Training Loss: 1.650, Validation Accuracy: 40.31%\n",
        "Epoch [4/10], Training Loss: 1.640, Validation Accuracy: 40.25%\n",
        "Epoch [5/10], Training Loss: 1.622, Validation Accuracy: 40.89%\n",
        "Epoch [6/10], Training Loss: 1.616, Validation Accuracy: 40.49%\n",
        "Epoch [7/10], Training Loss: 1.605, Validation Accuracy: 41.52%\n",
        "Epoch [8/10], Training Loss: 1.595, Validation Accuracy: 41.71%\n",
        "Epoch [9/10], Training Loss: 1.583, Validation Accuracy: 40.96%\n",
        "Epoch [10/10], Training Loss: 1.572, Validation Accuracy: 41.83%\n",
        "--- Round 7 Complete: Global Test Accuracy: 43.06% ---\n",
        "\n",
        "--- Round 8/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 1.577, Validation Accuracy: 42.83%\n",
        "Epoch [2/10], Training Loss: 1.570, Validation Accuracy: 43.51%\n",
        "Epoch [3/10], Training Loss: 1.556, Validation Accuracy: 42.55%\n",
        "Epoch [4/10], Training Loss: 1.542, Validation Accuracy: 44.05%\n",
        "Epoch [5/10], Training Loss: 1.526, Validation Accuracy: 44.08%\n",
        "Epoch [6/10], Training Loss: 1.519, Validation Accuracy: 43.71%\n",
        "Epoch [7/10], Training Loss: 1.511, Validation Accuracy: 44.44%\n",
        "Epoch [8/10], Training Loss: 1.502, Validation Accuracy: 44.02%\n",
        "Epoch [9/10], Training Loss: 1.490, Validation Accuracy: 45.35%\n",
        "Epoch [10/10], Training Loss: 1.483, Validation Accuracy: 45.05%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 1.572, Validation Accuracy: 42.75%\n",
        "Epoch [2/10], Training Loss: 1.559, Validation Accuracy: 43.37%\n",
        "Epoch [3/10], Training Loss: 1.548, Validation Accuracy: 44.09%\n",
        "Epoch [4/10], Training Loss: 1.540, Validation Accuracy: 43.65%\n",
        "Epoch [5/10], Training Loss: 1.529, Validation Accuracy: 44.56%\n",
        "Epoch [6/10], Training Loss: 1.517, Validation Accuracy: 42.70%\n",
        "Epoch [7/10], Training Loss: 1.515, Validation Accuracy: 44.30%\n",
        "Epoch [8/10], Training Loss: 1.504, Validation Accuracy: 45.44%\n",
        "Epoch [9/10], Training Loss: 1.487, Validation Accuracy: 44.83%\n",
        "Epoch [10/10], Training Loss: 1.478, Validation Accuracy: 45.73%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 1.572, Validation Accuracy: 42.43%\n",
        "Epoch [2/10], Training Loss: 1.560, Validation Accuracy: 43.52%\n",
        "Epoch [3/10], Training Loss: 1.543, Validation Accuracy: 43.09%\n",
        "Epoch [4/10], Training Loss: 1.535, Validation Accuracy: 43.96%\n",
        "Epoch [5/10], Training Loss: 1.527, Validation Accuracy: 43.67%\n",
        "Epoch [6/10], Training Loss: 1.513, Validation Accuracy: 44.10%\n",
        "Epoch [7/10], Training Loss: 1.503, Validation Accuracy: 45.12%\n",
        "Epoch [8/10], Training Loss: 1.494, Validation Accuracy: 43.69%\n",
        "Epoch [9/10], Training Loss: 1.486, Validation Accuracy: 45.78%\n",
        "Epoch [10/10], Training Loss: 1.470, Validation Accuracy: 45.80%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 1.577, Validation Accuracy: 42.10%\n",
        "Epoch [2/10], Training Loss: 1.562, Validation Accuracy: 43.50%\n",
        "Epoch [3/10], Training Loss: 1.552, Validation Accuracy: 43.22%\n",
        "Epoch [4/10], Training Loss: 1.538, Validation Accuracy: 43.89%\n",
        "Epoch [5/10], Training Loss: 1.531, Validation Accuracy: 44.72%\n",
        "Epoch [6/10], Training Loss: 1.516, Validation Accuracy: 44.76%\n",
        "Epoch [7/10], Training Loss: 1.508, Validation Accuracy: 44.80%\n",
        "Epoch [8/10], Training Loss: 1.496, Validation Accuracy: 44.57%\n",
        "Epoch [9/10], Training Loss: 1.490, Validation Accuracy: 45.33%\n",
        "Epoch [10/10], Training Loss: 1.476, Validation Accuracy: 45.19%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 1.582, Validation Accuracy: 42.34%\n",
        "Epoch [2/10], Training Loss: 1.570, Validation Accuracy: 43.49%\n",
        "Epoch [3/10], Training Loss: 1.560, Validation Accuracy: 43.33%\n",
        "Epoch [4/10], Training Loss: 1.548, Validation Accuracy: 44.23%\n",
        "Epoch [5/10], Training Loss: 1.538, Validation Accuracy: 44.08%\n",
        "Epoch [6/10], Training Loss: 1.524, Validation Accuracy: 44.43%\n",
        "Epoch [7/10], Training Loss: 1.520, Validation Accuracy: 44.52%\n",
        "Epoch [8/10], Training Loss: 1.509, Validation Accuracy: 44.71%\n",
        "Epoch [9/10], Training Loss: 1.499, Validation Accuracy: 44.97%\n",
        "Epoch [10/10], Training Loss: 1.491, Validation Accuracy: 44.29%\n",
        "--- Round 8 Complete: Global Test Accuracy: 46.08% ---\n",
        "\n",
        "--- Round 9/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 1.498, Validation Accuracy: 45.84%\n",
        "Epoch [2/10], Training Loss: 1.485, Validation Accuracy: 45.95%\n",
        "Epoch [3/10], Training Loss: 1.479, Validation Accuracy: 46.80%\n",
        "Epoch [4/10], Training Loss: 1.465, Validation Accuracy: 46.71%\n",
        "Epoch [5/10], Training Loss: 1.455, Validation Accuracy: 47.10%\n",
        "Epoch [6/10], Training Loss: 1.446, Validation Accuracy: 46.50%\n",
        "Epoch [7/10], Training Loss: 1.437, Validation Accuracy: 47.59%\n",
        "Epoch [8/10], Training Loss: 1.428, Validation Accuracy: 47.32%\n",
        "Epoch [9/10], Training Loss: 1.417, Validation Accuracy: 47.69%\n",
        "Epoch [10/10], Training Loss: 1.408, Validation Accuracy: 47.56%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 1.494, Validation Accuracy: 46.22%\n",
        "Epoch [2/10], Training Loss: 1.488, Validation Accuracy: 46.65%\n",
        "Epoch [3/10], Training Loss: 1.471, Validation Accuracy: 46.62%\n",
        "Epoch [4/10], Training Loss: 1.467, Validation Accuracy: 46.09%\n",
        "Epoch [5/10], Training Loss: 1.448, Validation Accuracy: 46.77%\n",
        "Epoch [6/10], Training Loss: 1.444, Validation Accuracy: 46.47%\n",
        "Epoch [7/10], Training Loss: 1.443, Validation Accuracy: 46.46%\n",
        "Epoch [8/10], Training Loss: 1.429, Validation Accuracy: 47.25%\n",
        "Epoch [9/10], Training Loss: 1.408, Validation Accuracy: 47.50%\n",
        "Epoch [10/10], Training Loss: 1.407, Validation Accuracy: 46.64%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 1.490, Validation Accuracy: 46.17%\n",
        "Epoch [2/10], Training Loss: 1.477, Validation Accuracy: 46.32%\n",
        "Epoch [3/10], Training Loss: 1.473, Validation Accuracy: 46.29%\n",
        "Epoch [4/10], Training Loss: 1.462, Validation Accuracy: 46.47%\n",
        "Epoch [5/10], Training Loss: 1.452, Validation Accuracy: 46.14%\n",
        "Epoch [6/10], Training Loss: 1.441, Validation Accuracy: 47.05%\n",
        "Epoch [7/10], Training Loss: 1.427, Validation Accuracy: 47.45%\n",
        "Epoch [8/10], Training Loss: 1.415, Validation Accuracy: 47.70%\n",
        "Epoch [9/10], Training Loss: 1.420, Validation Accuracy: 47.62%\n",
        "Epoch [10/10], Training Loss: 1.407, Validation Accuracy: 47.55%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 1.497, Validation Accuracy: 46.20%\n",
        "Epoch [2/10], Training Loss: 1.486, Validation Accuracy: 46.44%\n",
        "Epoch [3/10], Training Loss: 1.473, Validation Accuracy: 46.60%\n",
        "Epoch [4/10], Training Loss: 1.465, Validation Accuracy: 47.05%\n",
        "Epoch [5/10], Training Loss: 1.450, Validation Accuracy: 46.82%\n",
        "Epoch [6/10], Training Loss: 1.442, Validation Accuracy: 46.45%\n",
        "Epoch [7/10], Training Loss: 1.429, Validation Accuracy: 46.85%\n",
        "Epoch [8/10], Training Loss: 1.417, Validation Accuracy: 47.21%\n",
        "Epoch [9/10], Training Loss: 1.415, Validation Accuracy: 47.29%\n",
        "Epoch [10/10], Training Loss: 1.410, Validation Accuracy: 47.11%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 1.511, Validation Accuracy: 46.54%\n",
        "Epoch [2/10], Training Loss: 1.493, Validation Accuracy: 46.47%\n",
        "Epoch [3/10], Training Loss: 1.491, Validation Accuracy: 46.48%\n",
        "Epoch [4/10], Training Loss: 1.478, Validation Accuracy: 46.45%\n",
        "Epoch [5/10], Training Loss: 1.469, Validation Accuracy: 45.92%\n",
        "Epoch [6/10], Training Loss: 1.454, Validation Accuracy: 46.60%\n",
        "Epoch [7/10], Training Loss: 1.451, Validation Accuracy: 46.42%\n",
        "Epoch [8/10], Training Loss: 1.439, Validation Accuracy: 47.03%\n",
        "Epoch [9/10], Training Loss: 1.424, Validation Accuracy: 47.65%\n",
        "Epoch [10/10], Training Loss: 1.425, Validation Accuracy: 47.90%\n",
        "--- Round 9 Complete: Global Test Accuracy: 48.74% ---\n",
        "\n",
        "--- Round 10/10 ---\n",
        "Client 1:\n",
        "Epoch [1/10], Training Loss: 1.446, Validation Accuracy: 48.40%\n",
        "Epoch [2/10], Training Loss: 1.427, Validation Accuracy: 47.94%\n",
        "Epoch [3/10], Training Loss: 1.415, Validation Accuracy: 48.79%\n",
        "Epoch [4/10], Training Loss: 1.403, Validation Accuracy: 48.56%\n",
        "Epoch [5/10], Training Loss: 1.398, Validation Accuracy: 48.84%\n",
        "Epoch [6/10], Training Loss: 1.393, Validation Accuracy: 49.64%\n",
        "Epoch [7/10], Training Loss: 1.378, Validation Accuracy: 49.07%\n",
        "Epoch [8/10], Training Loss: 1.369, Validation Accuracy: 49.57%\n",
        "Epoch [9/10], Training Loss: 1.371, Validation Accuracy: 48.38%\n",
        "Epoch [10/10], Training Loss: 1.368, Validation Accuracy: 49.07%\n",
        "Client 2:\n",
        "Epoch [1/10], Training Loss: 1.433, Validation Accuracy: 48.45%\n",
        "Epoch [2/10], Training Loss: 1.426, Validation Accuracy: 47.65%\n",
        "Epoch [3/10], Training Loss: 1.411, Validation Accuracy: 48.78%\n",
        "Epoch [4/10], Training Loss: 1.402, Validation Accuracy: 48.92%\n",
        "Epoch [5/10], Training Loss: 1.396, Validation Accuracy: 48.16%\n",
        "Epoch [6/10], Training Loss: 1.390, Validation Accuracy: 48.84%\n",
        "Epoch [7/10], Training Loss: 1.375, Validation Accuracy: 49.58%\n",
        "Epoch [8/10], Training Loss: 1.370, Validation Accuracy: 49.31%\n",
        "Epoch [9/10], Training Loss: 1.358, Validation Accuracy: 49.13%\n",
        "Epoch [10/10], Training Loss: 1.344, Validation Accuracy: 49.58%\n",
        "Client 3:\n",
        "Epoch [1/10], Training Loss: 1.438, Validation Accuracy: 47.13%\n",
        "Epoch [2/10], Training Loss: 1.425, Validation Accuracy: 49.10%\n",
        "Epoch [3/10], Training Loss: 1.410, Validation Accuracy: 48.74%\n",
        "Epoch [4/10], Training Loss: 1.399, Validation Accuracy: 48.14%\n",
        "Epoch [5/10], Training Loss: 1.388, Validation Accuracy: 49.27%\n",
        "Epoch [6/10], Training Loss: 1.379, Validation Accuracy: 49.14%\n",
        "Epoch [7/10], Training Loss: 1.366, Validation Accuracy: 48.70%\n",
        "Epoch [8/10], Training Loss: 1.365, Validation Accuracy: 49.54%\n",
        "Epoch [9/10], Training Loss: 1.357, Validation Accuracy: 48.12%\n",
        "Epoch [10/10], Training Loss: 1.352, Validation Accuracy: 49.34%\n",
        "Client 4:\n",
        "Epoch [1/10], Training Loss: 1.430, Validation Accuracy: 48.53%\n",
        "Epoch [2/10], Training Loss: 1.426, Validation Accuracy: 47.83%\n",
        "Epoch [3/10], Training Loss: 1.427, Validation Accuracy: 47.81%\n",
        "Epoch [4/10], Training Loss: 1.406, Validation Accuracy: 48.26%\n",
        "Epoch [5/10], Training Loss: 1.398, Validation Accuracy: 48.63%\n",
        "Epoch [6/10], Training Loss: 1.388, Validation Accuracy: 48.82%\n",
        "Epoch [7/10], Training Loss: 1.376, Validation Accuracy: 49.04%\n",
        "Epoch [8/10], Training Loss: 1.361, Validation Accuracy: 49.44%\n",
        "Epoch [9/10], Training Loss: 1.362, Validation Accuracy: 48.28%\n",
        "Epoch [10/10], Training Loss: 1.353, Validation Accuracy: 50.10%\n",
        "Client 5:\n",
        "Epoch [1/10], Training Loss: 1.449, Validation Accuracy: 48.37%\n",
        "Epoch [2/10], Training Loss: 1.434, Validation Accuracy: 48.27%\n",
        "Epoch [3/10], Training Loss: 1.421, Validation Accuracy: 48.29%\n",
        "Epoch [4/10], Training Loss: 1.416, Validation Accuracy: 47.08%\n",
        "Epoch [5/10], Training Loss: 1.411, Validation Accuracy: 47.67%\n",
        "Epoch [6/10], Training Loss: 1.396, Validation Accuracy: 49.28%\n",
        "Epoch [7/10], Training Loss: 1.382, Validation Accuracy: 48.92%\n",
        "Epoch [8/10], Training Loss: 1.377, Validation Accuracy: 49.09%\n",
        "Epoch [9/10], Training Loss: 1.369, Validation Accuracy: 48.45%\n",
        "Epoch [10/10], Training Loss: 1.363, Validation Accuracy: 49.78%\n",
        "--- Round 10 Complete: Global Test Accuracy: 50.50% ---\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Regular expression to find validation accuracies\n",
        "accuracies = re.findall(r'Validation Accuracy: (\\d+\\.\\d+)%', log)\n",
        "\n",
        "# Convert accuracies from string to float\n",
        "accuracies = [float(acc) for acc in accuracies]\n",
        "\n",
        "# Print accuracies\n",
        "print(\"Accuracies:\", accuracies)\n",
        "\n",
        "# Print size of the array\n",
        "print(\"Size of array:\", len(accuracies))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344b416d-2b52-4ca8-cfd7-60296f8ad3d2",
        "id": "wPdKra2qnYGr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies: [11.41, 10.1, 9.96, 9.85, 9.85, 9.82, 9.83, 9.83, 9.85, 9.89, 11.49, 11.37, 11.23, 11.5, 12.31, 11.58, 10.71, 10.07, 10.0, 9.93, 11.48, 10.44, 10.58, 10.39, 10.28, 10.47, 11.27, 11.55, 12.25, 12.64, 10.39, 9.95, 9.9, 9.89, 9.87, 9.87, 9.87, 9.87, 9.87, 9.87, 10.89, 10.67, 9.91, 9.85, 9.84, 9.84, 9.84, 9.84, 9.85, 9.85, 12.64, 12.62, 11.74, 12.25, 12.77, 13.15, 13.48, 14.91, 15.73, 16.03, 13.97, 14.24, 12.69, 12.68, 12.96, 13.94, 14.58, 14.44, 15.77, 16.67, 13.78, 13.68, 13.63, 14.11, 14.08, 14.45, 14.52, 14.65, 15.43, 16.25, 12.48, 10.35, 9.97, 9.96, 9.94, 9.98, 10.27, 10.51, 11.47, 12.15, 13.08, 12.04, 10.53, 10.09, 10.01, 10.1, 10.71, 11.71, 13.14, 13.79, 19.21, 19.31, 19.58, 19.79, 19.42, 19.33, 19.4, 20.73, 22.36, 23.26, 20.07, 20.06, 19.94, 20.12, 19.6, 19.73, 20.21, 21.57, 22.21, 22.84, 18.88, 19.56, 19.42, 19.43, 19.34, 19.54, 20.44, 21.9, 22.51, 22.93, 19.43, 18.83, 18.54, 18.21, 18.36, 18.28, 18.63, 20.34, 21.74, 22.74, 19.56, 19.95, 20.11, 19.8, 20.01, 20.08, 19.9, 20.67, 21.59, 23.08, 23.62, 24.08, 24.89, 25.16, 25.46, 26.37, 26.7, 26.71, 27.61, 28.35, 23.02, 23.54, 24.3, 24.99, 25.57, 25.95, 26.64, 26.96, 27.72, 27.77, 23.18, 23.43, 24.32, 24.56, 25.59, 25.91, 26.04, 26.88, 26.82, 28.16, 23.28, 23.73, 24.24, 24.78, 25.62, 26.06, 26.75, 27.31, 27.89, 28.33, 23.25, 23.19, 23.92, 24.87, 25.44, 26.08, 26.21, 26.57, 27.85, 28.01, 28.19, 29.54, 29.57, 30.39, 31.49, 31.85, 32.71, 32.01, 33.64, 34.13, 28.58, 28.99, 29.79, 30.8, 30.26, 31.81, 31.65, 32.79, 33.58, 34.34, 28.44, 29.4, 29.91, 30.37, 30.85, 31.37, 31.97, 32.6, 33.57, 34.15, 29.03, 28.88, 29.92, 30.62, 30.73, 30.88, 32.01, 32.33, 33.96, 34.24, 28.39, 28.38, 29.45, 30.56, 30.01, 31.36, 31.56, 32.12, 32.87, 33.01, 34.66, 34.89, 35.89, 35.54, 36.32, 37.14, 37.36, 37.57, 38.43, 38.73, 34.93, 34.92, 36.09, 36.21, 36.86, 37.18, 37.88, 37.73, 38.3, 39.0, 34.52, 35.0, 35.12, 36.62, 36.96, 37.51, 37.97, 38.06, 37.72, 38.14, 34.63, 35.34, 35.39, 36.0, 36.19, 37.3, 37.44, 38.29, 38.65, 38.79, 34.19, 34.93, 35.49, 35.67, 35.04, 36.95, 37.32, 37.7, 38.21, 38.35, 38.96, 40.15, 39.8, 40.69, 40.96, 41.02, 40.87, 42.08, 41.28, 41.99, 39.45, 39.25, 40.19, 40.87, 40.62, 40.0, 41.25, 41.33, 42.52, 41.41, 39.12, 39.83, 40.06, 40.54, 40.87, 40.59, 41.27, 41.85, 41.4, 42.66, 39.4, 39.69, 39.33, 39.91, 40.7, 40.86, 41.26, 41.29, 41.52, 41.56, 39.49, 38.77, 40.31, 40.25, 40.89, 40.49, 41.52, 41.71, 40.96, 41.83, 42.83, 43.51, 42.55, 44.05, 44.08, 43.71, 44.44, 44.02, 45.35, 45.05, 42.75, 43.37, 44.09, 43.65, 44.56, 42.7, 44.3, 45.44, 44.83, 45.73, 42.43, 43.52, 43.09, 43.96, 43.67, 44.1, 45.12, 43.69, 45.78, 45.8, 42.1, 43.5, 43.22, 43.89, 44.72, 44.76, 44.8, 44.57, 45.33, 45.19, 42.34, 43.49, 43.33, 44.23, 44.08, 44.43, 44.52, 44.71, 44.97, 44.29, 45.84, 45.95, 46.8, 46.71, 47.1, 46.5, 47.59, 47.32, 47.69, 47.56, 46.22, 46.65, 46.62, 46.09, 46.77, 46.47, 46.46, 47.25, 47.5, 46.64, 46.17, 46.32, 46.29, 46.47, 46.14, 47.05, 47.45, 47.7, 47.62, 47.55, 46.2, 46.44, 46.6, 47.05, 46.82, 46.45, 46.85, 47.21, 47.29, 47.11, 46.54, 46.47, 46.48, 46.45, 45.92, 46.6, 46.42, 47.03, 47.65, 47.9, 48.4, 47.94, 48.79, 48.56, 48.84, 49.64, 49.07, 49.57, 48.38, 49.07, 48.45, 47.65, 48.78, 48.92, 48.16, 48.84, 49.58, 49.31, 49.13, 49.58, 47.13, 49.1, 48.74, 48.14, 49.27, 49.14, 48.7, 49.54, 48.12, 49.34, 48.53, 47.83, 47.81, 48.26, 48.63, 48.82, 49.04, 49.44, 48.28, 50.1, 48.37, 48.27, 48.29, 47.08, 47.67, 49.28, 48.92, 49.09, 48.45, 49.78]\n",
            "Size of array: 500\n"
          ]
        }
      ]
    }
  ]
}