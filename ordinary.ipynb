{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahad31/Kl-FedDis-Research-/blob/main/ordinary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yELruI1IpCqt",
        "outputId": "f0c63c09-085e-45b2-c33c-f06e84cf9199"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 377 µs, sys: 0 ns, total: 377 µs\n",
            "Wall time: 391 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoJ24tiipdHG"
      },
      "outputs": [],
      "source": [
        "# Define VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.x_dim = x_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2*z_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 32x32\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :self.z_dim], h[:, self.z_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEU_HGlkpjMy"
      },
      "outputs": [],
      "source": [
        "# Define VAE training procedure\n",
        "def vae_train(vae: VAE, trainloader: DataLoader, epochs: int) -> None:\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = vae(inputs)\n",
        "            loss = vae_loss(recon_x, inputs, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77xTShYPp7Tp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIMyvsHZqA0S",
        "outputId": "ab730a03-e16f-4077-d271-3fca1232fa90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:06<00:00, 27.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBc6iayKqMoT"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1qRZ4OgqQkh"
      },
      "outputs": [],
      "source": [
        "# Create training and validation loaders\n",
        "trainloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-I3RRdp7qwie"
      },
      "outputs": [],
      "source": [
        "# Define VAE loss function\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv4Dbvl2q2za"
      },
      "outputs": [],
      "source": [
        "# Define training procedure for classification model\n",
        "def train(net: nn.Module, trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / (i+1):.3f}, Validation Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoIsl09zq76r"
      },
      "outputs": [],
      "source": [
        "# Define evaluation procedure\n",
        "def evaluate(net: nn.Module, testloader: DataLoader) -> float:\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4_GLIx3rL3l"
      },
      "outputs": [],
      "source": [
        "def initialize_clients(trainset, transform, batch_size, num_clients):\n",
        "    clients = {}\n",
        "    for i in range(num_clients):\n",
        "        client_trainset = torch.utils.data.Subset(trainset, range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients))\n",
        "        client_trainloader = torch.utils.data.DataLoader(client_trainset, batch_size=batch_size, shuffle=True)\n",
        "        clients[f\"client_{i}\"] = client_trainloader\n",
        "    return clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYhcZLZDrR6I"
      },
      "outputs": [],
      "source": [
        "def get_distribution_info(vae: VAE) -> Dict:\n",
        "    # Implement the logic to extract distribution information from the VAE\n",
        "    # This can involve computing statistics, parameters, or any other relevant information\n",
        "    # that can be used to generate augmented data\n",
        "\n",
        "    # Example implementation:\n",
        "    distribution_info = {\n",
        "        \"mean\": vae.encoder[-1].bias.data.cpu().numpy(),\n",
        "        \"std\": torch.exp(0.5 * vae.encoder[-1].weight.data).cpu().numpy()\n",
        "    }\n",
        "\n",
        "    return distribution_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4KAYT8XrV0I"
      },
      "outputs": [],
      "source": [
        "def send_distribution_info(distribution_info: Dict) -> None:\n",
        "    # Implement the logic to send the distribution information to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the distribution information to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VV25UuEreCu"
      },
      "outputs": [],
      "source": [
        "# Define logic to generate augmented data using Ordinary Normal distribution\n",
        "def generate_augmented_data(vae: VAE, distribution_info: Dict) -> torch.Tensor:\n",
        "    # Generate augmented data using Ordinary Normal distribution\n",
        "    mean = distribution_info[\"mean\"]\n",
        "    std = distribution_info[\"std\"]\n",
        "    augmented_data = torch.randn(64, vae.z_dim) * std + mean\n",
        "    return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCcpkdCHrmIR"
      },
      "outputs": [],
      "source": [
        "def federated_train(net: nn.Module, vae: VAE, trainloaders: Dict[str, DataLoader], trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    for epoch in range(epochs):\n",
        "        for client_id, client_trainloader in trainloaders.items():\n",
        "            # Train VAE on client data\n",
        "            vae_train(vae, client_trainloader, epochs=10)\n",
        "\n",
        "            # Share distribution information with global server\n",
        "            distribution_info = get_distribution_info(vae)\n",
        "            send_distribution_info(distribution_info)\n",
        "\n",
        "            # Receive distribution information from other clients\n",
        "            other_distribution_info = receive_distribution_info()\n",
        "\n",
        "            # Generate augmented data using received distribution information\n",
        "            augmented_data = generate_augmented_data(vae, other_distribution_info)\n",
        "\n",
        "            # Train classification model using local, augmented, and validation data\n",
        "            train(net, client_trainloader, valloader, epochs=10)\n",
        "\n",
        "            # Send model updates to global server\n",
        "            send_model_update(client_id, net.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFPgJKA4rwQ_"
      },
      "outputs": [],
      "source": [
        "# Define logic to receive distribution information from global server\n",
        "def receive_distribution_info() -> Dict:\n",
        "    # Receive distribution information logic\n",
        "    distribution_info = {\n",
        "        \"mean\": np.zeros(20),  # Adjust the size based on your latent space dimension\n",
        "        \"std\": np.ones(20)\n",
        "    }\n",
        "    return distribution_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7ficB30r2Qd"
      },
      "outputs": [],
      "source": [
        "def send_model_update(client_id: str, model_update: Dict) -> None:\n",
        "    # Implement the logic to send the model update to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the model update\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the model update to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuBS1wHyr4DW",
        "outputId": "84895fd8-92b6-406c-bf8c-15cc1ddb498d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Training Loss: 2.304, Validation Accuracy: 10.23%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.23%\n",
            "Epoch [3/10], Training Loss: 2.303, Validation Accuracy: 10.23%\n",
            "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 10.23%\n",
            "Epoch [5/10], Training Loss: 2.302, Validation Accuracy: 10.23%\n",
            "Epoch [6/10], Training Loss: 2.302, Validation Accuracy: 10.23%\n",
            "Epoch [7/10], Training Loss: 2.301, Validation Accuracy: 10.23%\n",
            "Epoch [8/10], Training Loss: 2.301, Validation Accuracy: 10.23%\n",
            "Epoch [9/10], Training Loss: 2.300, Validation Accuracy: 10.23%\n",
            "Epoch [10/10], Training Loss: 2.300, Validation Accuracy: 10.23%\n",
            "Epoch [1/10], Training Loss: 2.300, Validation Accuracy: 10.25%\n",
            "Epoch [2/10], Training Loss: 2.299, Validation Accuracy: 11.46%\n",
            "Epoch [3/10], Training Loss: 2.298, Validation Accuracy: 13.78%\n",
            "Epoch [4/10], Training Loss: 2.297, Validation Accuracy: 15.52%\n",
            "Epoch [5/10], Training Loss: 2.295, Validation Accuracy: 16.95%\n",
            "Epoch [6/10], Training Loss: 2.293, Validation Accuracy: 17.94%\n",
            "Epoch [7/10], Training Loss: 2.290, Validation Accuracy: 18.52%\n",
            "Epoch [8/10], Training Loss: 2.285, Validation Accuracy: 19.01%\n",
            "Epoch [9/10], Training Loss: 2.278, Validation Accuracy: 18.79%\n",
            "Epoch [10/10], Training Loss: 2.267, Validation Accuracy: 18.49%\n",
            "Epoch [1/10], Training Loss: 2.252, Validation Accuracy: 19.54%\n",
            "Epoch [2/10], Training Loss: 2.234, Validation Accuracy: 21.37%\n",
            "Epoch [3/10], Training Loss: 2.214, Validation Accuracy: 22.16%\n",
            "Epoch [4/10], Training Loss: 2.191, Validation Accuracy: 22.60%\n",
            "Epoch [5/10], Training Loss: 2.166, Validation Accuracy: 24.12%\n",
            "Epoch [6/10], Training Loss: 2.138, Validation Accuracy: 24.57%\n",
            "Epoch [7/10], Training Loss: 2.107, Validation Accuracy: 25.01%\n",
            "Epoch [8/10], Training Loss: 2.080, Validation Accuracy: 25.39%\n",
            "Epoch [9/10], Training Loss: 2.056, Validation Accuracy: 26.09%\n",
            "Epoch [10/10], Training Loss: 2.035, Validation Accuracy: 26.18%\n",
            "Epoch [1/10], Training Loss: 2.029, Validation Accuracy: 26.25%\n",
            "Epoch [2/10], Training Loss: 2.014, Validation Accuracy: 26.81%\n",
            "Epoch [3/10], Training Loss: 2.000, Validation Accuracy: 27.36%\n",
            "Epoch [4/10], Training Loss: 1.987, Validation Accuracy: 27.94%\n",
            "Epoch [5/10], Training Loss: 1.974, Validation Accuracy: 28.34%\n",
            "Epoch [6/10], Training Loss: 1.961, Validation Accuracy: 29.47%\n",
            "Epoch [7/10], Training Loss: 1.949, Validation Accuracy: 30.21%\n",
            "Epoch [8/10], Training Loss: 1.937, Validation Accuracy: 30.08%\n",
            "Epoch [9/10], Training Loss: 1.924, Validation Accuracy: 31.13%\n",
            "Epoch [10/10], Training Loss: 1.911, Validation Accuracy: 31.12%\n",
            "Epoch [1/10], Training Loss: 1.914, Validation Accuracy: 32.30%\n",
            "Epoch [2/10], Training Loss: 1.899, Validation Accuracy: 32.37%\n",
            "Epoch [3/10], Training Loss: 1.885, Validation Accuracy: 32.97%\n",
            "Epoch [4/10], Training Loss: 1.867, Validation Accuracy: 33.08%\n",
            "Epoch [5/10], Training Loss: 1.852, Validation Accuracy: 34.01%\n",
            "Epoch [6/10], Training Loss: 1.833, Validation Accuracy: 35.06%\n",
            "Epoch [7/10], Training Loss: 1.817, Validation Accuracy: 35.08%\n",
            "Epoch [8/10], Training Loss: 1.799, Validation Accuracy: 35.79%\n",
            "Epoch [9/10], Training Loss: 1.784, Validation Accuracy: 35.44%\n",
            "Epoch [10/10], Training Loss: 1.766, Validation Accuracy: 36.18%\n",
            "Epoch [1/10], Training Loss: 1.771, Validation Accuracy: 37.31%\n",
            "Epoch [2/10], Training Loss: 1.749, Validation Accuracy: 37.95%\n",
            "Epoch [3/10], Training Loss: 1.732, Validation Accuracy: 38.59%\n",
            "Epoch [4/10], Training Loss: 1.716, Validation Accuracy: 39.16%\n",
            "Epoch [5/10], Training Loss: 1.701, Validation Accuracy: 39.06%\n",
            "Epoch [6/10], Training Loss: 1.686, Validation Accuracy: 39.34%\n",
            "Epoch [7/10], Training Loss: 1.671, Validation Accuracy: 40.02%\n",
            "Epoch [8/10], Training Loss: 1.652, Validation Accuracy: 40.72%\n",
            "Epoch [9/10], Training Loss: 1.633, Validation Accuracy: 41.01%\n",
            "Epoch [10/10], Training Loss: 1.620, Validation Accuracy: 41.10%\n",
            "Epoch [1/10], Training Loss: 1.623, Validation Accuracy: 41.92%\n",
            "Epoch [2/10], Training Loss: 1.602, Validation Accuracy: 42.37%\n",
            "Epoch [3/10], Training Loss: 1.591, Validation Accuracy: 42.94%\n",
            "Epoch [4/10], Training Loss: 1.568, Validation Accuracy: 42.51%\n",
            "Epoch [5/10], Training Loss: 1.552, Validation Accuracy: 42.76%\n",
            "Epoch [6/10], Training Loss: 1.544, Validation Accuracy: 43.61%\n",
            "Epoch [7/10], Training Loss: 1.530, Validation Accuracy: 44.58%\n",
            "Epoch [8/10], Training Loss: 1.513, Validation Accuracy: 44.99%\n",
            "Epoch [9/10], Training Loss: 1.503, Validation Accuracy: 43.56%\n",
            "Epoch [10/10], Training Loss: 1.495, Validation Accuracy: 45.06%\n",
            "Epoch [1/10], Training Loss: 1.537, Validation Accuracy: 45.58%\n",
            "Epoch [2/10], Training Loss: 1.514, Validation Accuracy: 45.11%\n",
            "Epoch [3/10], Training Loss: 1.499, Validation Accuracy: 45.62%\n",
            "Epoch [4/10], Training Loss: 1.488, Validation Accuracy: 46.11%\n",
            "Epoch [5/10], Training Loss: 1.484, Validation Accuracy: 46.03%\n",
            "Epoch [6/10], Training Loss: 1.467, Validation Accuracy: 46.40%\n",
            "Epoch [7/10], Training Loss: 1.460, Validation Accuracy: 46.78%\n",
            "Epoch [8/10], Training Loss: 1.453, Validation Accuracy: 46.55%\n",
            "Epoch [9/10], Training Loss: 1.440, Validation Accuracy: 46.96%\n",
            "Epoch [10/10], Training Loss: 1.436, Validation Accuracy: 46.70%\n",
            "Epoch [1/10], Training Loss: 1.485, Validation Accuracy: 47.64%\n",
            "Epoch [2/10], Training Loss: 1.468, Validation Accuracy: 47.54%\n",
            "Epoch [3/10], Training Loss: 1.457, Validation Accuracy: 47.93%\n",
            "Epoch [4/10], Training Loss: 1.447, Validation Accuracy: 47.99%\n",
            "Epoch [5/10], Training Loss: 1.434, Validation Accuracy: 46.94%\n",
            "Epoch [6/10], Training Loss: 1.421, Validation Accuracy: 47.38%\n",
            "Epoch [7/10], Training Loss: 1.414, Validation Accuracy: 48.14%\n",
            "Epoch [8/10], Training Loss: 1.404, Validation Accuracy: 48.09%\n",
            "Epoch [9/10], Training Loss: 1.404, Validation Accuracy: 48.04%\n",
            "Epoch [10/10], Training Loss: 1.392, Validation Accuracy: 48.43%\n",
            "Epoch [1/10], Training Loss: 1.424, Validation Accuracy: 48.60%\n",
            "Epoch [2/10], Training Loss: 1.417, Validation Accuracy: 49.05%\n",
            "Epoch [3/10], Training Loss: 1.404, Validation Accuracy: 49.45%\n",
            "Epoch [4/10], Training Loss: 1.391, Validation Accuracy: 49.41%\n",
            "Epoch [5/10], Training Loss: 1.390, Validation Accuracy: 49.01%\n",
            "Epoch [6/10], Training Loss: 1.374, Validation Accuracy: 49.63%\n",
            "Epoch [7/10], Training Loss: 1.360, Validation Accuracy: 49.19%\n",
            "Epoch [8/10], Training Loss: 1.355, Validation Accuracy: 49.01%\n",
            "Epoch [9/10], Training Loss: 1.358, Validation Accuracy: 49.84%\n",
            "Epoch [10/10], Training Loss: 1.333, Validation Accuracy: 50.53%\n",
            "Epoch [1/10], Training Loss: 1.399, Validation Accuracy: 49.23%\n",
            "Epoch [2/10], Training Loss: 1.385, Validation Accuracy: 49.87%\n",
            "Epoch [3/10], Training Loss: 1.368, Validation Accuracy: 50.19%\n",
            "Epoch [4/10], Training Loss: 1.365, Validation Accuracy: 50.20%\n",
            "Epoch [5/10], Training Loss: 1.358, Validation Accuracy: 49.20%\n",
            "Epoch [6/10], Training Loss: 1.344, Validation Accuracy: 50.13%\n",
            "Epoch [7/10], Training Loss: 1.329, Validation Accuracy: 50.02%\n",
            "Epoch [8/10], Training Loss: 1.323, Validation Accuracy: 51.12%\n",
            "Epoch [9/10], Training Loss: 1.321, Validation Accuracy: 50.69%\n",
            "Epoch [10/10], Training Loss: 1.306, Validation Accuracy: 50.69%\n",
            "Epoch [1/10], Training Loss: 1.365, Validation Accuracy: 50.44%\n",
            "Epoch [2/10], Training Loss: 1.350, Validation Accuracy: 51.17%\n",
            "Epoch [3/10], Training Loss: 1.328, Validation Accuracy: 51.06%\n",
            "Epoch [4/10], Training Loss: 1.318, Validation Accuracy: 51.89%\n",
            "Epoch [5/10], Training Loss: 1.315, Validation Accuracy: 50.97%\n",
            "Epoch [6/10], Training Loss: 1.298, Validation Accuracy: 51.46%\n",
            "Epoch [7/10], Training Loss: 1.289, Validation Accuracy: 51.64%\n",
            "Epoch [8/10], Training Loss: 1.281, Validation Accuracy: 51.94%\n",
            "Epoch [9/10], Training Loss: 1.273, Validation Accuracy: 50.88%\n",
            "Epoch [10/10], Training Loss: 1.270, Validation Accuracy: 51.79%\n",
            "Epoch [1/10], Training Loss: 1.339, Validation Accuracy: 50.43%\n",
            "Epoch [2/10], Training Loss: 1.323, Validation Accuracy: 51.94%\n",
            "Epoch [3/10], Training Loss: 1.305, Validation Accuracy: 52.60%\n",
            "Epoch [4/10], Training Loss: 1.291, Validation Accuracy: 51.15%\n",
            "Epoch [5/10], Training Loss: 1.277, Validation Accuracy: 52.98%\n",
            "Epoch [6/10], Training Loss: 1.265, Validation Accuracy: 52.64%\n",
            "Epoch [7/10], Training Loss: 1.258, Validation Accuracy: 52.48%\n",
            "Epoch [8/10], Training Loss: 1.248, Validation Accuracy: 52.99%\n",
            "Epoch [9/10], Training Loss: 1.237, Validation Accuracy: 53.09%\n",
            "Epoch [10/10], Training Loss: 1.225, Validation Accuracy: 53.21%\n",
            "Epoch [1/10], Training Loss: 1.317, Validation Accuracy: 52.81%\n",
            "Epoch [2/10], Training Loss: 1.303, Validation Accuracy: 53.65%\n",
            "Epoch [3/10], Training Loss: 1.272, Validation Accuracy: 53.06%\n",
            "Epoch [4/10], Training Loss: 1.259, Validation Accuracy: 53.99%\n",
            "Epoch [5/10], Training Loss: 1.252, Validation Accuracy: 53.82%\n",
            "Epoch [6/10], Training Loss: 1.239, Validation Accuracy: 53.82%\n",
            "Epoch [7/10], Training Loss: 1.232, Validation Accuracy: 53.86%\n",
            "Epoch [8/10], Training Loss: 1.218, Validation Accuracy: 53.25%\n",
            "Epoch [9/10], Training Loss: 1.207, Validation Accuracy: 53.63%\n",
            "Epoch [10/10], Training Loss: 1.197, Validation Accuracy: 54.19%\n",
            "Epoch [1/10], Training Loss: 1.278, Validation Accuracy: 53.00%\n",
            "Epoch [2/10], Training Loss: 1.255, Validation Accuracy: 53.64%\n",
            "Epoch [3/10], Training Loss: 1.244, Validation Accuracy: 54.42%\n",
            "Epoch [4/10], Training Loss: 1.219, Validation Accuracy: 53.17%\n",
            "Epoch [5/10], Training Loss: 1.225, Validation Accuracy: 54.05%\n",
            "Epoch [6/10], Training Loss: 1.204, Validation Accuracy: 54.19%\n",
            "Epoch [7/10], Training Loss: 1.194, Validation Accuracy: 54.50%\n",
            "Epoch [8/10], Training Loss: 1.175, Validation Accuracy: 54.63%\n",
            "Epoch [9/10], Training Loss: 1.179, Validation Accuracy: 54.22%\n",
            "Epoch [10/10], Training Loss: 1.161, Validation Accuracy: 53.46%\n",
            "Epoch [1/10], Training Loss: 1.280, Validation Accuracy: 54.06%\n",
            "Epoch [2/10], Training Loss: 1.254, Validation Accuracy: 53.74%\n",
            "Epoch [3/10], Training Loss: 1.230, Validation Accuracy: 55.11%\n",
            "Epoch [4/10], Training Loss: 1.211, Validation Accuracy: 54.77%\n",
            "Epoch [5/10], Training Loss: 1.203, Validation Accuracy: 55.03%\n",
            "Epoch [6/10], Training Loss: 1.189, Validation Accuracy: 55.11%\n",
            "Epoch [7/10], Training Loss: 1.176, Validation Accuracy: 54.42%\n",
            "Epoch [8/10], Training Loss: 1.177, Validation Accuracy: 54.69%\n",
            "Epoch [9/10], Training Loss: 1.165, Validation Accuracy: 54.84%\n",
            "Epoch [10/10], Training Loss: 1.159, Validation Accuracy: 55.49%\n",
            "Epoch [1/10], Training Loss: 1.246, Validation Accuracy: 54.99%\n",
            "Epoch [2/10], Training Loss: 1.215, Validation Accuracy: 55.43%\n",
            "Epoch [3/10], Training Loss: 1.189, Validation Accuracy: 55.47%\n",
            "Epoch [4/10], Training Loss: 1.177, Validation Accuracy: 55.47%\n",
            "Epoch [5/10], Training Loss: 1.164, Validation Accuracy: 55.49%\n",
            "Epoch [6/10], Training Loss: 1.157, Validation Accuracy: 55.40%\n",
            "Epoch [7/10], Training Loss: 1.139, Validation Accuracy: 55.52%\n",
            "Epoch [8/10], Training Loss: 1.143, Validation Accuracy: 54.85%\n",
            "Epoch [9/10], Training Loss: 1.126, Validation Accuracy: 55.73%\n",
            "Epoch [10/10], Training Loss: 1.117, Validation Accuracy: 55.45%\n",
            "Epoch [1/10], Training Loss: 1.222, Validation Accuracy: 55.06%\n",
            "Epoch [2/10], Training Loss: 1.183, Validation Accuracy: 56.00%\n",
            "Epoch [3/10], Training Loss: 1.169, Validation Accuracy: 55.84%\n",
            "Epoch [4/10], Training Loss: 1.156, Validation Accuracy: 55.19%\n",
            "Epoch [5/10], Training Loss: 1.140, Validation Accuracy: 56.13%\n",
            "Epoch [6/10], Training Loss: 1.119, Validation Accuracy: 55.50%\n",
            "Epoch [7/10], Training Loss: 1.117, Validation Accuracy: 56.33%\n",
            "Epoch [8/10], Training Loss: 1.102, Validation Accuracy: 56.18%\n",
            "Epoch [9/10], Training Loss: 1.097, Validation Accuracy: 55.46%\n",
            "Epoch [10/10], Training Loss: 1.086, Validation Accuracy: 55.39%\n",
            "Epoch [1/10], Training Loss: 1.205, Validation Accuracy: 56.28%\n",
            "Epoch [2/10], Training Loss: 1.163, Validation Accuracy: 56.27%\n",
            "Epoch [3/10], Training Loss: 1.140, Validation Accuracy: 56.61%\n",
            "Epoch [4/10], Training Loss: 1.124, Validation Accuracy: 56.06%\n",
            "Epoch [5/10], Training Loss: 1.118, Validation Accuracy: 56.00%\n",
            "Epoch [6/10], Training Loss: 1.107, Validation Accuracy: 56.33%\n",
            "Epoch [7/10], Training Loss: 1.090, Validation Accuracy: 56.76%\n",
            "Epoch [8/10], Training Loss: 1.078, Validation Accuracy: 56.33%\n",
            "Epoch [9/10], Training Loss: 1.070, Validation Accuracy: 56.59%\n",
            "Epoch [10/10], Training Loss: 1.060, Validation Accuracy: 54.75%\n",
            "Epoch [1/10], Training Loss: 1.187, Validation Accuracy: 55.94%\n",
            "Epoch [2/10], Training Loss: 1.148, Validation Accuracy: 56.10%\n",
            "Epoch [3/10], Training Loss: 1.125, Validation Accuracy: 56.91%\n",
            "Epoch [4/10], Training Loss: 1.097, Validation Accuracy: 57.52%\n",
            "Epoch [5/10], Training Loss: 1.085, Validation Accuracy: 56.92%\n",
            "Epoch [6/10], Training Loss: 1.077, Validation Accuracy: 57.44%\n",
            "Epoch [7/10], Training Loss: 1.059, Validation Accuracy: 57.86%\n",
            "Epoch [8/10], Training Loss: 1.061, Validation Accuracy: 57.09%\n",
            "Epoch [9/10], Training Loss: 1.034, Validation Accuracy: 57.42%\n",
            "Epoch [10/10], Training Loss: 1.020, Validation Accuracy: 57.43%\n",
            "Epoch [1/10], Training Loss: 1.180, Validation Accuracy: 56.95%\n",
            "Epoch [2/10], Training Loss: 1.151, Validation Accuracy: 57.59%\n",
            "Epoch [3/10], Training Loss: 1.115, Validation Accuracy: 55.95%\n",
            "Epoch [4/10], Training Loss: 1.101, Validation Accuracy: 58.20%\n",
            "Epoch [5/10], Training Loss: 1.079, Validation Accuracy: 57.83%\n",
            "Epoch [6/10], Training Loss: 1.067, Validation Accuracy: 58.35%\n",
            "Epoch [7/10], Training Loss: 1.055, Validation Accuracy: 57.10%\n",
            "Epoch [8/10], Training Loss: 1.043, Validation Accuracy: 57.98%\n",
            "Epoch [9/10], Training Loss: 1.033, Validation Accuracy: 57.27%\n",
            "Epoch [10/10], Training Loss: 1.019, Validation Accuracy: 57.62%\n",
            "Epoch [1/10], Training Loss: 1.150, Validation Accuracy: 57.93%\n",
            "Epoch [2/10], Training Loss: 1.113, Validation Accuracy: 57.88%\n",
            "Epoch [3/10], Training Loss: 1.082, Validation Accuracy: 57.93%\n",
            "Epoch [4/10], Training Loss: 1.067, Validation Accuracy: 57.40%\n",
            "Epoch [5/10], Training Loss: 1.063, Validation Accuracy: 57.24%\n",
            "Epoch [6/10], Training Loss: 1.035, Validation Accuracy: 58.08%\n",
            "Epoch [7/10], Training Loss: 1.016, Validation Accuracy: 58.42%\n",
            "Epoch [8/10], Training Loss: 1.005, Validation Accuracy: 57.81%\n",
            "Epoch [9/10], Training Loss: 0.997, Validation Accuracy: 56.74%\n",
            "Epoch [10/10], Training Loss: 0.982, Validation Accuracy: 57.90%\n",
            "Epoch [1/10], Training Loss: 1.133, Validation Accuracy: 58.45%\n",
            "Epoch [2/10], Training Loss: 1.085, Validation Accuracy: 58.95%\n",
            "Epoch [3/10], Training Loss: 1.066, Validation Accuracy: 58.77%\n",
            "Epoch [4/10], Training Loss: 1.048, Validation Accuracy: 58.18%\n",
            "Epoch [5/10], Training Loss: 1.026, Validation Accuracy: 58.80%\n",
            "Epoch [6/10], Training Loss: 1.008, Validation Accuracy: 58.76%\n",
            "Epoch [7/10], Training Loss: 0.996, Validation Accuracy: 58.72%\n",
            "Epoch [8/10], Training Loss: 0.978, Validation Accuracy: 57.66%\n",
            "Epoch [9/10], Training Loss: 0.977, Validation Accuracy: 58.33%\n",
            "Epoch [10/10], Training Loss: 0.961, Validation Accuracy: 58.42%\n",
            "Epoch [1/10], Training Loss: 1.117, Validation Accuracy: 58.56%\n",
            "Epoch [2/10], Training Loss: 1.077, Validation Accuracy: 59.24%\n",
            "Epoch [3/10], Training Loss: 1.049, Validation Accuracy: 58.19%\n",
            "Epoch [4/10], Training Loss: 1.027, Validation Accuracy: 59.27%\n",
            "Epoch [5/10], Training Loss: 1.000, Validation Accuracy: 57.36%\n",
            "Epoch [6/10], Training Loss: 0.988, Validation Accuracy: 58.79%\n",
            "Epoch [7/10], Training Loss: 0.974, Validation Accuracy: 58.10%\n",
            "Epoch [8/10], Training Loss: 0.958, Validation Accuracy: 57.91%\n",
            "Epoch [9/10], Training Loss: 0.949, Validation Accuracy: 58.56%\n",
            "Epoch [10/10], Training Loss: 0.938, Validation Accuracy: 58.36%\n",
            "Epoch [1/10], Training Loss: 1.100, Validation Accuracy: 59.29%\n",
            "Epoch [2/10], Training Loss: 1.046, Validation Accuracy: 58.20%\n",
            "Epoch [3/10], Training Loss: 1.024, Validation Accuracy: 59.30%\n",
            "Epoch [4/10], Training Loss: 0.993, Validation Accuracy: 59.67%\n",
            "Epoch [5/10], Training Loss: 0.985, Validation Accuracy: 59.64%\n",
            "Epoch [6/10], Training Loss: 0.956, Validation Accuracy: 59.00%\n",
            "Epoch [7/10], Training Loss: 0.940, Validation Accuracy: 59.34%\n",
            "Epoch [8/10], Training Loss: 0.932, Validation Accuracy: 59.59%\n",
            "Epoch [9/10], Training Loss: 0.908, Validation Accuracy: 59.34%\n",
            "Epoch [10/10], Training Loss: 0.909, Validation Accuracy: 58.80%\n",
            "Test Accuracy: 57.69%\n",
            "CPU times: user 1h 46min 34s, sys: 47.5 s, total: 1h 47min 21s\n",
            "Wall time: 1h 56min 53s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=5)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUVMC-RFkv6L"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import truncnorm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from typing import Dict, Tuple\n",
        "\n",
        "# Define VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.x_dim = x_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2*z_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 32x32\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :self.z_dim], h[:, self.z_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "# Define VAE training procedure\n",
        "def vae_train(vae: VAE, trainloader: DataLoader, epochs: int) -> None:\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        vae.train()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = vae(inputs)\n",
        "            loss = vae_loss(recon_x, inputs, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "# Define classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create training and validation loaders\n",
        "trainloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "# Define VAE loss function\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "# Define training procedure for classification model\n",
        "def train(net: nn.Module, trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / (i+1):.3f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define evaluation procedure\n",
        "def evaluate(net: nn.Module, testloader: DataLoader) -> float:\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize clients\n",
        "def initialize_clients(trainset, transform, batch_size, num_clients):\n",
        "    clients = {}\n",
        "    for i in range(num_clients):\n",
        "        client_trainset = torch.utils.data.Subset(trainset, range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients))\n",
        "        client_trainloader = torch.utils.data.DataLoader(client_trainset, batch_size=batch_size, shuffle=True)\n",
        "        clients[f\"client_{i}\"] = client_trainloader\n",
        "    return clients\n",
        "\n",
        "def get_distribution_info(vae: VAE) -> Dict:\n",
        "    # Implement the logic to extract distribution information from the VAE\n",
        "    # This can involve computing statistics, parameters, or any other relevant information\n",
        "    # that can be used to generate augmented data\n",
        "\n",
        "    # Example implementation:\n",
        "    distribution_info = {\n",
        "        \"mean\": vae.encoder[-1].bias.data.cpu().numpy(),\n",
        "        \"std\": torch.exp(0.5 * vae.encoder[-1].weight.data).cpu().numpy()\n",
        "    }\n",
        "\n",
        "    return distribution_info\n",
        "\n",
        "def send_distribution_info(distribution_info: Dict) -> None:\n",
        "    # Implement the logic to send the distribution information to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the distribution information to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n",
        "\n",
        "\n",
        "# Define logic to generate augmented data using Truncated Normal distribution\n",
        "def generate_augmented_data(vae: VAE, distribution_info: Dict) -> torch.Tensor:\n",
        "    # Generate augmented data using Truncated Normal distribution\n",
        "    mean = distribution_info[\"mean\"]\n",
        "    std = distribution_info[\"std\"]\n",
        "    a = (0 - mean) / std\n",
        "    b = np.inf\n",
        "    augmented_data = torch.from_numpy(truncnorm.rvs(a, b, loc=mean, scale=std, size=(64, vae.z_dim))).float()\n",
        "    return augmented_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def federated_train(net: nn.Module, vae: VAE, trainloaders: Dict[str, DataLoader], trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    for epoch in range(epochs):\n",
        "        for client_id, client_trainloader in trainloaders.items():\n",
        "            # Train VAE on client data\n",
        "            vae_train(vae, client_trainloader, epochs=10)\n",
        "\n",
        "            # Share distribution information with global server\n",
        "            distribution_info = get_distribution_info(vae)\n",
        "            send_distribution_info(distribution_info)\n",
        "\n",
        "            # Receive distribution information from other clients\n",
        "            other_distribution_info = receive_distribution_info()\n",
        "\n",
        "            # Generate augmented data using received distribution information\n",
        "            augmented_data = generate_augmented_data(vae, other_distribution_info)\n",
        "\n",
        "            # Train classification model using local, augmented, and validation data\n",
        "            train(net, client_trainloader, valloader, epochs=10)\n",
        "\n",
        "            # Send model updates to global server\n",
        "            send_model_update(client_id, net.state_dict())\n",
        "\n",
        "\n",
        "def receive_distribution_info() -> Dict:\n",
        "    # Implement the logic to receive the distribution information from the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to receive the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Receive the distribution information from the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to receive the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to receive the information\n",
        "    distribution_info = {\n",
        "        \"mean\": np.zeros(20),\n",
        "        \"std\": np.ones(20)\n",
        "    }\n",
        "    return distribution_info\n",
        "\n",
        "def send_model_update(client_id: str, model_update: Dict) -> None:\n",
        "    # Implement the logic to send the model update to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the model update\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the model update to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n",
        "\n",
        "# Define global server procedure\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=10)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLRxlHF18qzo",
        "outputId": "a0604e1f-a826-40bf-b4b2-516d54ffadd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracies: [10.23, 10.39, 10.4, 10.46, 10.51, 11.06, 11.38, 12.02, 12.71, 14.52, 17.72, 17.84, 16.83, 17.6, 19.17, 20.78, 22.38, 23.42, 24.32, 26.29, 26.32, 26.74, 27.73, 28.39, 28.82, 29.19, 29.31, 29.99, 30.69, 31.64, 32.97, 33.05, 34.13, 34.44, 34.67, 35.97, 36.63, 36.75, 37.37, 38.02, 37.85, 39.17, 39.35, 39.82, 39.85, 40.52, 41.12, 40.65, 41.61, 42.0, 42.16, 41.07, 42.26, 42.12, 43.3, 43.31, 43.59, 44.72, 43.08, 44.2, 44.49, 44.97, 44.74, 45.18, 45.09, 45.35, 45.75, 45.42, 46.19, 46.37, 46.75, 46.4, 47.26, 46.66, 47.4, 47.26, 46.78, 47.24, 47.41, 47.62, 48.26, 47.29, 48.46, 47.92, 48.9, 48.59, 48.0, 48.68, 48.55, 48.74, 49.03, 49.57, 49.46, 49.47, 49.49, 50.03, 49.5, 49.78, 50.29, 50.01, 50.54, 49.81, 50.71, 51.03, 51.24, 50.52, 51.22, 51.07, 51.01, 50.84, 51.86, 51.89, 51.9, 52.18, 51.86, 52.5, 52.05, 50.8, 52.27, 52.33, 52.94, 52.61, 52.37, 52.04, 52.91, 52.78, 52.36, 53.43, 53.43, 53.06, 53.18, 53.77, 53.35, 53.48, 53.38, 53.05, 53.4, 53.66, 53.54, 54.2, 53.92, 53.26, 54.0, 54.25, 53.4, 54.27, 53.64, 54.58, 54.28, 54.55, 54.3, 55.39, 55.22, 55.29, 54.05, 55.6, 55.25, 54.18, 55.79, 55.39, 55.35, 55.93, 56.11, 56.15, 56.2, 55.83, 56.08, 56.06, 56.1, 54.38, 56.58, 56.47, 56.87, 56.7, 56.62, 56.9, 56.71, 56.52, 56.13, 56.61, 56.98, 56.16, 57.32, 56.86, 57.18, 57.17, 57.05, 56.92, 57.95, 56.62, 58.08, 57.04, 56.6, 57.53, 57.85, 56.6, 57.85, 57.37, 57.73, 57.26, 57.98, 57.94, 57.44, 58.03, 57.91, 58.25, 58.16, 58.38, 57.65, 58.61, 56.73, 57.65, 58.57, 58.43, 58.48, 58.69, 58.49, 58.67, 58.06, 57.54, 58.58, 58.84, 58.49, 58.59, 58.61, 58.33, 58.84, 58.53, 59.15, 58.63, 58.13, 58.83, 59.03, 59.1, 58.39, 58.98, 59.09, 59.0, 57.83, 58.77, 57.96, 59.08, 59.17, 59.1, 59.45, 58.52, 58.91, 59.06, 58.64, 59.15, 59.78, 59.45, 59.84, 58.81, 58.99, 59.27, 59.94, 59.54, 59.55, 58.33, 59.44, 59.81, 59.61, 58.84, 60.43, 59.06, 59.7, 60.03, 59.71, 59.29, 60.1, 60.12, 60.36, 59.86, 60.17, 59.83, 60.0, 59.51, 60.01, 59.38, 59.24, 59.76, 60.19, 60.48, 59.82, 60.22, 59.36, 59.22, 59.71, 58.98, 60.22, 59.12, 60.01, 59.59, 60.23, 60.0, 60.27, 60.26, 59.79, 59.36, 60.19, 60.71, 60.27, 60.66, 59.14, 60.96, 60.14, 60.43, 60.2, 60.82, 60.6, 61.42, 60.41, 60.87, 60.36, 60.32, 60.45, 60.25, 59.89, 60.73, 60.67, 60.58, 60.78, 60.89, 60.95, 60.69, 60.93, 60.7, 60.77, 61.07, 60.83, 61.02, 60.91, 60.02, 60.91, 60.7, 60.32, 60.83, 59.72, 60.95, 59.98, 60.47, 60.69, 60.36, 60.48, 61.11, 60.42, 60.92, 60.6, 59.79, 60.13, 60.84, 61.15, 61.19, 60.74, 59.01, 60.74, 61.23, 60.52, 60.61, 61.67, 61.2, 60.74, 61.38, 61.29, 61.16, 60.29, 60.64, 61.48, 60.8, 61.04, 61.06, 61.36, 61.31, 61.41, 61.24, 61.37, 61.25, 60.79, 60.72, 60.62, 61.22, 60.87, 61.13, 60.99, 60.44, 58.91, 60.34, 60.92, 60.49, 60.46, 59.97, 59.86, 60.63, 60.85, 61.18, 60.24, 60.66, 60.75, 60.2, 60.99, 61.16, 60.21, 61.58, 61.09, 61.55, 61.47, 60.93, 61.45, 61.18, 60.46, 61.45, 61.51, 61.59, 61.45, 61.19, 61.56, 61.38, 61.28, 60.69, 60.79, 61.49, 61.15, 61.6, 60.88, 61.32, 61.79, 61.34, 60.26, 61.27, 60.71, 61.1, 61.37, 60.79, 61.31, 61.27, 60.94, 60.72, 61.06, 60.4, 60.53, 60.56, 59.76, 60.99, 60.52, 60.46, 60.25, 60.14, 60.94, 59.9, 60.67, 61.56, 61.0, 61.21, 61.82, 61.73, 61.31, 60.66, 61.46, 60.34, 60.61, 61.47, 59.98, 60.94, 61.45, 61.44, 61.21, 60.77, 60.86, 60.7, 61.29, 60.2, 61.37, 61.41, 60.84, 61.21, 61.0, 60.84, 60.91, 61.12, 61.13, 61.0, 61.37, 61.69, 61.54, 60.88, 61.23, 60.62, 60.74, 60.85, 60.45, 60.59, 60.86, 60.2, 60.48, 60.94, 61.03, 60.52, 59.92, 60.18]\n",
            "Size of array: 500\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Your provided text\n",
        "log = \"\"\"\n",
        "Epoch [1/10], Training Loss: 2.304, Validation Accuracy: 10.23%\n",
        "Epoch [2/10], Training Loss: 2.303, Validation Accuracy: 10.39%\n",
        "Epoch [3/10], Training Loss: 2.302, Validation Accuracy: 10.40%\n",
        "Epoch [4/10], Training Loss: 2.301, Validation Accuracy: 10.46%\n",
        "Epoch [5/10], Training Loss: 2.300, Validation Accuracy: 10.51%\n",
        "Epoch [6/10], Training Loss: 2.299, Validation Accuracy: 11.06%\n",
        "Epoch [7/10], Training Loss: 2.297, Validation Accuracy: 11.38%\n",
        "Epoch [8/10], Training Loss: 2.295, Validation Accuracy: 12.02%\n",
        "Epoch [9/10], Training Loss: 2.293, Validation Accuracy: 12.71%\n",
        "Epoch [10/10], Training Loss: 2.289, Validation Accuracy: 14.52%\n",
        "Epoch [1/10], Training Loss: 2.286, Validation Accuracy: 17.72%\n",
        "Epoch [2/10], Training Loss: 2.279, Validation Accuracy: 17.84%\n",
        "Epoch [3/10], Training Loss: 2.267, Validation Accuracy: 16.83%\n",
        "Epoch [4/10], Training Loss: 2.250, Validation Accuracy: 17.60%\n",
        "Epoch [5/10], Training Loss: 2.228, Validation Accuracy: 19.17%\n",
        "Epoch [6/10], Training Loss: 2.204, Validation Accuracy: 20.78%\n",
        "Epoch [7/10], Training Loss: 2.176, Validation Accuracy: 22.38%\n",
        "Epoch [8/10], Training Loss: 2.146, Validation Accuracy: 23.42%\n",
        "Epoch [9/10], Training Loss: 2.110, Validation Accuracy: 24.32%\n",
        "Epoch [10/10], Training Loss: 2.072, Validation Accuracy: 26.29%\n",
        "Epoch [1/10], Training Loss: 2.046, Validation Accuracy: 26.32%\n",
        "Epoch [2/10], Training Loss: 2.013, Validation Accuracy: 26.74%\n",
        "Epoch [3/10], Training Loss: 1.985, Validation Accuracy: 27.73%\n",
        "Epoch [4/10], Training Loss: 1.962, Validation Accuracy: 28.39%\n",
        "Epoch [5/10], Training Loss: 1.943, Validation Accuracy: 28.82%\n",
        "Epoch [6/10], Training Loss: 1.927, Validation Accuracy: 29.19%\n",
        "Epoch [7/10], Training Loss: 1.908, Validation Accuracy: 29.31%\n",
        "Epoch [8/10], Training Loss: 1.892, Validation Accuracy: 29.99%\n",
        "Epoch [9/10], Training Loss: 1.874, Validation Accuracy: 30.69%\n",
        "Epoch [10/10], Training Loss: 1.855, Validation Accuracy: 31.64%\n",
        "Epoch [1/10], Training Loss: 1.850, Validation Accuracy: 32.97%\n",
        "Epoch [2/10], Training Loss: 1.825, Validation Accuracy: 33.05%\n",
        "Epoch [3/10], Training Loss: 1.806, Validation Accuracy: 34.13%\n",
        "Epoch [4/10], Training Loss: 1.788, Validation Accuracy: 34.44%\n",
        "Epoch [5/10], Training Loss: 1.766, Validation Accuracy: 34.67%\n",
        "Epoch [6/10], Training Loss: 1.752, Validation Accuracy: 35.97%\n",
        "Epoch [7/10], Training Loss: 1.734, Validation Accuracy: 36.63%\n",
        "Epoch [8/10], Training Loss: 1.721, Validation Accuracy: 36.75%\n",
        "Epoch [9/10], Training Loss: 1.703, Validation Accuracy: 37.37%\n",
        "Epoch [10/10], Training Loss: 1.687, Validation Accuracy: 38.02%\n",
        "Epoch [1/10], Training Loss: 1.712, Validation Accuracy: 37.85%\n",
        "Epoch [2/10], Training Loss: 1.694, Validation Accuracy: 39.17%\n",
        "Epoch [3/10], Training Loss: 1.688, Validation Accuracy: 39.35%\n",
        "Epoch [4/10], Training Loss: 1.666, Validation Accuracy: 39.82%\n",
        "Epoch [5/10], Training Loss: 1.660, Validation Accuracy: 39.85%\n",
        "Epoch [6/10], Training Loss: 1.644, Validation Accuracy: 40.52%\n",
        "Epoch [7/10], Training Loss: 1.629, Validation Accuracy: 41.12%\n",
        "Epoch [8/10], Training Loss: 1.619, Validation Accuracy: 40.65%\n",
        "Epoch [9/10], Training Loss: 1.611, Validation Accuracy: 41.61%\n",
        "Epoch [10/10], Training Loss: 1.602, Validation Accuracy: 42.00%\n",
        "Epoch [1/10], Training Loss: 1.618, Validation Accuracy: 42.16%\n",
        "Epoch [2/10], Training Loss: 1.603, Validation Accuracy: 41.07%\n",
        "Epoch [3/10], Training Loss: 1.600, Validation Accuracy: 42.26%\n",
        "Epoch [4/10], Training Loss: 1.582, Validation Accuracy: 42.12%\n",
        "Epoch [5/10], Training Loss: 1.576, Validation Accuracy: 43.30%\n",
        "Epoch [6/10], Training Loss: 1.568, Validation Accuracy: 43.31%\n",
        "Epoch [7/10], Training Loss: 1.555, Validation Accuracy: 43.59%\n",
        "Epoch [8/10], Training Loss: 1.545, Validation Accuracy: 44.72%\n",
        "Epoch [9/10], Training Loss: 1.540, Validation Accuracy: 43.08%\n",
        "Epoch [10/10], Training Loss: 1.531, Validation Accuracy: 44.20%\n",
        "Epoch [1/10], Training Loss: 1.530, Validation Accuracy: 44.49%\n",
        "Epoch [2/10], Training Loss: 1.522, Validation Accuracy: 44.97%\n",
        "Epoch [3/10], Training Loss: 1.506, Validation Accuracy: 44.74%\n",
        "Epoch [4/10], Training Loss: 1.496, Validation Accuracy: 45.18%\n",
        "Epoch [5/10], Training Loss: 1.484, Validation Accuracy: 45.09%\n",
        "Epoch [6/10], Training Loss: 1.481, Validation Accuracy: 45.35%\n",
        "Epoch [7/10], Training Loss: 1.469, Validation Accuracy: 45.75%\n",
        "Epoch [8/10], Training Loss: 1.460, Validation Accuracy: 45.42%\n",
        "Epoch [9/10], Training Loss: 1.454, Validation Accuracy: 46.19%\n",
        "Epoch [10/10], Training Loss: 1.445, Validation Accuracy: 46.37%\n",
        "Epoch [1/10], Training Loss: 1.484, Validation Accuracy: 46.75%\n",
        "Epoch [2/10], Training Loss: 1.480, Validation Accuracy: 46.40%\n",
        "Epoch [3/10], Training Loss: 1.465, Validation Accuracy: 47.26%\n",
        "Epoch [4/10], Training Loss: 1.454, Validation Accuracy: 46.66%\n",
        "Epoch [5/10], Training Loss: 1.445, Validation Accuracy: 47.40%\n",
        "Epoch [6/10], Training Loss: 1.439, Validation Accuracy: 47.26%\n",
        "Epoch [7/10], Training Loss: 1.433, Validation Accuracy: 46.78%\n",
        "Epoch [8/10], Training Loss: 1.422, Validation Accuracy: 47.24%\n",
        "Epoch [9/10], Training Loss: 1.418, Validation Accuracy: 47.41%\n",
        "Epoch [10/10], Training Loss: 1.412, Validation Accuracy: 47.62%\n",
        "Epoch [1/10], Training Loss: 1.436, Validation Accuracy: 48.26%\n",
        "Epoch [2/10], Training Loss: 1.429, Validation Accuracy: 47.29%\n",
        "Epoch [3/10], Training Loss: 1.416, Validation Accuracy: 48.46%\n",
        "Epoch [4/10], Training Loss: 1.411, Validation Accuracy: 47.92%\n",
        "Epoch [5/10], Training Loss: 1.402, Validation Accuracy: 48.90%\n",
        "Epoch [6/10], Training Loss: 1.392, Validation Accuracy: 48.59%\n",
        "Epoch [7/10], Training Loss: 1.383, Validation Accuracy: 48.00%\n",
        "Epoch [8/10], Training Loss: 1.377, Validation Accuracy: 48.68%\n",
        "Epoch [9/10], Training Loss: 1.373, Validation Accuracy: 48.55%\n",
        "Epoch [10/10], Training Loss: 1.359, Validation Accuracy: 48.74%\n",
        "Epoch [1/10], Training Loss: 1.417, Validation Accuracy: 49.03%\n",
        "Epoch [2/10], Training Loss: 1.415, Validation Accuracy: 49.57%\n",
        "Epoch [3/10], Training Loss: 1.398, Validation Accuracy: 49.46%\n",
        "Epoch [4/10], Training Loss: 1.390, Validation Accuracy: 49.47%\n",
        "Epoch [5/10], Training Loss: 1.380, Validation Accuracy: 49.49%\n",
        "Epoch [6/10], Training Loss: 1.368, Validation Accuracy: 50.03%\n",
        "Epoch [7/10], Training Loss: 1.365, Validation Accuracy: 49.50%\n",
        "Epoch [8/10], Training Loss: 1.356, Validation Accuracy: 49.78%\n",
        "Epoch [9/10], Training Loss: 1.351, Validation Accuracy: 50.29%\n",
        "Epoch [10/10], Training Loss: 1.343, Validation Accuracy: 50.01%\n",
        "Epoch [1/10], Training Loss: 1.397, Validation Accuracy: 50.54%\n",
        "Epoch [2/10], Training Loss: 1.376, Validation Accuracy: 49.81%\n",
        "Epoch [3/10], Training Loss: 1.366, Validation Accuracy: 50.71%\n",
        "Epoch [4/10], Training Loss: 1.351, Validation Accuracy: 51.03%\n",
        "Epoch [5/10], Training Loss: 1.341, Validation Accuracy: 51.24%\n",
        "Epoch [6/10], Training Loss: 1.333, Validation Accuracy: 50.52%\n",
        "Epoch [7/10], Training Loss: 1.323, Validation Accuracy: 51.22%\n",
        "Epoch [8/10], Training Loss: 1.316, Validation Accuracy: 51.07%\n",
        "Epoch [9/10], Training Loss: 1.308, Validation Accuracy: 51.01%\n",
        "Epoch [10/10], Training Loss: 1.313, Validation Accuracy: 50.84%\n",
        "Epoch [1/10], Training Loss: 1.335, Validation Accuracy: 51.86%\n",
        "Epoch [2/10], Training Loss: 1.311, Validation Accuracy: 51.89%\n",
        "Epoch [3/10], Training Loss: 1.307, Validation Accuracy: 51.90%\n",
        "Epoch [4/10], Training Loss: 1.290, Validation Accuracy: 52.18%\n",
        "Epoch [5/10], Training Loss: 1.280, Validation Accuracy: 51.86%\n",
        "Epoch [6/10], Training Loss: 1.270, Validation Accuracy: 52.50%\n",
        "Epoch [7/10], Training Loss: 1.267, Validation Accuracy: 52.05%\n",
        "Epoch [8/10], Training Loss: 1.255, Validation Accuracy: 50.80%\n",
        "Epoch [9/10], Training Loss: 1.248, Validation Accuracy: 52.27%\n",
        "Epoch [10/10], Training Loss: 1.234, Validation Accuracy: 52.33%\n",
        "Epoch [1/10], Training Loss: 1.323, Validation Accuracy: 52.94%\n",
        "Epoch [2/10], Training Loss: 1.303, Validation Accuracy: 52.61%\n",
        "Epoch [3/10], Training Loss: 1.294, Validation Accuracy: 52.37%\n",
        "Epoch [4/10], Training Loss: 1.284, Validation Accuracy: 52.04%\n",
        "Epoch [5/10], Training Loss: 1.272, Validation Accuracy: 52.91%\n",
        "Epoch [6/10], Training Loss: 1.258, Validation Accuracy: 52.78%\n",
        "Epoch [7/10], Training Loss: 1.256, Validation Accuracy: 52.36%\n",
        "Epoch [8/10], Training Loss: 1.240, Validation Accuracy: 53.43%\n",
        "Epoch [9/10], Training Loss: 1.235, Validation Accuracy: 53.43%\n",
        "Epoch [10/10], Training Loss: 1.227, Validation Accuracy: 53.06%\n",
        "Epoch [1/10], Training Loss: 1.277, Validation Accuracy: 53.18%\n",
        "Epoch [2/10], Training Loss: 1.268, Validation Accuracy: 53.77%\n",
        "Epoch [3/10], Training Loss: 1.249, Validation Accuracy: 53.35%\n",
        "Epoch [4/10], Training Loss: 1.235, Validation Accuracy: 53.48%\n",
        "Epoch [5/10], Training Loss: 1.224, Validation Accuracy: 53.38%\n",
        "Epoch [6/10], Training Loss: 1.219, Validation Accuracy: 53.05%\n",
        "Epoch [7/10], Training Loss: 1.209, Validation Accuracy: 53.40%\n",
        "Epoch [8/10], Training Loss: 1.197, Validation Accuracy: 53.66%\n",
        "Epoch [9/10], Training Loss: 1.197, Validation Accuracy: 53.54%\n",
        "Epoch [10/10], Training Loss: 1.180, Validation Accuracy: 54.20%\n",
        "Epoch [1/10], Training Loss: 1.272, Validation Accuracy: 53.92%\n",
        "Epoch [2/10], Training Loss: 1.246, Validation Accuracy: 53.26%\n",
        "Epoch [3/10], Training Loss: 1.234, Validation Accuracy: 54.00%\n",
        "Epoch [4/10], Training Loss: 1.221, Validation Accuracy: 54.25%\n",
        "Epoch [5/10], Training Loss: 1.211, Validation Accuracy: 53.40%\n",
        "Epoch [6/10], Training Loss: 1.201, Validation Accuracy: 54.27%\n",
        "Epoch [7/10], Training Loss: 1.190, Validation Accuracy: 53.64%\n",
        "Epoch [8/10], Training Loss: 1.178, Validation Accuracy: 54.58%\n",
        "Epoch [9/10], Training Loss: 1.174, Validation Accuracy: 54.28%\n",
        "Epoch [10/10], Training Loss: 1.162, Validation Accuracy: 54.55%\n",
        "Epoch [1/10], Training Loss: 1.253, Validation Accuracy: 54.30%\n",
        "Epoch [2/10], Training Loss: 1.229, Validation Accuracy: 55.39%\n",
        "Epoch [3/10], Training Loss: 1.205, Validation Accuracy: 55.22%\n",
        "Epoch [4/10], Training Loss: 1.190, Validation Accuracy: 55.29%\n",
        "Epoch [5/10], Training Loss: 1.178, Validation Accuracy: 54.05%\n",
        "Epoch [6/10], Training Loss: 1.172, Validation Accuracy: 55.60%\n",
        "Epoch [7/10], Training Loss: 1.153, Validation Accuracy: 55.25%\n",
        "Epoch [8/10], Training Loss: 1.155, Validation Accuracy: 54.18%\n",
        "Epoch [9/10], Training Loss: 1.146, Validation Accuracy: 55.79%\n",
        "Epoch [10/10], Training Loss: 1.131, Validation Accuracy: 55.39%\n",
        "Epoch [1/10], Training Loss: 1.196, Validation Accuracy: 55.35%\n",
        "Epoch [2/10], Training Loss: 1.182, Validation Accuracy: 55.93%\n",
        "Epoch [3/10], Training Loss: 1.160, Validation Accuracy: 56.11%\n",
        "Epoch [4/10], Training Loss: 1.143, Validation Accuracy: 56.15%\n",
        "Epoch [5/10], Training Loss: 1.130, Validation Accuracy: 56.20%\n",
        "Epoch [6/10], Training Loss: 1.123, Validation Accuracy: 55.83%\n",
        "Epoch [7/10], Training Loss: 1.114, Validation Accuracy: 56.08%\n",
        "Epoch [8/10], Training Loss: 1.098, Validation Accuracy: 56.06%\n",
        "Epoch [9/10], Training Loss: 1.091, Validation Accuracy: 56.10%\n",
        "Epoch [10/10], Training Loss: 1.085, Validation Accuracy: 54.38%\n",
        "Epoch [1/10], Training Loss: 1.212, Validation Accuracy: 56.58%\n",
        "Epoch [2/10], Training Loss: 1.176, Validation Accuracy: 56.47%\n",
        "Epoch [3/10], Training Loss: 1.170, Validation Accuracy: 56.87%\n",
        "Epoch [4/10], Training Loss: 1.154, Validation Accuracy: 56.70%\n",
        "Epoch [5/10], Training Loss: 1.140, Validation Accuracy: 56.62%\n",
        "Epoch [6/10], Training Loss: 1.125, Validation Accuracy: 56.90%\n",
        "Epoch [7/10], Training Loss: 1.109, Validation Accuracy: 56.71%\n",
        "Epoch [8/10], Training Loss: 1.108, Validation Accuracy: 56.52%\n",
        "Epoch [9/10], Training Loss: 1.093, Validation Accuracy: 56.13%\n",
        "Epoch [10/10], Training Loss: 1.086, Validation Accuracy: 56.61%\n",
        "Epoch [1/10], Training Loss: 1.156, Validation Accuracy: 56.98%\n",
        "Epoch [2/10], Training Loss: 1.136, Validation Accuracy: 56.16%\n",
        "Epoch [3/10], Training Loss: 1.117, Validation Accuracy: 57.32%\n",
        "Epoch [4/10], Training Loss: 1.100, Validation Accuracy: 56.86%\n",
        "Epoch [5/10], Training Loss: 1.093, Validation Accuracy: 57.18%\n",
        "Epoch [6/10], Training Loss: 1.081, Validation Accuracy: 57.17%\n",
        "Epoch [7/10], Training Loss: 1.073, Validation Accuracy: 57.05%\n",
        "Epoch [8/10], Training Loss: 1.056, Validation Accuracy: 56.92%\n",
        "Epoch [9/10], Training Loss: 1.053, Validation Accuracy: 57.95%\n",
        "Epoch [10/10], Training Loss: 1.037, Validation Accuracy: 56.62%\n",
        "Epoch [1/10], Training Loss: 1.162, Validation Accuracy: 58.08%\n",
        "Epoch [2/10], Training Loss: 1.131, Validation Accuracy: 57.04%\n",
        "Epoch [3/10], Training Loss: 1.116, Validation Accuracy: 56.60%\n",
        "Epoch [4/10], Training Loss: 1.100, Validation Accuracy: 57.53%\n",
        "Epoch [5/10], Training Loss: 1.086, Validation Accuracy: 57.85%\n",
        "Epoch [6/10], Training Loss: 1.085, Validation Accuracy: 56.60%\n",
        "Epoch [7/10], Training Loss: 1.057, Validation Accuracy: 57.85%\n",
        "Epoch [8/10], Training Loss: 1.061, Validation Accuracy: 57.37%\n",
        "Epoch [9/10], Training Loss: 1.036, Validation Accuracy: 57.73%\n",
        "Epoch [10/10], Training Loss: 1.027, Validation Accuracy: 57.26%\n",
        "Epoch [1/10], Training Loss: 1.136, Validation Accuracy: 57.98%\n",
        "Epoch [2/10], Training Loss: 1.114, Validation Accuracy: 57.94%\n",
        "Epoch [3/10], Training Loss: 1.089, Validation Accuracy: 57.44%\n",
        "Epoch [4/10], Training Loss: 1.076, Validation Accuracy: 58.03%\n",
        "Epoch [5/10], Training Loss: 1.055, Validation Accuracy: 57.91%\n",
        "Epoch [6/10], Training Loss: 1.040, Validation Accuracy: 58.25%\n",
        "Epoch [7/10], Training Loss: 1.029, Validation Accuracy: 58.16%\n",
        "Epoch [8/10], Training Loss: 1.028, Validation Accuracy: 58.38%\n",
        "Epoch [9/10], Training Loss: 1.007, Validation Accuracy: 57.65%\n",
        "Epoch [10/10], Training Loss: 1.003, Validation Accuracy: 58.61%\n",
        "Epoch [1/10], Training Loss: 1.107, Validation Accuracy: 56.73%\n",
        "Epoch [2/10], Training Loss: 1.073, Validation Accuracy: 57.65%\n",
        "Epoch [3/10], Training Loss: 1.060, Validation Accuracy: 58.57%\n",
        "Epoch [4/10], Training Loss: 1.034, Validation Accuracy: 58.43%\n",
        "Epoch [5/10], Training Loss: 1.026, Validation Accuracy: 58.48%\n",
        "Epoch [6/10], Training Loss: 1.011, Validation Accuracy: 58.69%\n",
        "Epoch [7/10], Training Loss: 0.996, Validation Accuracy: 58.49%\n",
        "Epoch [8/10], Training Loss: 0.979, Validation Accuracy: 58.67%\n",
        "Epoch [9/10], Training Loss: 0.969, Validation Accuracy: 58.06%\n",
        "Epoch [10/10], Training Loss: 0.958, Validation Accuracy: 57.54%\n",
        "Epoch [1/10], Training Loss: 1.121, Validation Accuracy: 58.58%\n",
        "Epoch [2/10], Training Loss: 1.078, Validation Accuracy: 58.84%\n",
        "Epoch [3/10], Training Loss: 1.063, Validation Accuracy: 58.49%\n",
        "Epoch [4/10], Training Loss: 1.037, Validation Accuracy: 58.59%\n",
        "Epoch [5/10], Training Loss: 1.027, Validation Accuracy: 58.61%\n",
        "Epoch [6/10], Training Loss: 1.012, Validation Accuracy: 58.33%\n",
        "Epoch [7/10], Training Loss: 1.000, Validation Accuracy: 58.84%\n",
        "Epoch [8/10], Training Loss: 0.982, Validation Accuracy: 58.53%\n",
        "Epoch [9/10], Training Loss: 0.975, Validation Accuracy: 59.15%\n",
        "Epoch [10/10], Training Loss: 0.967, Validation Accuracy: 58.63%\n",
        "Epoch [1/10], Training Loss: 1.083, Validation Accuracy: 58.13%\n",
        "Epoch [2/10], Training Loss: 1.047, Validation Accuracy: 58.83%\n",
        "Epoch [3/10], Training Loss: 1.017, Validation Accuracy: 59.03%\n",
        "Epoch [4/10], Training Loss: 0.999, Validation Accuracy: 59.10%\n",
        "Epoch [5/10], Training Loss: 0.987, Validation Accuracy: 58.39%\n",
        "Epoch [6/10], Training Loss: 0.976, Validation Accuracy: 58.98%\n",
        "Epoch [7/10], Training Loss: 0.955, Validation Accuracy: 59.09%\n",
        "Epoch [8/10], Training Loss: 0.953, Validation Accuracy: 59.00%\n",
        "Epoch [9/10], Training Loss: 0.947, Validation Accuracy: 57.83%\n",
        "Epoch [10/10], Training Loss: 0.932, Validation Accuracy: 58.77%\n",
        "Epoch [1/10], Training Loss: 1.092, Validation Accuracy: 57.96%\n",
        "Epoch [2/10], Training Loss: 1.050, Validation Accuracy: 59.08%\n",
        "Epoch [3/10], Training Loss: 1.018, Validation Accuracy: 59.17%\n",
        "Epoch [4/10], Training Loss: 1.003, Validation Accuracy: 59.10%\n",
        "Epoch [5/10], Training Loss: 0.992, Validation Accuracy: 59.45%\n",
        "Epoch [6/10], Training Loss: 0.970, Validation Accuracy: 58.52%\n",
        "Epoch [7/10], Training Loss: 0.957, Validation Accuracy: 58.91%\n",
        "Epoch [8/10], Training Loss: 0.948, Validation Accuracy: 59.06%\n",
        "Epoch [9/10], Training Loss: 0.939, Validation Accuracy: 58.64%\n",
        "Epoch [10/10], Training Loss: 0.925, Validation Accuracy: 59.15%\n",
        "Epoch [1/10], Training Loss: 1.062, Validation Accuracy: 59.78%\n",
        "Epoch [2/10], Training Loss: 1.023, Validation Accuracy: 59.45%\n",
        "Epoch [3/10], Training Loss: 0.991, Validation Accuracy: 59.84%\n",
        "Epoch [4/10], Training Loss: 0.977, Validation Accuracy: 58.81%\n",
        "Epoch [5/10], Training Loss: 0.959, Validation Accuracy: 58.99%\n",
        "Epoch [6/10], Training Loss: 0.936, Validation Accuracy: 59.27%\n",
        "Epoch [7/10], Training Loss: 0.927, Validation Accuracy: 59.94%\n",
        "Epoch [8/10], Training Loss: 0.913, Validation Accuracy: 59.54%\n",
        "Epoch [9/10], Training Loss: 0.911, Validation Accuracy: 59.55%\n",
        "Epoch [10/10], Training Loss: 0.889, Validation Accuracy: 58.33%\n",
        "Epoch [1/10], Training Loss: 1.040, Validation Accuracy: 59.44%\n",
        "Epoch [2/10], Training Loss: 1.000, Validation Accuracy: 59.81%\n",
        "Epoch [3/10], Training Loss: 0.968, Validation Accuracy: 59.61%\n",
        "Epoch [4/10], Training Loss: 0.946, Validation Accuracy: 58.84%\n",
        "Epoch [5/10], Training Loss: 0.930, Validation Accuracy: 60.43%\n",
        "Epoch [6/10], Training Loss: 0.912, Validation Accuracy: 59.06%\n",
        "Epoch [7/10], Training Loss: 0.895, Validation Accuracy: 59.70%\n",
        "Epoch [8/10], Training Loss: 0.881, Validation Accuracy: 60.03%\n",
        "Epoch [9/10], Training Loss: 0.867, Validation Accuracy: 59.71%\n",
        "Epoch [10/10], Training Loss: 0.865, Validation Accuracy: 59.29%\n",
        "Epoch [1/10], Training Loss: 1.049, Validation Accuracy: 60.10%\n",
        "Epoch [2/10], Training Loss: 0.998, Validation Accuracy: 60.12%\n",
        "Epoch [3/10], Training Loss: 0.975, Validation Accuracy: 60.36%\n",
        "Epoch [4/10], Training Loss: 0.943, Validation Accuracy: 59.86%\n",
        "Epoch [5/10], Training Loss: 0.926, Validation Accuracy: 60.17%\n",
        "Epoch [6/10], Training Loss: 0.913, Validation Accuracy: 59.83%\n",
        "Epoch [7/10], Training Loss: 0.896, Validation Accuracy: 60.00%\n",
        "Epoch [8/10], Training Loss: 0.886, Validation Accuracy: 59.51%\n",
        "Epoch [9/10], Training Loss: 0.875, Validation Accuracy: 60.01%\n",
        "Epoch [10/10], Training Loss: 0.852, Validation Accuracy: 59.38%\n",
        "Epoch [1/10], Training Loss: 1.022, Validation Accuracy: 59.24%\n",
        "Epoch [2/10], Training Loss: 0.966, Validation Accuracy: 59.76%\n",
        "Epoch [3/10], Training Loss: 0.943, Validation Accuracy: 60.19%\n",
        "Epoch [4/10], Training Loss: 0.913, Validation Accuracy: 60.48%\n",
        "Epoch [5/10], Training Loss: 0.896, Validation Accuracy: 59.82%\n",
        "Epoch [6/10], Training Loss: 0.887, Validation Accuracy: 60.22%\n",
        "Epoch [7/10], Training Loss: 0.863, Validation Accuracy: 59.36%\n",
        "Epoch [8/10], Training Loss: 0.850, Validation Accuracy: 59.22%\n",
        "Epoch [9/10], Training Loss: 0.833, Validation Accuracy: 59.71%\n",
        "Epoch [10/10], Training Loss: 0.826, Validation Accuracy: 58.98%\n",
        "Epoch [1/10], Training Loss: 1.028, Validation Accuracy: 60.22%\n",
        "Epoch [2/10], Training Loss: 0.974, Validation Accuracy: 59.12%\n",
        "Epoch [3/10], Training Loss: 0.944, Validation Accuracy: 60.01%\n",
        "Epoch [4/10], Training Loss: 0.927, Validation Accuracy: 59.59%\n",
        "Epoch [5/10], Training Loss: 0.907, Validation Accuracy: 60.23%\n",
        "Epoch [6/10], Training Loss: 0.883, Validation Accuracy: 60.00%\n",
        "Epoch [7/10], Training Loss: 0.872, Validation Accuracy: 60.27%\n",
        "Epoch [8/10], Training Loss: 0.864, Validation Accuracy: 60.26%\n",
        "Epoch [9/10], Training Loss: 0.844, Validation Accuracy: 59.79%\n",
        "Epoch [10/10], Training Loss: 0.826, Validation Accuracy: 59.36%\n",
        "Epoch [1/10], Training Loss: 0.998, Validation Accuracy: 60.19%\n",
        "Epoch [2/10], Training Loss: 0.946, Validation Accuracy: 60.71%\n",
        "Epoch [3/10], Training Loss: 0.913, Validation Accuracy: 60.27%\n",
        "Epoch [4/10], Training Loss: 0.893, Validation Accuracy: 60.66%\n",
        "Epoch [5/10], Training Loss: 0.874, Validation Accuracy: 59.14%\n",
        "Epoch [6/10], Training Loss: 0.852, Validation Accuracy: 60.96%\n",
        "Epoch [7/10], Training Loss: 0.829, Validation Accuracy: 60.14%\n",
        "Epoch [8/10], Training Loss: 0.807, Validation Accuracy: 60.43%\n",
        "Epoch [9/10], Training Loss: 0.803, Validation Accuracy: 60.20%\n",
        "Epoch [10/10], Training Loss: 0.788, Validation Accuracy: 60.82%\n",
        "Epoch [1/10], Training Loss: 0.985, Validation Accuracy: 60.60%\n",
        "Epoch [2/10], Training Loss: 0.927, Validation Accuracy: 61.42%\n",
        "Epoch [3/10], Training Loss: 0.894, Validation Accuracy: 60.41%\n",
        "Epoch [4/10], Training Loss: 0.867, Validation Accuracy: 60.87%\n",
        "Epoch [5/10], Training Loss: 0.847, Validation Accuracy: 60.36%\n",
        "Epoch [6/10], Training Loss: 0.835, Validation Accuracy: 60.32%\n",
        "Epoch [7/10], Training Loss: 0.811, Validation Accuracy: 60.45%\n",
        "Epoch [8/10], Training Loss: 0.792, Validation Accuracy: 60.25%\n",
        "Epoch [9/10], Training Loss: 0.780, Validation Accuracy: 59.89%\n",
        "Epoch [10/10], Training Loss: 0.762, Validation Accuracy: 60.73%\n",
        "Epoch [1/10], Training Loss: 0.984, Validation Accuracy: 60.67%\n",
        "Epoch [2/10], Training Loss: 0.922, Validation Accuracy: 60.58%\n",
        "Epoch [3/10], Training Loss: 0.896, Validation Accuracy: 60.78%\n",
        "Epoch [4/10], Training Loss: 0.868, Validation Accuracy: 60.89%\n",
        "Epoch [5/10], Training Loss: 0.840, Validation Accuracy: 60.95%\n",
        "Epoch [6/10], Training Loss: 0.817, Validation Accuracy: 60.69%\n",
        "Epoch [7/10], Training Loss: 0.797, Validation Accuracy: 60.93%\n",
        "Epoch [8/10], Training Loss: 0.779, Validation Accuracy: 60.70%\n",
        "Epoch [9/10], Training Loss: 0.768, Validation Accuracy: 60.77%\n",
        "Epoch [10/10], Training Loss: 0.751, Validation Accuracy: 61.07%\n",
        "Epoch [1/10], Training Loss: 0.957, Validation Accuracy: 60.83%\n",
        "Epoch [2/10], Training Loss: 0.899, Validation Accuracy: 61.02%\n",
        "Epoch [3/10], Training Loss: 0.865, Validation Accuracy: 60.91%\n",
        "Epoch [4/10], Training Loss: 0.835, Validation Accuracy: 60.02%\n",
        "Epoch [5/10], Training Loss: 0.817, Validation Accuracy: 60.91%\n",
        "Epoch [6/10], Training Loss: 0.802, Validation Accuracy: 60.70%\n",
        "Epoch [7/10], Training Loss: 0.782, Validation Accuracy: 60.32%\n",
        "Epoch [8/10], Training Loss: 0.770, Validation Accuracy: 60.83%\n",
        "Epoch [9/10], Training Loss: 0.752, Validation Accuracy: 59.72%\n",
        "Epoch [10/10], Training Loss: 0.733, Validation Accuracy: 60.95%\n",
        "Epoch [1/10], Training Loss: 0.975, Validation Accuracy: 59.98%\n",
        "Epoch [2/10], Training Loss: 0.908, Validation Accuracy: 60.47%\n",
        "Epoch [3/10], Training Loss: 0.865, Validation Accuracy: 60.69%\n",
        "Epoch [4/10], Training Loss: 0.837, Validation Accuracy: 60.36%\n",
        "Epoch [5/10], Training Loss: 0.813, Validation Accuracy: 60.48%\n",
        "Epoch [6/10], Training Loss: 0.798, Validation Accuracy: 61.11%\n",
        "Epoch [7/10], Training Loss: 0.783, Validation Accuracy: 60.42%\n",
        "Epoch [8/10], Training Loss: 0.765, Validation Accuracy: 60.92%\n",
        "Epoch [9/10], Training Loss: 0.744, Validation Accuracy: 60.60%\n",
        "Epoch [10/10], Training Loss: 0.733, Validation Accuracy: 59.79%\n",
        "Epoch [1/10], Training Loss: 0.935, Validation Accuracy: 60.13%\n",
        "Epoch [2/10], Training Loss: 0.875, Validation Accuracy: 60.84%\n",
        "Epoch [3/10], Training Loss: 0.838, Validation Accuracy: 61.15%\n",
        "Epoch [4/10], Training Loss: 0.811, Validation Accuracy: 61.19%\n",
        "Epoch [5/10], Training Loss: 0.792, Validation Accuracy: 60.74%\n",
        "Epoch [6/10], Training Loss: 0.764, Validation Accuracy: 59.01%\n",
        "Epoch [7/10], Training Loss: 0.754, Validation Accuracy: 60.74%\n",
        "Epoch [8/10], Training Loss: 0.728, Validation Accuracy: 61.23%\n",
        "Epoch [9/10], Training Loss: 0.707, Validation Accuracy: 60.52%\n",
        "Epoch [10/10], Training Loss: 0.701, Validation Accuracy: 60.61%\n",
        "Epoch [1/10], Training Loss: 0.933, Validation Accuracy: 61.67%\n",
        "Epoch [2/10], Training Loss: 0.853, Validation Accuracy: 61.20%\n",
        "Epoch [3/10], Training Loss: 0.818, Validation Accuracy: 60.74%\n",
        "Epoch [4/10], Training Loss: 0.794, Validation Accuracy: 61.38%\n",
        "Epoch [5/10], Training Loss: 0.763, Validation Accuracy: 61.29%\n",
        "Epoch [6/10], Training Loss: 0.735, Validation Accuracy: 61.16%\n",
        "Epoch [7/10], Training Loss: 0.714, Validation Accuracy: 60.29%\n",
        "Epoch [8/10], Training Loss: 0.702, Validation Accuracy: 60.64%\n",
        "Epoch [9/10], Training Loss: 0.678, Validation Accuracy: 61.48%\n",
        "Epoch [10/10], Training Loss: 0.668, Validation Accuracy: 60.80%\n",
        "Epoch [1/10], Training Loss: 0.940, Validation Accuracy: 61.04%\n",
        "Epoch [2/10], Training Loss: 0.855, Validation Accuracy: 61.06%\n",
        "Epoch [3/10], Training Loss: 0.824, Validation Accuracy: 61.36%\n",
        "Epoch [4/10], Training Loss: 0.778, Validation Accuracy: 61.31%\n",
        "Epoch [5/10], Training Loss: 0.756, Validation Accuracy: 61.41%\n",
        "Epoch [6/10], Training Loss: 0.740, Validation Accuracy: 61.24%\n",
        "Epoch [7/10], Training Loss: 0.711, Validation Accuracy: 61.37%\n",
        "Epoch [8/10], Training Loss: 0.687, Validation Accuracy: 61.25%\n",
        "Epoch [9/10], Training Loss: 0.677, Validation Accuracy: 60.79%\n",
        "Epoch [10/10], Training Loss: 0.663, Validation Accuracy: 60.72%\n",
        "Epoch [1/10], Training Loss: 0.915, Validation Accuracy: 60.62%\n",
        "Epoch [2/10], Training Loss: 0.831, Validation Accuracy: 61.22%\n",
        "Epoch [3/10], Training Loss: 0.789, Validation Accuracy: 60.87%\n",
        "Epoch [4/10], Training Loss: 0.755, Validation Accuracy: 61.13%\n",
        "Epoch [5/10], Training Loss: 0.736, Validation Accuracy: 60.99%\n",
        "Epoch [6/10], Training Loss: 0.713, Validation Accuracy: 60.44%\n",
        "Epoch [7/10], Training Loss: 0.690, Validation Accuracy: 58.91%\n",
        "Epoch [8/10], Training Loss: 0.674, Validation Accuracy: 60.34%\n",
        "Epoch [9/10], Training Loss: 0.655, Validation Accuracy: 60.92%\n",
        "Epoch [10/10], Training Loss: 0.635, Validation Accuracy: 60.49%\n",
        "Epoch [1/10], Training Loss: 0.923, Validation Accuracy: 60.46%\n",
        "Epoch [2/10], Training Loss: 0.848, Validation Accuracy: 59.97%\n",
        "Epoch [3/10], Training Loss: 0.808, Validation Accuracy: 59.86%\n",
        "Epoch [4/10], Training Loss: 0.764, Validation Accuracy: 60.63%\n",
        "Epoch [5/10], Training Loss: 0.746, Validation Accuracy: 60.85%\n",
        "Epoch [6/10], Training Loss: 0.719, Validation Accuracy: 61.18%\n",
        "Epoch [7/10], Training Loss: 0.693, Validation Accuracy: 60.24%\n",
        "Epoch [8/10], Training Loss: 0.677, Validation Accuracy: 60.66%\n",
        "Epoch [9/10], Training Loss: 0.662, Validation Accuracy: 60.75%\n",
        "Epoch [10/10], Training Loss: 0.649, Validation Accuracy: 60.20%\n",
        "Epoch [1/10], Training Loss: 0.900, Validation Accuracy: 60.99%\n",
        "Epoch [2/10], Training Loss: 0.822, Validation Accuracy: 61.16%\n",
        "Epoch [3/10], Training Loss: 0.768, Validation Accuracy: 60.21%\n",
        "Epoch [4/10], Training Loss: 0.731, Validation Accuracy: 61.58%\n",
        "Epoch [5/10], Training Loss: 0.701, Validation Accuracy: 61.09%\n",
        "Epoch [6/10], Training Loss: 0.678, Validation Accuracy: 61.55%\n",
        "Epoch [7/10], Training Loss: 0.659, Validation Accuracy: 61.47%\n",
        "Epoch [8/10], Training Loss: 0.633, Validation Accuracy: 60.93%\n",
        "Epoch [9/10], Training Loss: 0.620, Validation Accuracy: 61.45%\n",
        "Epoch [10/10], Training Loss: 0.602, Validation Accuracy: 61.18%\n",
        "Epoch [1/10], Training Loss: 0.889, Validation Accuracy: 60.46%\n",
        "Epoch [2/10], Training Loss: 0.798, Validation Accuracy: 61.45%\n",
        "Epoch [3/10], Training Loss: 0.747, Validation Accuracy: 61.51%\n",
        "Epoch [4/10], Training Loss: 0.719, Validation Accuracy: 61.59%\n",
        "Epoch [5/10], Training Loss: 0.695, Validation Accuracy: 61.45%\n",
        "Epoch [6/10], Training Loss: 0.652, Validation Accuracy: 61.19%\n",
        "Epoch [7/10], Training Loss: 0.641, Validation Accuracy: 61.56%\n",
        "Epoch [8/10], Training Loss: 0.610, Validation Accuracy: 61.38%\n",
        "Epoch [9/10], Training Loss: 0.589, Validation Accuracy: 61.28%\n",
        "Epoch [10/10], Training Loss: 0.577, Validation Accuracy: 60.69%\n",
        "Epoch [1/10], Training Loss: 0.904, Validation Accuracy: 60.79%\n",
        "Epoch [2/10], Training Loss: 0.790, Validation Accuracy: 61.49%\n",
        "Epoch [3/10], Training Loss: 0.739, Validation Accuracy: 61.15%\n",
        "Epoch [4/10], Training Loss: 0.701, Validation Accuracy: 61.60%\n",
        "Epoch [5/10], Training Loss: 0.681, Validation Accuracy: 60.88%\n",
        "Epoch [6/10], Training Loss: 0.646, Validation Accuracy: 61.32%\n",
        "Epoch [7/10], Training Loss: 0.616, Validation Accuracy: 61.79%\n",
        "Epoch [8/10], Training Loss: 0.606, Validation Accuracy: 61.34%\n",
        "Epoch [9/10], Training Loss: 0.578, Validation Accuracy: 60.26%\n",
        "Epoch [10/10], Training Loss: 0.566, Validation Accuracy: 61.27%\n",
        "Epoch [1/10], Training Loss: 0.878, Validation Accuracy: 60.71%\n",
        "Epoch [2/10], Training Loss: 0.790, Validation Accuracy: 61.10%\n",
        "Epoch [3/10], Training Loss: 0.721, Validation Accuracy: 61.37%\n",
        "Epoch [4/10], Training Loss: 0.680, Validation Accuracy: 60.79%\n",
        "Epoch [5/10], Training Loss: 0.655, Validation Accuracy: 61.31%\n",
        "Epoch [6/10], Training Loss: 0.624, Validation Accuracy: 61.27%\n",
        "Epoch [7/10], Training Loss: 0.596, Validation Accuracy: 60.94%\n",
        "Epoch [8/10], Training Loss: 0.575, Validation Accuracy: 60.72%\n",
        "Epoch [9/10], Training Loss: 0.563, Validation Accuracy: 61.06%\n",
        "Epoch [10/10], Training Loss: 0.540, Validation Accuracy: 60.40%\n",
        "Epoch [1/10], Training Loss: 0.886, Validation Accuracy: 60.53%\n",
        "Epoch [2/10], Training Loss: 0.786, Validation Accuracy: 60.56%\n",
        "Epoch [3/10], Training Loss: 0.747, Validation Accuracy: 59.76%\n",
        "Epoch [4/10], Training Loss: 0.704, Validation Accuracy: 60.99%\n",
        "Epoch [5/10], Training Loss: 0.666, Validation Accuracy: 60.52%\n",
        "Epoch [6/10], Training Loss: 0.641, Validation Accuracy: 60.46%\n",
        "Epoch [7/10], Training Loss: 0.614, Validation Accuracy: 60.25%\n",
        "Epoch [8/10], Training Loss: 0.597, Validation Accuracy: 60.14%\n",
        "Epoch [9/10], Training Loss: 0.575, Validation Accuracy: 60.94%\n",
        "Epoch [10/10], Training Loss: 0.552, Validation Accuracy: 59.90%\n",
        "Epoch [1/10], Training Loss: 0.864, Validation Accuracy: 60.67%\n",
        "Epoch [2/10], Training Loss: 0.753, Validation Accuracy: 61.56%\n",
        "Epoch [3/10], Training Loss: 0.716, Validation Accuracy: 61.00%\n",
        "Epoch [4/10], Training Loss: 0.667, Validation Accuracy: 61.21%\n",
        "Epoch [5/10], Training Loss: 0.626, Validation Accuracy: 61.82%\n",
        "Epoch [6/10], Training Loss: 0.605, Validation Accuracy: 61.73%\n",
        "Epoch [7/10], Training Loss: 0.571, Validation Accuracy: 61.31%\n",
        "Epoch [8/10], Training Loss: 0.559, Validation Accuracy: 60.66%\n",
        "Epoch [9/10], Training Loss: 0.532, Validation Accuracy: 61.46%\n",
        "Epoch [10/10], Training Loss: 0.514, Validation Accuracy: 60.34%\n",
        "Epoch [1/10], Training Loss: 0.853, Validation Accuracy: 60.61%\n",
        "Epoch [2/10], Training Loss: 0.742, Validation Accuracy: 61.47%\n",
        "Epoch [3/10], Training Loss: 0.682, Validation Accuracy: 59.98%\n",
        "Epoch [4/10], Training Loss: 0.643, Validation Accuracy: 60.94%\n",
        "Epoch [5/10], Training Loss: 0.602, Validation Accuracy: 61.45%\n",
        "Epoch [6/10], Training Loss: 0.580, Validation Accuracy: 61.44%\n",
        "Epoch [7/10], Training Loss: 0.546, Validation Accuracy: 61.21%\n",
        "Epoch [8/10], Training Loss: 0.531, Validation Accuracy: 60.77%\n",
        "Epoch [9/10], Training Loss: 0.511, Validation Accuracy: 60.86%\n",
        "Epoch [10/10], Training Loss: 0.498, Validation Accuracy: 60.70%\n",
        "Epoch [1/10], Training Loss: 0.859, Validation Accuracy: 61.29%\n",
        "Epoch [2/10], Training Loss: 0.737, Validation Accuracy: 60.20%\n",
        "Epoch [3/10], Training Loss: 0.678, Validation Accuracy: 61.37%\n",
        "Epoch [4/10], Training Loss: 0.631, Validation Accuracy: 61.41%\n",
        "Epoch [5/10], Training Loss: 0.599, Validation Accuracy: 60.84%\n",
        "Epoch [6/10], Training Loss: 0.571, Validation Accuracy: 61.21%\n",
        "Epoch [7/10], Training Loss: 0.546, Validation Accuracy: 61.00%\n",
        "Epoch [8/10], Training Loss: 0.514, Validation Accuracy: 60.84%\n",
        "Epoch [9/10], Training Loss: 0.494, Validation Accuracy: 60.91%\n",
        "Epoch [10/10], Training Loss: 0.499, Validation Accuracy: 61.12%\n",
        "Epoch [1/10], Training Loss: 0.834, Validation Accuracy: 61.13%\n",
        "Epoch [2/10], Training Loss: 0.712, Validation Accuracy: 61.00%\n",
        "Epoch [3/10], Training Loss: 0.653, Validation Accuracy: 61.37%\n",
        "Epoch [4/10], Training Loss: 0.610, Validation Accuracy: 61.69%\n",
        "Epoch [5/10], Training Loss: 0.575, Validation Accuracy: 61.54%\n",
        "Epoch [6/10], Training Loss: 0.548, Validation Accuracy: 60.88%\n",
        "Epoch [7/10], Training Loss: 0.516, Validation Accuracy: 61.23%\n",
        "Epoch [8/10], Training Loss: 0.494, Validation Accuracy: 60.62%\n",
        "Epoch [9/10], Training Loss: 0.486, Validation Accuracy: 60.74%\n",
        "Epoch [10/10], Training Loss: 0.464, Validation Accuracy: 60.85%\n",
        "Epoch [1/10], Training Loss: 0.854, Validation Accuracy: 60.45%\n",
        "Epoch [2/10], Training Loss: 0.731, Validation Accuracy: 60.59%\n",
        "Epoch [3/10], Training Loss: 0.668, Validation Accuracy: 60.86%\n",
        "Epoch [4/10], Training Loss: 0.624, Validation Accuracy: 60.20%\n",
        "Epoch [5/10], Training Loss: 0.601, Validation Accuracy: 60.48%\n",
        "Epoch [6/10], Training Loss: 0.558, Validation Accuracy: 60.94%\n",
        "Epoch [7/10], Training Loss: 0.538, Validation Accuracy: 61.03%\n",
        "Epoch [8/10], Training Loss: 0.507, Validation Accuracy: 60.52%\n",
        "Epoch [9/10], Training Loss: 0.493, Validation Accuracy: 59.92%\n",
        "Epoch [10/10], Training Loss: 0.471, Validation Accuracy: 60.18%\n",
        "\"\"\"\n",
        "\n",
        "# Regular expression to find validation accuracies\n",
        "accuracies = re.findall(r'Validation Accuracy: (\\d+\\.\\d+)%', log)\n",
        "\n",
        "# Convert accuracies from string to float\n",
        "accuracies = [float(acc) for acc in accuracies]\n",
        "\n",
        "# Print accuracies\n",
        "print(\"Accuracies:\", accuracies)\n",
        "\n",
        "# Print size of the array\n",
        "print(\"Size of array:\", len(accuracies))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gvhqXpOGpoH",
        "outputId": "52a42ce6-292e-4137-88b2-76fa259d124c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 10.54%\n",
            "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 10.89%\n",
            "Epoch [3/10], Training Loss: 2.305, Validation Accuracy: 10.83%\n",
            "Epoch [4/10], Training Loss: 2.304, Validation Accuracy: 11.51%\n",
            "Epoch [5/10], Training Loss: 2.304, Validation Accuracy: 11.62%\n",
            "Epoch [6/10], Training Loss: 2.303, Validation Accuracy: 12.56%\n",
            "Epoch [7/10], Training Loss: 2.303, Validation Accuracy: 12.60%\n",
            "Epoch [8/10], Training Loss: 2.302, Validation Accuracy: 13.07%\n",
            "Epoch [9/10], Training Loss: 2.301, Validation Accuracy: 13.95%\n",
            "Epoch [10/10], Training Loss: 2.300, Validation Accuracy: 13.66%\n",
            "Epoch [1/10], Training Loss: 2.300, Validation Accuracy: 13.22%\n",
            "Epoch [2/10], Training Loss: 2.300, Validation Accuracy: 12.61%\n",
            "Epoch [3/10], Training Loss: 2.299, Validation Accuracy: 12.54%\n",
            "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 12.38%\n",
            "Epoch [5/10], Training Loss: 2.298, Validation Accuracy: 12.53%\n",
            "Epoch [6/10], Training Loss: 2.297, Validation Accuracy: 12.41%\n",
            "Epoch [7/10], Training Loss: 2.296, Validation Accuracy: 12.62%\n",
            "Epoch [8/10], Training Loss: 2.296, Validation Accuracy: 12.71%\n",
            "Epoch [9/10], Training Loss: 2.295, Validation Accuracy: 13.01%\n",
            "Epoch [10/10], Training Loss: 2.294, Validation Accuracy: 13.26%\n",
            "Epoch [1/10], Training Loss: 2.294, Validation Accuracy: 13.48%\n",
            "Epoch [2/10], Training Loss: 2.293, Validation Accuracy: 13.92%\n",
            "Epoch [3/10], Training Loss: 2.292, Validation Accuracy: 14.09%\n",
            "Epoch [4/10], Training Loss: 2.290, Validation Accuracy: 14.84%\n",
            "Epoch [5/10], Training Loss: 2.288, Validation Accuracy: 15.34%\n",
            "Epoch [6/10], Training Loss: 2.286, Validation Accuracy: 16.34%\n",
            "Epoch [7/10], Training Loss: 2.283, Validation Accuracy: 16.49%\n",
            "Epoch [8/10], Training Loss: 2.280, Validation Accuracy: 16.62%\n",
            "Epoch [9/10], Training Loss: 2.276, Validation Accuracy: 16.84%\n",
            "Epoch [10/10], Training Loss: 2.272, Validation Accuracy: 16.81%\n",
            "Epoch [1/10], Training Loss: 2.267, Validation Accuracy: 17.75%\n",
            "Epoch [2/10], Training Loss: 2.259, Validation Accuracy: 18.46%\n",
            "Epoch [3/10], Training Loss: 2.249, Validation Accuracy: 18.85%\n",
            "Epoch [4/10], Training Loss: 2.238, Validation Accuracy: 18.17%\n",
            "Epoch [5/10], Training Loss: 2.229, Validation Accuracy: 19.01%\n",
            "Epoch [6/10], Training Loss: 2.222, Validation Accuracy: 18.91%\n",
            "Epoch [7/10], Training Loss: 2.210, Validation Accuracy: 19.36%\n",
            "Epoch [8/10], Training Loss: 2.201, Validation Accuracy: 19.51%\n",
            "Epoch [9/10], Training Loss: 2.190, Validation Accuracy: 19.98%\n",
            "Epoch [10/10], Training Loss: 2.178, Validation Accuracy: 20.64%\n",
            "Epoch [1/10], Training Loss: 2.177, Validation Accuracy: 20.42%\n",
            "Epoch [2/10], Training Loss: 2.168, Validation Accuracy: 21.12%\n",
            "Epoch [3/10], Training Loss: 2.157, Validation Accuracy: 21.42%\n",
            "Epoch [4/10], Training Loss: 2.148, Validation Accuracy: 22.38%\n",
            "Epoch [5/10], Training Loss: 2.137, Validation Accuracy: 22.32%\n",
            "Epoch [6/10], Training Loss: 2.131, Validation Accuracy: 22.88%\n",
            "Epoch [7/10], Training Loss: 2.115, Validation Accuracy: 22.96%\n",
            "Epoch [8/10], Training Loss: 2.105, Validation Accuracy: 23.45%\n",
            "Epoch [9/10], Training Loss: 2.096, Validation Accuracy: 23.69%\n",
            "Epoch [10/10], Training Loss: 2.084, Validation Accuracy: 24.06%\n",
            "Epoch [1/10], Training Loss: 2.087, Validation Accuracy: 25.20%\n",
            "Epoch [2/10], Training Loss: 2.073, Validation Accuracy: 25.52%\n",
            "Epoch [3/10], Training Loss: 2.057, Validation Accuracy: 25.50%\n",
            "Epoch [4/10], Training Loss: 2.044, Validation Accuracy: 25.90%\n",
            "Epoch [5/10], Training Loss: 2.027, Validation Accuracy: 26.28%\n",
            "Epoch [6/10], Training Loss: 2.023, Validation Accuracy: 26.82%\n",
            "Epoch [7/10], Training Loss: 1.998, Validation Accuracy: 27.19%\n",
            "Epoch [8/10], Training Loss: 1.990, Validation Accuracy: 27.86%\n",
            "Epoch [9/10], Training Loss: 1.981, Validation Accuracy: 28.32%\n",
            "Epoch [10/10], Training Loss: 1.965, Validation Accuracy: 28.84%\n",
            "Epoch [1/10], Training Loss: 1.952, Validation Accuracy: 29.28%\n",
            "Epoch [2/10], Training Loss: 1.933, Validation Accuracy: 29.39%\n",
            "Epoch [3/10], Training Loss: 1.921, Validation Accuracy: 30.49%\n",
            "Epoch [4/10], Training Loss: 1.910, Validation Accuracy: 30.82%\n",
            "Epoch [5/10], Training Loss: 1.893, Validation Accuracy: 31.30%\n",
            "Epoch [6/10], Training Loss: 1.883, Validation Accuracy: 31.50%\n",
            "Epoch [7/10], Training Loss: 1.869, Validation Accuracy: 31.77%\n",
            "Epoch [8/10], Training Loss: 1.866, Validation Accuracy: 32.15%\n",
            "Epoch [9/10], Training Loss: 1.853, Validation Accuracy: 32.42%\n",
            "Epoch [10/10], Training Loss: 1.846, Validation Accuracy: 32.55%\n",
            "Epoch [1/10], Training Loss: 1.874, Validation Accuracy: 33.11%\n",
            "Epoch [2/10], Training Loss: 1.863, Validation Accuracy: 33.20%\n",
            "Epoch [3/10], Training Loss: 1.851, Validation Accuracy: 33.66%\n",
            "Epoch [4/10], Training Loss: 1.842, Validation Accuracy: 33.75%\n",
            "Epoch [5/10], Training Loss: 1.832, Validation Accuracy: 34.31%\n",
            "Epoch [6/10], Training Loss: 1.812, Validation Accuracy: 34.67%\n",
            "Epoch [7/10], Training Loss: 1.803, Validation Accuracy: 34.42%\n",
            "Epoch [8/10], Training Loss: 1.795, Validation Accuracy: 35.43%\n",
            "Epoch [9/10], Training Loss: 1.782, Validation Accuracy: 34.77%\n",
            "Epoch [10/10], Training Loss: 1.767, Validation Accuracy: 36.01%\n",
            "Epoch [1/10], Training Loss: 1.778, Validation Accuracy: 36.08%\n",
            "Epoch [2/10], Training Loss: 1.764, Validation Accuracy: 36.49%\n",
            "Epoch [3/10], Training Loss: 1.750, Validation Accuracy: 37.11%\n",
            "Epoch [4/10], Training Loss: 1.739, Validation Accuracy: 37.35%\n",
            "Epoch [5/10], Training Loss: 1.723, Validation Accuracy: 37.61%\n",
            "Epoch [6/10], Training Loss: 1.710, Validation Accuracy: 37.60%\n",
            "Epoch [7/10], Training Loss: 1.700, Validation Accuracy: 38.08%\n",
            "Epoch [8/10], Training Loss: 1.685, Validation Accuracy: 37.96%\n",
            "Epoch [9/10], Training Loss: 1.681, Validation Accuracy: 38.03%\n",
            "Epoch [10/10], Training Loss: 1.666, Validation Accuracy: 38.09%\n",
            "Epoch [1/10], Training Loss: 1.680, Validation Accuracy: 38.71%\n",
            "Epoch [2/10], Training Loss: 1.662, Validation Accuracy: 37.99%\n",
            "Epoch [3/10], Training Loss: 1.657, Validation Accuracy: 39.25%\n",
            "Epoch [4/10], Training Loss: 1.650, Validation Accuracy: 39.51%\n",
            "Epoch [5/10], Training Loss: 1.636, Validation Accuracy: 38.25%\n",
            "Epoch [6/10], Training Loss: 1.631, Validation Accuracy: 39.71%\n",
            "Epoch [7/10], Training Loss: 1.629, Validation Accuracy: 39.98%\n",
            "Epoch [8/10], Training Loss: 1.609, Validation Accuracy: 39.45%\n",
            "Epoch [9/10], Training Loss: 1.603, Validation Accuracy: 40.27%\n",
            "Epoch [10/10], Training Loss: 1.592, Validation Accuracy: 39.83%\n",
            "Epoch [1/10], Training Loss: 1.628, Validation Accuracy: 40.19%\n",
            "Epoch [2/10], Training Loss: 1.610, Validation Accuracy: 41.14%\n",
            "Epoch [3/10], Training Loss: 1.613, Validation Accuracy: 41.23%\n",
            "Epoch [4/10], Training Loss: 1.603, Validation Accuracy: 41.18%\n",
            "Epoch [5/10], Training Loss: 1.599, Validation Accuracy: 41.00%\n",
            "Epoch [6/10], Training Loss: 1.589, Validation Accuracy: 41.56%\n",
            "Epoch [7/10], Training Loss: 1.585, Validation Accuracy: 41.53%\n",
            "Epoch [8/10], Training Loss: 1.566, Validation Accuracy: 41.97%\n",
            "Epoch [9/10], Training Loss: 1.568, Validation Accuracy: 42.68%\n",
            "Epoch [10/10], Training Loss: 1.554, Validation Accuracy: 41.02%\n",
            "Epoch [1/10], Training Loss: 1.586, Validation Accuracy: 41.41%\n",
            "Epoch [2/10], Training Loss: 1.568, Validation Accuracy: 42.81%\n",
            "Epoch [3/10], Training Loss: 1.554, Validation Accuracy: 42.28%\n",
            "Epoch [4/10], Training Loss: 1.566, Validation Accuracy: 42.32%\n",
            "Epoch [5/10], Training Loss: 1.553, Validation Accuracy: 42.50%\n",
            "Epoch [6/10], Training Loss: 1.550, Validation Accuracy: 43.01%\n",
            "Epoch [7/10], Training Loss: 1.537, Validation Accuracy: 42.78%\n",
            "Epoch [8/10], Training Loss: 1.522, Validation Accuracy: 43.12%\n",
            "Epoch [9/10], Training Loss: 1.524, Validation Accuracy: 41.97%\n",
            "Epoch [10/10], Training Loss: 1.514, Validation Accuracy: 42.80%\n",
            "Epoch [1/10], Training Loss: 1.569, Validation Accuracy: 43.05%\n",
            "Epoch [2/10], Training Loss: 1.553, Validation Accuracy: 43.98%\n",
            "Epoch [3/10], Training Loss: 1.545, Validation Accuracy: 43.67%\n",
            "Epoch [4/10], Training Loss: 1.546, Validation Accuracy: 43.75%\n",
            "Epoch [5/10], Training Loss: 1.534, Validation Accuracy: 44.15%\n",
            "Epoch [6/10], Training Loss: 1.532, Validation Accuracy: 43.84%\n",
            "Epoch [7/10], Training Loss: 1.523, Validation Accuracy: 44.12%\n",
            "Epoch [8/10], Training Loss: 1.509, Validation Accuracy: 44.53%\n",
            "Epoch [9/10], Training Loss: 1.515, Validation Accuracy: 44.29%\n",
            "Epoch [10/10], Training Loss: 1.508, Validation Accuracy: 43.81%\n",
            "Epoch [1/10], Training Loss: 1.512, Validation Accuracy: 44.20%\n",
            "Epoch [2/10], Training Loss: 1.498, Validation Accuracy: 44.55%\n",
            "Epoch [3/10], Training Loss: 1.488, Validation Accuracy: 44.58%\n",
            "Epoch [4/10], Training Loss: 1.483, Validation Accuracy: 45.29%\n",
            "Epoch [5/10], Training Loss: 1.463, Validation Accuracy: 44.58%\n",
            "Epoch [6/10], Training Loss: 1.464, Validation Accuracy: 45.27%\n",
            "Epoch [7/10], Training Loss: 1.463, Validation Accuracy: 45.47%\n",
            "Epoch [8/10], Training Loss: 1.448, Validation Accuracy: 45.45%\n",
            "Epoch [9/10], Training Loss: 1.437, Validation Accuracy: 45.77%\n",
            "Epoch [10/10], Training Loss: 1.430, Validation Accuracy: 45.76%\n",
            "Epoch [1/10], Training Loss: 1.504, Validation Accuracy: 45.91%\n",
            "Epoch [2/10], Training Loss: 1.494, Validation Accuracy: 45.80%\n",
            "Epoch [3/10], Training Loss: 1.478, Validation Accuracy: 45.77%\n",
            "Epoch [4/10], Training Loss: 1.467, Validation Accuracy: 46.82%\n",
            "Epoch [5/10], Training Loss: 1.462, Validation Accuracy: 46.57%\n",
            "Epoch [6/10], Training Loss: 1.458, Validation Accuracy: 46.18%\n",
            "Epoch [7/10], Training Loss: 1.440, Validation Accuracy: 45.40%\n",
            "Epoch [8/10], Training Loss: 1.446, Validation Accuracy: 45.92%\n",
            "Epoch [9/10], Training Loss: 1.447, Validation Accuracy: 46.95%\n",
            "Epoch [10/10], Training Loss: 1.423, Validation Accuracy: 46.88%\n",
            "Epoch [1/10], Training Loss: 1.476, Validation Accuracy: 46.33%\n",
            "Epoch [2/10], Training Loss: 1.466, Validation Accuracy: 47.23%\n",
            "Epoch [3/10], Training Loss: 1.462, Validation Accuracy: 47.05%\n",
            "Epoch [4/10], Training Loss: 1.444, Validation Accuracy: 47.41%\n",
            "Epoch [5/10], Training Loss: 1.436, Validation Accuracy: 47.75%\n",
            "Epoch [6/10], Training Loss: 1.427, Validation Accuracy: 47.63%\n",
            "Epoch [7/10], Training Loss: 1.418, Validation Accuracy: 47.72%\n",
            "Epoch [8/10], Training Loss: 1.407, Validation Accuracy: 47.99%\n",
            "Epoch [9/10], Training Loss: 1.400, Validation Accuracy: 47.46%\n",
            "Epoch [10/10], Training Loss: 1.396, Validation Accuracy: 47.13%\n",
            "Epoch [1/10], Training Loss: 1.445, Validation Accuracy: 47.50%\n",
            "Epoch [2/10], Training Loss: 1.422, Validation Accuracy: 48.00%\n",
            "Epoch [3/10], Training Loss: 1.403, Validation Accuracy: 47.28%\n",
            "Epoch [4/10], Training Loss: 1.401, Validation Accuracy: 48.54%\n",
            "Epoch [5/10], Training Loss: 1.377, Validation Accuracy: 46.71%\n",
            "Epoch [6/10], Training Loss: 1.386, Validation Accuracy: 48.32%\n",
            "Epoch [7/10], Training Loss: 1.363, Validation Accuracy: 48.24%\n",
            "Epoch [8/10], Training Loss: 1.361, Validation Accuracy: 48.31%\n",
            "Epoch [9/10], Training Loss: 1.358, Validation Accuracy: 48.48%\n",
            "Epoch [10/10], Training Loss: 1.347, Validation Accuracy: 47.84%\n",
            "Epoch [1/10], Training Loss: 1.423, Validation Accuracy: 48.29%\n",
            "Epoch [2/10], Training Loss: 1.413, Validation Accuracy: 48.88%\n",
            "Epoch [3/10], Training Loss: 1.382, Validation Accuracy: 48.84%\n",
            "Epoch [4/10], Training Loss: 1.380, Validation Accuracy: 48.76%\n",
            "Epoch [5/10], Training Loss: 1.368, Validation Accuracy: 48.39%\n",
            "Epoch [6/10], Training Loss: 1.368, Validation Accuracy: 48.62%\n",
            "Epoch [7/10], Training Loss: 1.362, Validation Accuracy: 48.95%\n",
            "Epoch [8/10], Training Loss: 1.354, Validation Accuracy: 48.95%\n",
            "Epoch [9/10], Training Loss: 1.336, Validation Accuracy: 49.11%\n",
            "Epoch [10/10], Training Loss: 1.333, Validation Accuracy: 48.50%\n",
            "Epoch [1/10], Training Loss: 1.427, Validation Accuracy: 49.63%\n",
            "Epoch [2/10], Training Loss: 1.408, Validation Accuracy: 49.24%\n",
            "Epoch [3/10], Training Loss: 1.396, Validation Accuracy: 49.75%\n",
            "Epoch [4/10], Training Loss: 1.370, Validation Accuracy: 49.61%\n",
            "Epoch [5/10], Training Loss: 1.359, Validation Accuracy: 49.61%\n",
            "Epoch [6/10], Training Loss: 1.355, Validation Accuracy: 48.85%\n",
            "Epoch [7/10], Training Loss: 1.360, Validation Accuracy: 49.87%\n",
            "Epoch [8/10], Training Loss: 1.342, Validation Accuracy: 49.72%\n",
            "Epoch [9/10], Training Loss: 1.339, Validation Accuracy: 49.68%\n",
            "Epoch [10/10], Training Loss: 1.338, Validation Accuracy: 49.48%\n",
            "Epoch [1/10], Training Loss: 1.395, Validation Accuracy: 50.05%\n",
            "Epoch [2/10], Training Loss: 1.365, Validation Accuracy: 50.22%\n",
            "Epoch [3/10], Training Loss: 1.354, Validation Accuracy: 48.96%\n",
            "Epoch [4/10], Training Loss: 1.342, Validation Accuracy: 50.05%\n",
            "Epoch [5/10], Training Loss: 1.330, Validation Accuracy: 50.07%\n",
            "Epoch [6/10], Training Loss: 1.311, Validation Accuracy: 50.72%\n",
            "Epoch [7/10], Training Loss: 1.309, Validation Accuracy: 50.82%\n",
            "Epoch [8/10], Training Loss: 1.300, Validation Accuracy: 50.30%\n",
            "Epoch [9/10], Training Loss: 1.290, Validation Accuracy: 49.86%\n",
            "Epoch [10/10], Training Loss: 1.290, Validation Accuracy: 50.24%\n",
            "Epoch [1/10], Training Loss: 1.346, Validation Accuracy: 50.30%\n",
            "Epoch [2/10], Training Loss: 1.339, Validation Accuracy: 50.64%\n",
            "Epoch [3/10], Training Loss: 1.317, Validation Accuracy: 51.74%\n",
            "Epoch [4/10], Training Loss: 1.304, Validation Accuracy: 51.94%\n",
            "Epoch [5/10], Training Loss: 1.301, Validation Accuracy: 51.32%\n",
            "Epoch [6/10], Training Loss: 1.283, Validation Accuracy: 51.49%\n",
            "Epoch [7/10], Training Loss: 1.299, Validation Accuracy: 51.99%\n",
            "Epoch [8/10], Training Loss: 1.272, Validation Accuracy: 51.06%\n",
            "Epoch [9/10], Training Loss: 1.253, Validation Accuracy: 51.47%\n",
            "Epoch [10/10], Training Loss: 1.254, Validation Accuracy: 51.73%\n",
            "Epoch [1/10], Training Loss: 1.342, Validation Accuracy: 51.32%\n",
            "Epoch [2/10], Training Loss: 1.335, Validation Accuracy: 51.42%\n",
            "Epoch [3/10], Training Loss: 1.304, Validation Accuracy: 51.84%\n",
            "Epoch [4/10], Training Loss: 1.277, Validation Accuracy: 51.83%\n",
            "Epoch [5/10], Training Loss: 1.285, Validation Accuracy: 51.33%\n",
            "Epoch [6/10], Training Loss: 1.287, Validation Accuracy: 51.81%\n",
            "Epoch [7/10], Training Loss: 1.257, Validation Accuracy: 52.21%\n",
            "Epoch [8/10], Training Loss: 1.260, Validation Accuracy: 50.60%\n",
            "Epoch [9/10], Training Loss: 1.249, Validation Accuracy: 52.02%\n",
            "Epoch [10/10], Training Loss: 1.233, Validation Accuracy: 51.71%\n",
            "Epoch [1/10], Training Loss: 1.356, Validation Accuracy: 52.67%\n",
            "Epoch [2/10], Training Loss: 1.335, Validation Accuracy: 52.47%\n",
            "Epoch [3/10], Training Loss: 1.327, Validation Accuracy: 52.16%\n",
            "Epoch [4/10], Training Loss: 1.309, Validation Accuracy: 52.91%\n",
            "Epoch [5/10], Training Loss: 1.298, Validation Accuracy: 51.98%\n",
            "Epoch [6/10], Training Loss: 1.302, Validation Accuracy: 52.62%\n",
            "Epoch [7/10], Training Loss: 1.284, Validation Accuracy: 52.77%\n",
            "Epoch [8/10], Training Loss: 1.267, Validation Accuracy: 52.95%\n",
            "Epoch [9/10], Training Loss: 1.269, Validation Accuracy: 52.83%\n",
            "Epoch [10/10], Training Loss: 1.257, Validation Accuracy: 53.45%\n"
          ]
        }
      ],
      "source": [
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 10  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=5)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rz_6gbNsHnsv",
        "outputId": "115f06b2-ba29-46ff-aca6-c19f96530ba6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracies: [10.04, 10.78, 11.4, 11.7, 11.99, 11.82, 11.51, 11.33, 11.38, 11.46, 11.43, 11.86, 12.51, 13.75, 14.94, 16.29, 17.4, 18.76, 20.65, 23.27, 24.55, 25.06, 25.58, 25.8, 26.4, 27.51, 28.46, 28.4, 28.93, 30.03, 31.17, 31.15, 31.97, 32.09, 32.1, 33.37, 33.2, 34.15, 34.71, 35.26, 35.33, 36.05, 35.13, 36.08, 36.72, 37.83, 37.47, 37.17, 38.33, 39.32, 39.08, 39.65, 39.7, 40.42, 40.39, 40.5, 40.47, 41.93, 41.17, 41.28, 41.96, 42.78, 42.13, 42.36, 42.97, 43.05, 43.32, 43.55, 44.07, 44.25, 43.37, 44.78, 44.92, 44.52, 45.19, 45.2, 45.03, 46.05, 45.85, 46.56, 46.45, 46.63, 47.03, 47.31, 46.22, 47.19, 47.72, 48.12, 47.44, 48.09, 48.06, 48.26, 48.7, 48.05, 48.69, 49.05, 47.7, 48.53, 49.62, 49.59, 49.24, 49.81, 50.83, 49.15, 51.02, 49.88, 50.12, 50.6, 49.96, 51.31, 50.29, 51.65, 50.89, 50.7, 52.4, 51.84, 51.16, 51.69, 52.57, 52.05, 52.26, 51.97, 52.06, 52.88, 52.62, 52.25, 53.48, 52.86, 51.74, 52.79, 53.37, 53.38, 53.78, 53.45, 54.44, 53.64, 54.34, 54.23, 52.83, 54.44, 51.78, 54.93, 54.3, 53.76, 54.73, 55.49, 54.89, 55.41, 54.78, 55.71, 55.33, 55.27, 54.99, 55.41, 55.4, 55.7, 55.87, 54.13, 55.39, 55.85, 56.05, 55.29, 55.98, 55.84, 56.36, 56.28, 56.18, 55.3, 54.2, 56.52, 56.84, 55.99, 56.09, 57.1, 57.28, 56.85, 56.53, 56.86, 56.5, 57.02, 56.97, 56.81, 56.91, 56.39, 56.59, 57.2, 57.44, 57.69, 57.37, 57.09, 58.24, 57.43, 58.08, 58.14, 58.06, 57.68, 58.31, 58.51, 57.5, 56.47, 57.72, 58.52, 58.36, 57.61, 58.42, 56.58, 58.41, 58.1, 57.99, 57.56, 58.03, 59.04, 58.37, 58.63, 58.73, 58.43, 58.15, 57.82, 58.63, 58.36, 58.56, 58.4, 59.53, 59.06, 58.58, 58.32, 59.33, 59.55, 58.6, 57.83, 59.57, 59.29, 59.27, 59.18, 59.24, 58.64, 59.05, 59.76, 58.58, 59.51, 59.68, 59.5, 59.27, 59.77, 59.26, 59.13, 59.33, 58.98, 58.62, 59.56, 59.3, 58.82, 58.98, 59.54, 59.23, 60.37, 60.26, 59.53, 59.57, 59.44, 59.7, 59.92, 59.77, 60.5, 59.8, 59.79, 59.8, 60.09, 60.32, 59.73, 60.64, 60.32, 60.15, 60.26, 60.22, 60.01, 60.41, 60.85, 59.96, 60.41, 60.37, 60.05, 59.81, 60.43, 60.35, 60.23, 60.41, 59.96, 60.56, 60.56, 60.81, 60.77, 60.66, 60.73, 60.01, 60.3, 60.22, 60.89, 59.89, 60.03, 60.17, 60.63, 60.33, 60.29, 60.36, 60.91, 60.14, 59.25, 60.33, 60.37, 59.96, 60.87, 61.25, 60.88, 61.25, 60.72, 61.17, 60.38, 61.07, 59.82, 61.02, 61.31, 61.01, 61.45, 60.65, 61.44, 60.96, 60.14, 61.1, 61.37, 61.03, 61.48, 61.2, 61.31, 60.95, 60.76, 60.87, 60.84, 60.54, 60.23, 61.74, 60.7, 60.87, 60.93, 60.75, 61.52, 61.02, 60.71, 60.33, 60.55, 61.59, 60.98, 61.25, 61.34, 61.59, 60.38, 60.43, 60.19, 60.96, 60.61, 61.08, 61.35, 61.97, 61.84, 61.76, 61.48, 61.1, 61.44, 60.94, 61.01, 61.01, 61.51, 60.92, 60.84, 61.77, 61.58, 61.98, 61.53, 61.63, 61.66, 61.13, 61.73, 61.18, 60.5, 61.84, 60.94, 60.96, 60.93, 61.35, 61.25, 60.31, 61.39, 61.22, 60.27, 60.93, 61.42, 60.34, 60.31, 60.61, 61.15, 61.1, 61.33, 61.22, 60.53, 60.7, 60.69, 60.49, 60.42, 60.22, 60.16, 60.94, 61.56, 61.37, 61.37, 61.26, 61.01, 60.89, 61.23, 60.86, 60.5]\n",
            "Size of array: 420\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Your provided text\n",
        "log = \"\"\"\n",
        "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 10.04%\n",
        "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.78%\n",
        "Epoch [3/10], Training Loss: 2.303, Validation Accuracy: 11.40%\n",
        "Epoch [4/10], Training Loss: 2.302, Validation Accuracy: 11.70%\n",
        "Epoch [5/10], Training Loss: 2.301, Validation Accuracy: 11.99%\n",
        "Epoch [6/10], Training Loss: 2.300, Validation Accuracy: 11.82%\n",
        "Epoch [7/10], Training Loss: 2.299, Validation Accuracy: 11.51%\n",
        "Epoch [8/10], Training Loss: 2.298, Validation Accuracy: 11.33%\n",
        "Epoch [9/10], Training Loss: 2.296, Validation Accuracy: 11.38%\n",
        "Epoch [10/10], Training Loss: 2.295, Validation Accuracy: 11.46%\n",
        "Epoch [1/10], Training Loss: 2.293, Validation Accuracy: 11.43%\n",
        "Epoch [2/10], Training Loss: 2.290, Validation Accuracy: 11.86%\n",
        "Epoch [3/10], Training Loss: 2.287, Validation Accuracy: 12.51%\n",
        "Epoch [4/10], Training Loss: 2.282, Validation Accuracy: 13.75%\n",
        "Epoch [5/10], Training Loss: 2.274, Validation Accuracy: 14.94%\n",
        "Epoch [6/10], Training Loss: 2.263, Validation Accuracy: 16.29%\n",
        "Epoch [7/10], Training Loss: 2.246, Validation Accuracy: 17.40%\n",
        "Epoch [8/10], Training Loss: 2.220, Validation Accuracy: 18.76%\n",
        "Epoch [9/10], Training Loss: 2.190, Validation Accuracy: 20.65%\n",
        "Epoch [10/10], Training Loss: 2.162, Validation Accuracy: 23.27%\n",
        "Epoch [1/10], Training Loss: 2.139, Validation Accuracy: 24.55%\n",
        "Epoch [2/10], Training Loss: 2.121, Validation Accuracy: 25.06%\n",
        "Epoch [3/10], Training Loss: 2.104, Validation Accuracy: 25.58%\n",
        "Epoch [4/10], Training Loss: 2.091, Validation Accuracy: 25.80%\n",
        "Epoch [5/10], Training Loss: 2.076, Validation Accuracy: 26.40%\n",
        "Epoch [6/10], Training Loss: 2.061, Validation Accuracy: 27.51%\n",
        "Epoch [7/10], Training Loss: 2.045, Validation Accuracy: 28.46%\n",
        "Epoch [8/10], Training Loss: 2.026, Validation Accuracy: 28.40%\n",
        "Epoch [9/10], Training Loss: 2.008, Validation Accuracy: 28.93%\n",
        "Epoch [10/10], Training Loss: 1.982, Validation Accuracy: 30.03%\n",
        "Epoch [1/10], Training Loss: 1.968, Validation Accuracy: 31.17%\n",
        "Epoch [2/10], Training Loss: 1.941, Validation Accuracy: 31.15%\n",
        "Epoch [3/10], Training Loss: 1.909, Validation Accuracy: 31.97%\n",
        "Epoch [4/10], Training Loss: 1.885, Validation Accuracy: 32.09%\n",
        "Epoch [5/10], Training Loss: 1.865, Validation Accuracy: 32.10%\n",
        "Epoch [6/10], Training Loss: 1.847, Validation Accuracy: 33.37%\n",
        "Epoch [7/10], Training Loss: 1.826, Validation Accuracy: 33.20%\n",
        "Epoch [8/10], Training Loss: 1.803, Validation Accuracy: 34.15%\n",
        "Epoch [9/10], Training Loss: 1.786, Validation Accuracy: 34.71%\n",
        "Epoch [10/10], Training Loss: 1.769, Validation Accuracy: 35.26%\n",
        "Epoch [1/10], Training Loss: 1.777, Validation Accuracy: 35.33%\n",
        "Epoch [2/10], Training Loss: 1.756, Validation Accuracy: 36.05%\n",
        "Epoch [3/10], Training Loss: 1.742, Validation Accuracy: 35.13%\n",
        "Epoch [4/10], Training Loss: 1.735, Validation Accuracy: 36.08%\n",
        "Epoch [5/10], Training Loss: 1.717, Validation Accuracy: 36.72%\n",
        "Epoch [6/10], Training Loss: 1.707, Validation Accuracy: 37.83%\n",
        "Epoch [7/10], Training Loss: 1.683, Validation Accuracy: 37.47%\n",
        "Epoch [8/10], Training Loss: 1.677, Validation Accuracy: 37.17%\n",
        "Epoch [9/10], Training Loss: 1.664, Validation Accuracy: 38.33%\n",
        "Epoch [10/10], Training Loss: 1.654, Validation Accuracy: 39.32%\n",
        "Epoch [1/10], Training Loss: 1.677, Validation Accuracy: 39.08%\n",
        "Epoch [2/10], Training Loss: 1.660, Validation Accuracy: 39.65%\n",
        "Epoch [3/10], Training Loss: 1.645, Validation Accuracy: 39.70%\n",
        "Epoch [4/10], Training Loss: 1.633, Validation Accuracy: 40.42%\n",
        "Epoch [5/10], Training Loss: 1.624, Validation Accuracy: 40.39%\n",
        "Epoch [6/10], Training Loss: 1.613, Validation Accuracy: 40.50%\n",
        "Epoch [7/10], Training Loss: 1.603, Validation Accuracy: 40.47%\n",
        "Epoch [8/10], Training Loss: 1.593, Validation Accuracy: 41.93%\n",
        "Epoch [9/10], Training Loss: 1.579, Validation Accuracy: 41.17%\n",
        "Epoch [10/10], Training Loss: 1.575, Validation Accuracy: 41.28%\n",
        "Epoch [1/10], Training Loss: 1.633, Validation Accuracy: 41.96%\n",
        "Epoch [2/10], Training Loss: 1.615, Validation Accuracy: 42.78%\n",
        "Epoch [3/10], Training Loss: 1.605, Validation Accuracy: 42.13%\n",
        "Epoch [4/10], Training Loss: 1.594, Validation Accuracy: 42.36%\n",
        "Epoch [5/10], Training Loss: 1.586, Validation Accuracy: 42.97%\n",
        "Epoch [6/10], Training Loss: 1.573, Validation Accuracy: 43.05%\n",
        "Epoch [7/10], Training Loss: 1.563, Validation Accuracy: 43.32%\n",
        "Epoch [8/10], Training Loss: 1.553, Validation Accuracy: 43.55%\n",
        "Epoch [9/10], Training Loss: 1.543, Validation Accuracy: 44.07%\n",
        "Epoch [10/10], Training Loss: 1.532, Validation Accuracy: 44.25%\n",
        "Epoch [1/10], Training Loss: 1.520, Validation Accuracy: 43.37%\n",
        "Epoch [2/10], Training Loss: 1.508, Validation Accuracy: 44.78%\n",
        "Epoch [3/10], Training Loss: 1.489, Validation Accuracy: 44.92%\n",
        "Epoch [4/10], Training Loss: 1.486, Validation Accuracy: 44.52%\n",
        "Epoch [5/10], Training Loss: 1.477, Validation Accuracy: 45.19%\n",
        "Epoch [6/10], Training Loss: 1.464, Validation Accuracy: 45.20%\n",
        "Epoch [7/10], Training Loss: 1.452, Validation Accuracy: 45.03%\n",
        "Epoch [8/10], Training Loss: 1.451, Validation Accuracy: 46.05%\n",
        "Epoch [9/10], Training Loss: 1.430, Validation Accuracy: 45.85%\n",
        "Epoch [10/10], Training Loss: 1.425, Validation Accuracy: 46.56%\n",
        "Epoch [1/10], Training Loss: 1.451, Validation Accuracy: 46.45%\n",
        "Epoch [2/10], Training Loss: 1.440, Validation Accuracy: 46.63%\n",
        "Epoch [3/10], Training Loss: 1.431, Validation Accuracy: 47.03%\n",
        "Epoch [4/10], Training Loss: 1.417, Validation Accuracy: 47.31%\n",
        "Epoch [5/10], Training Loss: 1.402, Validation Accuracy: 46.22%\n",
        "Epoch [6/10], Training Loss: 1.403, Validation Accuracy: 47.19%\n",
        "Epoch [7/10], Training Loss: 1.397, Validation Accuracy: 47.72%\n",
        "Epoch [8/10], Training Loss: 1.379, Validation Accuracy: 48.12%\n",
        "Epoch [9/10], Training Loss: 1.378, Validation Accuracy: 47.44%\n",
        "Epoch [10/10], Training Loss: 1.365, Validation Accuracy: 48.09%\n",
        "Epoch [1/10], Training Loss: 1.422, Validation Accuracy: 48.06%\n",
        "Epoch [2/10], Training Loss: 1.410, Validation Accuracy: 48.26%\n",
        "Epoch [3/10], Training Loss: 1.391, Validation Accuracy: 48.70%\n",
        "Epoch [4/10], Training Loss: 1.384, Validation Accuracy: 48.05%\n",
        "Epoch [5/10], Training Loss: 1.374, Validation Accuracy: 48.69%\n",
        "Epoch [6/10], Training Loss: 1.363, Validation Accuracy: 49.05%\n",
        "Epoch [7/10], Training Loss: 1.359, Validation Accuracy: 47.70%\n",
        "Epoch [8/10], Training Loss: 1.361, Validation Accuracy: 48.53%\n",
        "Epoch [9/10], Training Loss: 1.344, Validation Accuracy: 49.62%\n",
        "Epoch [10/10], Training Loss: 1.335, Validation Accuracy: 49.59%\n",
        "Epoch [1/10], Training Loss: 1.395, Validation Accuracy: 49.24%\n",
        "Epoch [2/10], Training Loss: 1.376, Validation Accuracy: 49.81%\n",
        "Epoch [3/10], Training Loss: 1.359, Validation Accuracy: 50.83%\n",
        "Epoch [4/10], Training Loss: 1.351, Validation Accuracy: 49.15%\n",
        "Epoch [5/10], Training Loss: 1.338, Validation Accuracy: 51.02%\n",
        "Epoch [6/10], Training Loss: 1.334, Validation Accuracy: 49.88%\n",
        "Epoch [7/10], Training Loss: 1.328, Validation Accuracy: 50.12%\n",
        "Epoch [8/10], Training Loss: 1.319, Validation Accuracy: 50.60%\n",
        "Epoch [9/10], Training Loss: 1.308, Validation Accuracy: 49.96%\n",
        "Epoch [10/10], Training Loss: 1.304, Validation Accuracy: 51.31%\n",
        "Epoch [1/10], Training Loss: 1.381, Validation Accuracy: 50.29%\n",
        "Epoch [2/10], Training Loss: 1.361, Validation Accuracy: 51.65%\n",
        "Epoch [3/10], Training Loss: 1.349, Validation Accuracy: 50.89%\n",
        "Epoch [4/10], Training Loss: 1.335, Validation Accuracy: 50.70%\n",
        "Epoch [5/10], Training Loss: 1.333, Validation Accuracy: 52.40%\n",
        "Epoch [6/10], Training Loss: 1.322, Validation Accuracy: 51.84%\n",
        "Epoch [7/10], Training Loss: 1.319, Validation Accuracy: 51.16%\n",
        "Epoch [8/10], Training Loss: 1.307, Validation Accuracy: 51.69%\n",
        "Epoch [9/10], Training Loss: 1.292, Validation Accuracy: 52.57%\n",
        "Epoch [10/10], Training Loss: 1.282, Validation Accuracy: 52.05%\n",
        "Epoch [1/10], Training Loss: 1.320, Validation Accuracy: 52.26%\n",
        "Epoch [2/10], Training Loss: 1.294, Validation Accuracy: 51.97%\n",
        "Epoch [3/10], Training Loss: 1.282, Validation Accuracy: 52.06%\n",
        "Epoch [4/10], Training Loss: 1.267, Validation Accuracy: 52.88%\n",
        "Epoch [5/10], Training Loss: 1.252, Validation Accuracy: 52.62%\n",
        "Epoch [6/10], Training Loss: 1.251, Validation Accuracy: 52.25%\n",
        "Epoch [7/10], Training Loss: 1.242, Validation Accuracy: 53.48%\n",
        "Epoch [8/10], Training Loss: 1.228, Validation Accuracy: 52.86%\n",
        "Epoch [9/10], Training Loss: 1.222, Validation Accuracy: 51.74%\n",
        "Epoch [10/10], Training Loss: 1.218, Validation Accuracy: 52.79%\n",
        "Epoch [1/10], Training Loss: 1.284, Validation Accuracy: 53.37%\n",
        "Epoch [2/10], Training Loss: 1.257, Validation Accuracy: 53.38%\n",
        "Epoch [3/10], Training Loss: 1.244, Validation Accuracy: 53.78%\n",
        "Epoch [4/10], Training Loss: 1.235, Validation Accuracy: 53.45%\n",
        "Epoch [5/10], Training Loss: 1.223, Validation Accuracy: 54.44%\n",
        "Epoch [6/10], Training Loss: 1.216, Validation Accuracy: 53.64%\n",
        "Epoch [7/10], Training Loss: 1.203, Validation Accuracy: 54.34%\n",
        "Epoch [8/10], Training Loss: 1.194, Validation Accuracy: 54.23%\n",
        "Epoch [9/10], Training Loss: 1.197, Validation Accuracy: 52.83%\n",
        "Epoch [10/10], Training Loss: 1.179, Validation Accuracy: 54.44%\n",
        "Epoch [1/10], Training Loss: 1.265, Validation Accuracy: 51.78%\n",
        "Epoch [2/10], Training Loss: 1.273, Validation Accuracy: 54.93%\n",
        "Epoch [3/10], Training Loss: 1.237, Validation Accuracy: 54.30%\n",
        "Epoch [4/10], Training Loss: 1.219, Validation Accuracy: 53.76%\n",
        "Epoch [5/10], Training Loss: 1.198, Validation Accuracy: 54.73%\n",
        "Epoch [6/10], Training Loss: 1.199, Validation Accuracy: 55.49%\n",
        "Epoch [7/10], Training Loss: 1.187, Validation Accuracy: 54.89%\n",
        "Epoch [8/10], Training Loss: 1.180, Validation Accuracy: 55.41%\n",
        "Epoch [9/10], Training Loss: 1.167, Validation Accuracy: 54.78%\n",
        "Epoch [10/10], Training Loss: 1.163, Validation Accuracy: 55.71%\n",
        "Epoch [1/10], Training Loss: 1.258, Validation Accuracy: 55.33%\n",
        "Epoch [2/10], Training Loss: 1.227, Validation Accuracy: 55.27%\n",
        "Epoch [3/10], Training Loss: 1.203, Validation Accuracy: 54.99%\n",
        "Epoch [4/10], Training Loss: 1.188, Validation Accuracy: 55.41%\n",
        "Epoch [5/10], Training Loss: 1.179, Validation Accuracy: 55.40%\n",
        "Epoch [6/10], Training Loss: 1.172, Validation Accuracy: 55.70%\n",
        "Epoch [7/10], Training Loss: 1.160, Validation Accuracy: 55.87%\n",
        "Epoch [8/10], Training Loss: 1.145, Validation Accuracy: 54.13%\n",
        "Epoch [9/10], Training Loss: 1.138, Validation Accuracy: 55.39%\n",
        "Epoch [10/10], Training Loss: 1.125, Validation Accuracy: 55.85%\n",
        "Epoch [1/10], Training Loss: 1.239, Validation Accuracy: 56.05%\n",
        "Epoch [2/10], Training Loss: 1.210, Validation Accuracy: 55.29%\n",
        "Epoch [3/10], Training Loss: 1.201, Validation Accuracy: 55.98%\n",
        "Epoch [4/10], Training Loss: 1.188, Validation Accuracy: 55.84%\n",
        "Epoch [5/10], Training Loss: 1.176, Validation Accuracy: 56.36%\n",
        "Epoch [6/10], Training Loss: 1.155, Validation Accuracy: 56.28%\n",
        "Epoch [7/10], Training Loss: 1.152, Validation Accuracy: 56.18%\n",
        "Epoch [8/10], Training Loss: 1.145, Validation Accuracy: 55.30%\n",
        "Epoch [9/10], Training Loss: 1.142, Validation Accuracy: 54.20%\n",
        "Epoch [10/10], Training Loss: 1.122, Validation Accuracy: 56.52%\n",
        "Epoch [1/10], Training Loss: 1.191, Validation Accuracy: 56.84%\n",
        "Epoch [2/10], Training Loss: 1.172, Validation Accuracy: 55.99%\n",
        "Epoch [3/10], Training Loss: 1.146, Validation Accuracy: 56.09%\n",
        "Epoch [4/10], Training Loss: 1.147, Validation Accuracy: 57.10%\n",
        "Epoch [5/10], Training Loss: 1.123, Validation Accuracy: 57.28%\n",
        "Epoch [6/10], Training Loss: 1.111, Validation Accuracy: 56.85%\n",
        "Epoch [7/10], Training Loss: 1.102, Validation Accuracy: 56.53%\n",
        "Epoch [8/10], Training Loss: 1.093, Validation Accuracy: 56.86%\n",
        "Epoch [9/10], Training Loss: 1.083, Validation Accuracy: 56.50%\n",
        "Epoch [10/10], Training Loss: 1.074, Validation Accuracy: 57.02%\n",
        "Epoch [1/10], Training Loss: 1.171, Validation Accuracy: 56.97%\n",
        "Epoch [2/10], Training Loss: 1.140, Validation Accuracy: 56.81%\n",
        "Epoch [3/10], Training Loss: 1.119, Validation Accuracy: 56.91%\n",
        "Epoch [4/10], Training Loss: 1.102, Validation Accuracy: 56.39%\n",
        "Epoch [5/10], Training Loss: 1.096, Validation Accuracy: 56.59%\n",
        "Epoch [6/10], Training Loss: 1.084, Validation Accuracy: 57.20%\n",
        "Epoch [7/10], Training Loss: 1.069, Validation Accuracy: 57.44%\n",
        "Epoch [8/10], Training Loss: 1.060, Validation Accuracy: 57.69%\n",
        "Epoch [9/10], Training Loss: 1.051, Validation Accuracy: 57.37%\n",
        "Epoch [10/10], Training Loss: 1.037, Validation Accuracy: 57.09%\n",
        "Epoch [1/10], Training Loss: 1.165, Validation Accuracy: 58.24%\n",
        "Epoch [2/10], Training Loss: 1.130, Validation Accuracy: 57.43%\n",
        "Epoch [3/10], Training Loss: 1.107, Validation Accuracy: 58.08%\n",
        "Epoch [4/10], Training Loss: 1.091, Validation Accuracy: 58.14%\n",
        "Epoch [5/10], Training Loss: 1.078, Validation Accuracy: 58.06%\n",
        "Epoch [6/10], Training Loss: 1.063, Validation Accuracy: 57.68%\n",
        "Epoch [7/10], Training Loss: 1.061, Validation Accuracy: 58.31%\n",
        "Epoch [8/10], Training Loss: 1.045, Validation Accuracy: 58.51%\n",
        "Epoch [9/10], Training Loss: 1.034, Validation Accuracy: 57.50%\n",
        "Epoch [10/10], Training Loss: 1.019, Validation Accuracy: 56.47%\n",
        "Epoch [1/10], Training Loss: 1.140, Validation Accuracy: 57.72%\n",
        "Epoch [2/10], Training Loss: 1.101, Validation Accuracy: 58.52%\n",
        "Epoch [3/10], Training Loss: 1.081, Validation Accuracy: 58.36%\n",
        "Epoch [4/10], Training Loss: 1.069, Validation Accuracy: 57.61%\n",
        "Epoch [5/10], Training Loss: 1.063, Validation Accuracy: 58.42%\n",
        "Epoch [6/10], Training Loss: 1.039, Validation Accuracy: 56.58%\n",
        "Epoch [7/10], Training Loss: 1.034, Validation Accuracy: 58.41%\n",
        "Epoch [8/10], Training Loss: 1.022, Validation Accuracy: 58.10%\n",
        "Epoch [9/10], Training Loss: 1.005, Validation Accuracy: 57.99%\n",
        "Epoch [10/10], Training Loss: 0.999, Validation Accuracy: 57.56%\n",
        "Epoch [1/10], Training Loss: 1.149, Validation Accuracy: 58.03%\n",
        "Epoch [2/10], Training Loss: 1.113, Validation Accuracy: 59.04%\n",
        "Epoch [3/10], Training Loss: 1.081, Validation Accuracy: 58.37%\n",
        "Epoch [4/10], Training Loss: 1.067, Validation Accuracy: 58.63%\n",
        "Epoch [5/10], Training Loss: 1.048, Validation Accuracy: 58.73%\n",
        "Epoch [6/10], Training Loss: 1.042, Validation Accuracy: 58.43%\n",
        "Epoch [7/10], Training Loss: 1.032, Validation Accuracy: 58.15%\n",
        "Epoch [8/10], Training Loss: 1.025, Validation Accuracy: 57.82%\n",
        "Epoch [9/10], Training Loss: 1.003, Validation Accuracy: 58.63%\n",
        "Epoch [10/10], Training Loss: 0.998, Validation Accuracy: 58.36%\n",
        "Epoch [1/10], Training Loss: 1.101, Validation Accuracy: 58.56%\n",
        "Epoch [2/10], Training Loss: 1.060, Validation Accuracy: 58.40%\n",
        "Epoch [3/10], Training Loss: 1.041, Validation Accuracy: 59.53%\n",
        "Epoch [4/10], Training Loss: 1.015, Validation Accuracy: 59.06%\n",
        "Epoch [5/10], Training Loss: 1.004, Validation Accuracy: 58.58%\n",
        "Epoch [6/10], Training Loss: 0.991, Validation Accuracy: 58.32%\n",
        "Epoch [7/10], Training Loss: 0.980, Validation Accuracy: 59.33%\n",
        "Epoch [8/10], Training Loss: 0.960, Validation Accuracy: 59.55%\n",
        "Epoch [9/10], Training Loss: 0.951, Validation Accuracy: 58.60%\n",
        "Epoch [10/10], Training Loss: 0.954, Validation Accuracy: 57.83%\n",
        "Epoch [1/10], Training Loss: 1.081, Validation Accuracy: 59.57%\n",
        "Epoch [2/10], Training Loss: 1.039, Validation Accuracy: 59.29%\n",
        "Epoch [3/10], Training Loss: 1.016, Validation Accuracy: 59.27%\n",
        "Epoch [4/10], Training Loss: 1.001, Validation Accuracy: 59.18%\n",
        "Epoch [5/10], Training Loss: 0.992, Validation Accuracy: 59.24%\n",
        "Epoch [6/10], Training Loss: 0.970, Validation Accuracy: 58.64%\n",
        "Epoch [7/10], Training Loss: 0.961, Validation Accuracy: 59.05%\n",
        "Epoch [8/10], Training Loss: 0.943, Validation Accuracy: 59.76%\n",
        "Epoch [9/10], Training Loss: 0.937, Validation Accuracy: 58.58%\n",
        "Epoch [10/10], Training Loss: 0.918, Validation Accuracy: 59.51%\n",
        "Epoch [1/10], Training Loss: 1.072, Validation Accuracy: 59.68%\n",
        "Epoch [2/10], Training Loss: 1.050, Validation Accuracy: 59.50%\n",
        "Epoch [3/10], Training Loss: 1.008, Validation Accuracy: 59.27%\n",
        "Epoch [4/10], Training Loss: 0.989, Validation Accuracy: 59.77%\n",
        "Epoch [5/10], Training Loss: 0.972, Validation Accuracy: 59.26%\n",
        "Epoch [6/10], Training Loss: 0.964, Validation Accuracy: 59.13%\n",
        "Epoch [7/10], Training Loss: 0.953, Validation Accuracy: 59.33%\n",
        "Epoch [8/10], Training Loss: 0.930, Validation Accuracy: 58.98%\n",
        "Epoch [9/10], Training Loss: 0.912, Validation Accuracy: 58.62%\n",
        "Epoch [10/10], Training Loss: 0.907, Validation Accuracy: 59.56%\n",
        "Epoch [1/10], Training Loss: 1.066, Validation Accuracy: 59.30%\n",
        "Epoch [2/10], Training Loss: 1.026, Validation Accuracy: 58.82%\n",
        "Epoch [3/10], Training Loss: 1.001, Validation Accuracy: 58.98%\n",
        "Epoch [4/10], Training Loss: 0.979, Validation Accuracy: 59.54%\n",
        "Epoch [5/10], Training Loss: 0.959, Validation Accuracy: 59.23%\n",
        "Epoch [6/10], Training Loss: 0.939, Validation Accuracy: 60.37%\n",
        "Epoch [7/10], Training Loss: 0.934, Validation Accuracy: 60.26%\n",
        "Epoch [8/10], Training Loss: 0.914, Validation Accuracy: 59.53%\n",
        "Epoch [9/10], Training Loss: 0.894, Validation Accuracy: 59.57%\n",
        "Epoch [10/10], Training Loss: 0.882, Validation Accuracy: 59.44%\n",
        "Epoch [1/10], Training Loss: 1.075, Validation Accuracy: 59.70%\n",
        "Epoch [2/10], Training Loss: 1.037, Validation Accuracy: 59.92%\n",
        "Epoch [3/10], Training Loss: 1.001, Validation Accuracy: 59.77%\n",
        "Epoch [4/10], Training Loss: 0.968, Validation Accuracy: 60.50%\n",
        "Epoch [5/10], Training Loss: 0.949, Validation Accuracy: 59.80%\n",
        "Epoch [6/10], Training Loss: 0.942, Validation Accuracy: 59.79%\n",
        "Epoch [7/10], Training Loss: 0.923, Validation Accuracy: 59.80%\n",
        "Epoch [8/10], Training Loss: 0.905, Validation Accuracy: 60.09%\n",
        "Epoch [9/10], Training Loss: 0.892, Validation Accuracy: 60.32%\n",
        "Epoch [10/10], Training Loss: 0.881, Validation Accuracy: 59.73%\n",
        "Epoch [1/10], Training Loss: 1.030, Validation Accuracy: 60.64%\n",
        "Epoch [2/10], Training Loss: 0.970, Validation Accuracy: 60.32%\n",
        "Epoch [3/10], Training Loss: 0.955, Validation Accuracy: 60.15%\n",
        "Epoch [4/10], Training Loss: 0.929, Validation Accuracy: 60.26%\n",
        "Epoch [5/10], Training Loss: 0.904, Validation Accuracy: 60.22%\n",
        "Epoch [6/10], Training Loss: 0.896, Validation Accuracy: 60.01%\n",
        "Epoch [7/10], Training Loss: 0.873, Validation Accuracy: 60.41%\n",
        "Epoch [8/10], Training Loss: 0.857, Validation Accuracy: 60.85%\n",
        "Epoch [9/10], Training Loss: 0.849, Validation Accuracy: 59.96%\n",
        "Epoch [10/10], Training Loss: 0.839, Validation Accuracy: 60.41%\n",
        "Epoch [1/10], Training Loss: 1.013, Validation Accuracy: 60.37%\n",
        "Epoch [2/10], Training Loss: 0.968, Validation Accuracy: 60.05%\n",
        "Epoch [3/10], Training Loss: 0.937, Validation Accuracy: 59.81%\n",
        "Epoch [4/10], Training Loss: 0.910, Validation Accuracy: 60.43%\n",
        "Epoch [5/10], Training Loss: 0.885, Validation Accuracy: 60.35%\n",
        "Epoch [6/10], Training Loss: 0.873, Validation Accuracy: 60.23%\n",
        "Epoch [7/10], Training Loss: 0.861, Validation Accuracy: 60.41%\n",
        "Epoch [8/10], Training Loss: 0.840, Validation Accuracy: 59.96%\n",
        "Epoch [9/10], Training Loss: 0.836, Validation Accuracy: 60.56%\n",
        "Epoch [10/10], Training Loss: 0.819, Validation Accuracy: 60.56%\n",
        "Epoch [1/10], Training Loss: 1.025, Validation Accuracy: 60.81%\n",
        "Epoch [2/10], Training Loss: 0.964, Validation Accuracy: 60.77%\n",
        "Epoch [3/10], Training Loss: 0.928, Validation Accuracy: 60.66%\n",
        "Epoch [4/10], Training Loss: 0.905, Validation Accuracy: 60.73%\n",
        "Epoch [5/10], Training Loss: 0.878, Validation Accuracy: 60.01%\n",
        "Epoch [6/10], Training Loss: 0.864, Validation Accuracy: 60.30%\n",
        "Epoch [7/10], Training Loss: 0.855, Validation Accuracy: 60.22%\n",
        "Epoch [8/10], Training Loss: 0.838, Validation Accuracy: 60.89%\n",
        "Epoch [9/10], Training Loss: 0.809, Validation Accuracy: 59.89%\n",
        "Epoch [10/10], Training Loss: 0.807, Validation Accuracy: 60.03%\n",
        "Epoch [1/10], Training Loss: 0.995, Validation Accuracy: 60.17%\n",
        "Epoch [2/10], Training Loss: 0.940, Validation Accuracy: 60.63%\n",
        "Epoch [3/10], Training Loss: 0.909, Validation Accuracy: 60.33%\n",
        "Epoch [4/10], Training Loss: 0.886, Validation Accuracy: 60.29%\n",
        "Epoch [5/10], Training Loss: 0.869, Validation Accuracy: 60.36%\n",
        "Epoch [6/10], Training Loss: 0.848, Validation Accuracy: 60.91%\n",
        "Epoch [7/10], Training Loss: 0.831, Validation Accuracy: 60.14%\n",
        "Epoch [8/10], Training Loss: 0.821, Validation Accuracy: 59.25%\n",
        "Epoch [9/10], Training Loss: 0.810, Validation Accuracy: 60.33%\n",
        "Epoch [10/10], Training Loss: 0.789, Validation Accuracy: 60.37%\n",
        "Epoch [1/10], Training Loss: 1.001, Validation Accuracy: 59.96%\n",
        "Epoch [2/10], Training Loss: 0.952, Validation Accuracy: 60.87%\n",
        "Epoch [3/10], Training Loss: 0.906, Validation Accuracy: 61.25%\n",
        "Epoch [4/10], Training Loss: 0.886, Validation Accuracy: 60.88%\n",
        "Epoch [5/10], Training Loss: 0.862, Validation Accuracy: 61.25%\n",
        "Epoch [6/10], Training Loss: 0.845, Validation Accuracy: 60.72%\n",
        "Epoch [7/10], Training Loss: 0.823, Validation Accuracy: 61.17%\n",
        "Epoch [8/10], Training Loss: 0.804, Validation Accuracy: 60.38%\n",
        "Epoch [9/10], Training Loss: 0.787, Validation Accuracy: 61.07%\n",
        "Epoch [10/10], Training Loss: 0.780, Validation Accuracy: 59.82%\n",
        "Epoch [1/10], Training Loss: 0.971, Validation Accuracy: 61.02%\n",
        "Epoch [2/10], Training Loss: 0.911, Validation Accuracy: 61.31%\n",
        "Epoch [3/10], Training Loss: 0.863, Validation Accuracy: 61.01%\n",
        "Epoch [4/10], Training Loss: 0.844, Validation Accuracy: 61.45%\n",
        "Epoch [5/10], Training Loss: 0.821, Validation Accuracy: 60.65%\n",
        "Epoch [6/10], Training Loss: 0.803, Validation Accuracy: 61.44%\n",
        "Epoch [7/10], Training Loss: 0.783, Validation Accuracy: 60.96%\n",
        "Epoch [8/10], Training Loss: 0.777, Validation Accuracy: 60.14%\n",
        "Epoch [9/10], Training Loss: 0.754, Validation Accuracy: 61.10%\n",
        "Epoch [10/10], Training Loss: 0.740, Validation Accuracy: 61.37%\n",
        "Epoch [1/10], Training Loss: 0.944, Validation Accuracy: 61.03%\n",
        "Epoch [2/10], Training Loss: 0.896, Validation Accuracy: 61.48%\n",
        "Epoch [3/10], Training Loss: 0.873, Validation Accuracy: 61.20%\n",
        "Epoch [4/10], Training Loss: 0.825, Validation Accuracy: 61.31%\n",
        "Epoch [5/10], Training Loss: 0.803, Validation Accuracy: 60.95%\n",
        "Epoch [6/10], Training Loss: 0.789, Validation Accuracy: 60.76%\n",
        "Epoch [7/10], Training Loss: 0.766, Validation Accuracy: 60.87%\n",
        "Epoch [8/10], Training Loss: 0.753, Validation Accuracy: 60.84%\n",
        "Epoch [9/10], Training Loss: 0.736, Validation Accuracy: 60.54%\n",
        "Epoch [10/10], Training Loss: 0.718, Validation Accuracy: 60.23%\n",
        "Epoch [1/10], Training Loss: 0.953, Validation Accuracy: 61.74%\n",
        "Epoch [2/10], Training Loss: 0.888, Validation Accuracy: 60.70%\n",
        "Epoch [3/10], Training Loss: 0.850, Validation Accuracy: 60.87%\n",
        "Epoch [4/10], Training Loss: 0.825, Validation Accuracy: 60.93%\n",
        "Epoch [5/10], Training Loss: 0.802, Validation Accuracy: 60.75%\n",
        "Epoch [6/10], Training Loss: 0.777, Validation Accuracy: 61.52%\n",
        "Epoch [7/10], Training Loss: 0.747, Validation Accuracy: 61.02%\n",
        "Epoch [8/10], Training Loss: 0.745, Validation Accuracy: 60.71%\n",
        "Epoch [9/10], Training Loss: 0.731, Validation Accuracy: 60.33%\n",
        "Epoch [10/10], Training Loss: 0.712, Validation Accuracy: 60.55%\n",
        "Epoch [1/10], Training Loss: 0.943, Validation Accuracy: 61.59%\n",
        "Epoch [2/10], Training Loss: 0.876, Validation Accuracy: 60.98%\n",
        "Epoch [3/10], Training Loss: 0.830, Validation Accuracy: 61.25%\n",
        "Epoch [4/10], Training Loss: 0.816, Validation Accuracy: 61.34%\n",
        "Epoch [5/10], Training Loss: 0.782, Validation Accuracy: 61.59%\n",
        "Epoch [6/10], Training Loss: 0.758, Validation Accuracy: 60.38%\n",
        "Epoch [7/10], Training Loss: 0.753, Validation Accuracy: 60.43%\n",
        "Epoch [8/10], Training Loss: 0.728, Validation Accuracy: 60.19%\n",
        "Epoch [9/10], Training Loss: 0.712, Validation Accuracy: 60.96%\n",
        "Epoch [10/10], Training Loss: 0.692, Validation Accuracy: 60.61%\n",
        "Epoch [1/10], Training Loss: 0.945, Validation Accuracy: 61.08%\n",
        "Epoch [2/10], Training Loss: 0.880, Validation Accuracy: 61.35%\n",
        "Epoch [3/10], Training Loss: 0.836, Validation Accuracy: 61.97%\n",
        "Epoch [4/10], Training Loss: 0.803, Validation Accuracy: 61.84%\n",
        "Epoch [5/10], Training Loss: 0.776, Validation Accuracy: 61.76%\n",
        "Epoch [6/10], Training Loss: 0.752, Validation Accuracy: 61.48%\n",
        "Epoch [7/10], Training Loss: 0.731, Validation Accuracy: 61.10%\n",
        "Epoch [8/10], Training Loss: 0.709, Validation Accuracy: 61.44%\n",
        "Epoch [9/10], Training Loss: 0.696, Validation Accuracy: 60.94%\n",
        "Epoch [10/10], Training Loss: 0.680, Validation Accuracy: 61.01%\n",
        "Epoch [1/10], Training Loss: 0.919, Validation Accuracy: 61.01%\n",
        "Epoch [2/10], Training Loss: 0.835, Validation Accuracy: 61.51%\n",
        "Epoch [3/10], Training Loss: 0.822, Validation Accuracy: 60.92%\n",
        "Epoch [4/10], Training Loss: 0.772, Validation Accuracy: 60.84%\n",
        "Epoch [5/10], Training Loss: 0.739, Validation Accuracy: 61.77%\n",
        "Epoch [6/10], Training Loss: 0.711, Validation Accuracy: 61.58%\n",
        "Epoch [7/10], Training Loss: 0.712, Validation Accuracy: 61.98%\n",
        "Epoch [8/10], Training Loss: 0.678, Validation Accuracy: 61.53%\n",
        "Epoch [9/10], Training Loss: 0.660, Validation Accuracy: 61.63%\n",
        "Epoch [10/10], Training Loss: 0.641, Validation Accuracy: 61.66%\n",
        "Epoch [1/10], Training Loss: 0.916, Validation Accuracy: 61.13%\n",
        "Epoch [2/10], Training Loss: 0.839, Validation Accuracy: 61.73%\n",
        "Epoch [3/10], Training Loss: 0.787, Validation Accuracy: 61.18%\n",
        "Epoch [4/10], Training Loss: 0.753, Validation Accuracy: 60.50%\n",
        "Epoch [5/10], Training Loss: 0.731, Validation Accuracy: 61.84%\n",
        "Epoch [6/10], Training Loss: 0.695, Validation Accuracy: 60.94%\n",
        "Epoch [7/10], Training Loss: 0.674, Validation Accuracy: 60.96%\n",
        "Epoch [8/10], Training Loss: 0.663, Validation Accuracy: 60.93%\n",
        "Epoch [9/10], Training Loss: 0.646, Validation Accuracy: 61.35%\n",
        "Epoch [10/10], Training Loss: 0.618, Validation Accuracy: 61.25%\n",
        "Epoch [1/10], Training Loss: 0.915, Validation Accuracy: 60.31%\n",
        "Epoch [2/10], Training Loss: 0.820, Validation Accuracy: 61.39%\n",
        "Epoch [3/10], Training Loss: 0.773, Validation Accuracy: 61.22%\n",
        "Epoch [4/10], Training Loss: 0.744, Validation Accuracy: 60.27%\n",
        "Epoch [5/10], Training Loss: 0.711, Validation Accuracy: 60.93%\n",
        "Epoch [6/10], Training Loss: 0.691, Validation Accuracy: 61.42%\n",
        "Epoch [7/10], Training Loss: 0.664, Validation Accuracy: 60.34%\n",
        "Epoch [8/10], Training Loss: 0.663, Validation Accuracy: 60.31%\n",
        "Epoch [9/10], Training Loss: 0.634, Validation Accuracy: 60.61%\n",
        "Epoch [10/10], Training Loss: 0.616, Validation Accuracy: 61.15%\n",
        "Epoch [1/10], Training Loss: 0.887, Validation Accuracy: 61.10%\n",
        "Epoch [2/10], Training Loss: 0.812, Validation Accuracy: 61.33%\n",
        "Epoch [3/10], Training Loss: 0.761, Validation Accuracy: 61.22%\n",
        "Epoch [4/10], Training Loss: 0.738, Validation Accuracy: 60.53%\n",
        "Epoch [5/10], Training Loss: 0.707, Validation Accuracy: 60.70%\n",
        "Epoch [6/10], Training Loss: 0.680, Validation Accuracy: 60.69%\n",
        "Epoch [7/10], Training Loss: 0.683, Validation Accuracy: 60.49%\n",
        "Epoch [8/10], Training Loss: 0.641, Validation Accuracy: 60.42%\n",
        "Epoch [9/10], Training Loss: 0.614, Validation Accuracy: 60.22%\n",
        "Epoch [10/10], Training Loss: 0.601, Validation Accuracy: 60.16%\n",
        "Epoch [1/10], Training Loss: 0.900, Validation Accuracy: 60.94%\n",
        "Epoch [2/10], Training Loss: 0.809, Validation Accuracy: 61.56%\n",
        "Epoch [3/10], Training Loss: 0.753, Validation Accuracy: 61.37%\n",
        "Epoch [4/10], Training Loss: 0.721, Validation Accuracy: 61.37%\n",
        "Epoch [5/10], Training Loss: 0.689, Validation Accuracy: 61.26%\n",
        "Epoch [6/10], Training Loss: 0.659, Validation Accuracy: 61.01%\n",
        "Epoch [7/10], Training Loss: 0.639, Validation Accuracy: 60.89%\n",
        "Epoch [8/10], Training Loss: 0.619, Validation Accuracy: 61.23%\n",
        "Epoch [9/10], Training Loss: 0.609, Validation Accuracy: 60.86%\n",
        "Epoch [10/10], Training Loss: 0.579, Validation Accuracy: 60.50%\n",
        "\"\"\"\n",
        "\n",
        "# Regular expression to find validation accuracies\n",
        "accuracies = re.findall(r'Validation Accuracy: (\\d+\\.\\d+)%', log)\n",
        "\n",
        "# Convert accuracies from string to float\n",
        "accuracies = [float(acc) for acc in accuracies]\n",
        "\n",
        "# Print accuracies\n",
        "print(\"Accuracies:\", accuracies)\n",
        "\n",
        "# Print size of the array\n",
        "print(\"Size of array:\", len(accuracies))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZNWDE3OMWyg",
        "outputId": "46926e06-2a9b-49cc-f8ca-7c96c936a68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Training Loss: 2.303, Validation Accuracy: 9.95%\n",
            "Epoch [2/10], Training Loss: 2.302, Validation Accuracy: 9.95%\n",
            "Epoch [3/10], Training Loss: 2.301, Validation Accuracy: 9.95%\n",
            "Epoch [4/10], Training Loss: 2.299, Validation Accuracy: 9.95%\n",
            "Epoch [5/10], Training Loss: 2.298, Validation Accuracy: 9.95%\n",
            "Epoch [6/10], Training Loss: 2.297, Validation Accuracy: 9.95%\n",
            "Epoch [7/10], Training Loss: 2.295, Validation Accuracy: 9.95%\n",
            "Epoch [8/10], Training Loss: 2.293, Validation Accuracy: 9.95%\n",
            "Epoch [9/10], Training Loss: 2.290, Validation Accuracy: 9.95%\n",
            "Epoch [10/10], Training Loss: 2.287, Validation Accuracy: 9.95%\n",
            "Epoch [1/10], Training Loss: 2.284, Validation Accuracy: 9.95%\n",
            "Epoch [2/10], Training Loss: 2.278, Validation Accuracy: 11.23%\n",
            "Epoch [3/10], Training Loss: 2.268, Validation Accuracy: 15.33%\n",
            "Epoch [4/10], Training Loss: 2.254, Validation Accuracy: 17.81%\n",
            "Epoch [5/10], Training Loss: 2.232, Validation Accuracy: 18.93%\n",
            "Epoch [6/10], Training Loss: 2.199, Validation Accuracy: 21.12%\n",
            "Epoch [7/10], Training Loss: 2.156, Validation Accuracy: 23.23%\n",
            "Epoch [8/10], Training Loss: 2.116, Validation Accuracy: 24.90%\n",
            "Epoch [9/10], Training Loss: 2.083, Validation Accuracy: 26.17%\n",
            "Epoch [10/10], Training Loss: 2.052, Validation Accuracy: 27.35%\n",
            "Epoch [1/10], Training Loss: 2.025, Validation Accuracy: 28.54%\n",
            "Epoch [2/10], Training Loss: 1.995, Validation Accuracy: 29.79%\n",
            "Epoch [3/10], Training Loss: 1.967, Validation Accuracy: 30.50%\n",
            "Epoch [4/10], Training Loss: 1.945, Validation Accuracy: 30.68%\n",
            "Epoch [5/10], Training Loss: 1.929, Validation Accuracy: 30.94%\n",
            "Epoch [6/10], Training Loss: 1.917, Validation Accuracy: 31.85%\n",
            "Epoch [7/10], Training Loss: 1.901, Validation Accuracy: 31.69%\n",
            "Epoch [8/10], Training Loss: 1.886, Validation Accuracy: 32.38%\n",
            "Epoch [9/10], Training Loss: 1.870, Validation Accuracy: 33.48%\n",
            "Epoch [10/10], Training Loss: 1.861, Validation Accuracy: 33.30%\n",
            "Epoch [1/10], Training Loss: 1.860, Validation Accuracy: 34.10%\n",
            "Epoch [2/10], Training Loss: 1.843, Validation Accuracy: 33.96%\n",
            "Epoch [3/10], Training Loss: 1.827, Validation Accuracy: 35.04%\n",
            "Epoch [4/10], Training Loss: 1.806, Validation Accuracy: 35.13%\n",
            "Epoch [5/10], Training Loss: 1.782, Validation Accuracy: 35.55%\n",
            "Epoch [6/10], Training Loss: 1.762, Validation Accuracy: 36.88%\n",
            "Epoch [7/10], Training Loss: 1.740, Validation Accuracy: 36.75%\n",
            "Epoch [8/10], Training Loss: 1.722, Validation Accuracy: 37.99%\n",
            "Epoch [9/10], Training Loss: 1.701, Validation Accuracy: 38.26%\n",
            "Epoch [10/10], Training Loss: 1.689, Validation Accuracy: 38.67%\n",
            "Epoch [1/10], Training Loss: 1.693, Validation Accuracy: 39.51%\n",
            "Epoch [2/10], Training Loss: 1.678, Validation Accuracy: 39.26%\n",
            "Epoch [3/10], Training Loss: 1.661, Validation Accuracy: 39.80%\n",
            "Epoch [4/10], Training Loss: 1.647, Validation Accuracy: 39.34%\n",
            "Epoch [5/10], Training Loss: 1.641, Validation Accuracy: 40.42%\n",
            "Epoch [6/10], Training Loss: 1.622, Validation Accuracy: 40.92%\n",
            "Epoch [7/10], Training Loss: 1.611, Validation Accuracy: 40.94%\n",
            "Epoch [8/10], Training Loss: 1.599, Validation Accuracy: 41.35%\n",
            "Epoch [9/10], Training Loss: 1.591, Validation Accuracy: 41.87%\n",
            "Epoch [10/10], Training Loss: 1.581, Validation Accuracy: 42.15%\n",
            "Epoch [1/10], Training Loss: 1.590, Validation Accuracy: 42.49%\n",
            "Epoch [2/10], Training Loss: 1.580, Validation Accuracy: 42.26%\n",
            "Epoch [3/10], Training Loss: 1.569, Validation Accuracy: 43.28%\n",
            "Epoch [4/10], Training Loss: 1.561, Validation Accuracy: 43.51%\n",
            "Epoch [5/10], Training Loss: 1.550, Validation Accuracy: 43.35%\n",
            "Epoch [6/10], Training Loss: 1.538, Validation Accuracy: 44.26%\n",
            "Epoch [7/10], Training Loss: 1.530, Validation Accuracy: 44.61%\n",
            "Epoch [8/10], Training Loss: 1.522, Validation Accuracy: 44.61%\n",
            "Epoch [9/10], Training Loss: 1.515, Validation Accuracy: 44.76%\n",
            "Epoch [10/10], Training Loss: 1.511, Validation Accuracy: 44.90%\n",
            "Epoch [1/10], Training Loss: 1.527, Validation Accuracy: 45.53%\n",
            "Epoch [2/10], Training Loss: 1.516, Validation Accuracy: 45.19%\n",
            "Epoch [3/10], Training Loss: 1.504, Validation Accuracy: 45.44%\n",
            "Epoch [4/10], Training Loss: 1.496, Validation Accuracy: 45.11%\n",
            "Epoch [5/10], Training Loss: 1.483, Validation Accuracy: 45.57%\n",
            "Epoch [6/10], Training Loss: 1.477, Validation Accuracy: 46.40%\n",
            "Epoch [7/10], Training Loss: 1.468, Validation Accuracy: 46.32%\n",
            "Epoch [8/10], Training Loss: 1.463, Validation Accuracy: 46.72%\n",
            "Epoch [9/10], Training Loss: 1.466, Validation Accuracy: 47.09%\n",
            "Epoch [10/10], Training Loss: 1.451, Validation Accuracy: 47.04%\n",
            "Epoch [1/10], Training Loss: 1.493, Validation Accuracy: 46.55%\n",
            "Epoch [2/10], Training Loss: 1.470, Validation Accuracy: 46.48%\n",
            "Epoch [3/10], Training Loss: 1.465, Validation Accuracy: 46.02%\n",
            "Epoch [4/10], Training Loss: 1.455, Validation Accuracy: 47.43%\n",
            "Epoch [5/10], Training Loss: 1.447, Validation Accuracy: 47.47%\n",
            "Epoch [6/10], Training Loss: 1.441, Validation Accuracy: 47.21%\n",
            "Epoch [7/10], Training Loss: 1.435, Validation Accuracy: 47.33%\n",
            "Epoch [8/10], Training Loss: 1.426, Validation Accuracy: 48.07%\n",
            "Epoch [9/10], Training Loss: 1.415, Validation Accuracy: 48.01%\n",
            "Epoch [10/10], Training Loss: 1.411, Validation Accuracy: 47.00%\n",
            "Epoch [1/10], Training Loss: 1.451, Validation Accuracy: 46.67%\n",
            "Epoch [2/10], Training Loss: 1.434, Validation Accuracy: 46.36%\n",
            "Epoch [3/10], Training Loss: 1.436, Validation Accuracy: 48.27%\n",
            "Epoch [4/10], Training Loss: 1.421, Validation Accuracy: 48.63%\n",
            "Epoch [5/10], Training Loss: 1.411, Validation Accuracy: 48.72%\n",
            "Epoch [6/10], Training Loss: 1.404, Validation Accuracy: 47.17%\n",
            "Epoch [7/10], Training Loss: 1.393, Validation Accuracy: 48.85%\n",
            "Epoch [8/10], Training Loss: 1.390, Validation Accuracy: 49.11%\n",
            "Epoch [9/10], Training Loss: 1.378, Validation Accuracy: 49.00%\n",
            "Epoch [10/10], Training Loss: 1.373, Validation Accuracy: 49.01%\n",
            "Epoch [1/10], Training Loss: 1.416, Validation Accuracy: 48.19%\n",
            "Epoch [2/10], Training Loss: 1.399, Validation Accuracy: 50.07%\n",
            "Epoch [3/10], Training Loss: 1.385, Validation Accuracy: 50.23%\n",
            "Epoch [4/10], Training Loss: 1.382, Validation Accuracy: 49.46%\n",
            "Epoch [5/10], Training Loss: 1.376, Validation Accuracy: 50.00%\n",
            "Epoch [6/10], Training Loss: 1.359, Validation Accuracy: 50.28%\n",
            "Epoch [7/10], Training Loss: 1.354, Validation Accuracy: 50.52%\n",
            "Epoch [8/10], Training Loss: 1.343, Validation Accuracy: 50.57%\n",
            "Epoch [9/10], Training Loss: 1.337, Validation Accuracy: 50.13%\n",
            "Epoch [10/10], Training Loss: 1.337, Validation Accuracy: 50.94%\n",
            "Epoch [1/10], Training Loss: 1.380, Validation Accuracy: 51.08%\n",
            "Epoch [2/10], Training Loss: 1.358, Validation Accuracy: 51.37%\n",
            "Epoch [3/10], Training Loss: 1.354, Validation Accuracy: 51.48%\n",
            "Epoch [4/10], Training Loss: 1.356, Validation Accuracy: 51.01%\n",
            "Epoch [5/10], Training Loss: 1.335, Validation Accuracy: 51.67%\n",
            "Epoch [6/10], Training Loss: 1.323, Validation Accuracy: 51.13%\n",
            "Epoch [7/10], Training Loss: 1.314, Validation Accuracy: 51.21%\n",
            "Epoch [8/10], Training Loss: 1.314, Validation Accuracy: 51.24%\n",
            "Epoch [9/10], Training Loss: 1.306, Validation Accuracy: 51.72%\n",
            "Epoch [10/10], Training Loss: 1.301, Validation Accuracy: 51.70%\n",
            "Epoch [1/10], Training Loss: 1.347, Validation Accuracy: 51.49%\n",
            "Epoch [2/10], Training Loss: 1.330, Validation Accuracy: 51.43%\n",
            "Epoch [3/10], Training Loss: 1.319, Validation Accuracy: 51.57%\n",
            "Epoch [4/10], Training Loss: 1.306, Validation Accuracy: 52.82%\n",
            "Epoch [5/10], Training Loss: 1.294, Validation Accuracy: 51.87%\n",
            "Epoch [6/10], Training Loss: 1.290, Validation Accuracy: 51.97%\n",
            "Epoch [7/10], Training Loss: 1.281, Validation Accuracy: 52.49%\n",
            "Epoch [8/10], Training Loss: 1.281, Validation Accuracy: 52.38%\n",
            "Epoch [9/10], Training Loss: 1.268, Validation Accuracy: 52.96%\n",
            "Epoch [10/10], Training Loss: 1.262, Validation Accuracy: 52.10%\n",
            "Epoch [1/10], Training Loss: 1.313, Validation Accuracy: 52.92%\n",
            "Epoch [2/10], Training Loss: 1.288, Validation Accuracy: 52.60%\n",
            "Epoch [3/10], Training Loss: 1.281, Validation Accuracy: 52.72%\n",
            "Epoch [4/10], Training Loss: 1.273, Validation Accuracy: 51.84%\n",
            "Epoch [5/10], Training Loss: 1.272, Validation Accuracy: 52.89%\n",
            "Epoch [6/10], Training Loss: 1.253, Validation Accuracy: 52.42%\n",
            "Epoch [7/10], Training Loss: 1.246, Validation Accuracy: 53.50%\n",
            "Epoch [8/10], Training Loss: 1.237, Validation Accuracy: 52.23%\n",
            "Epoch [9/10], Training Loss: 1.230, Validation Accuracy: 52.48%\n",
            "Epoch [10/10], Training Loss: 1.215, Validation Accuracy: 53.94%\n",
            "Epoch [1/10], Training Loss: 1.298, Validation Accuracy: 53.75%\n",
            "Epoch [2/10], Training Loss: 1.280, Validation Accuracy: 53.88%\n",
            "Epoch [3/10], Training Loss: 1.263, Validation Accuracy: 54.00%\n",
            "Epoch [4/10], Training Loss: 1.249, Validation Accuracy: 53.72%\n",
            "Epoch [5/10], Training Loss: 1.249, Validation Accuracy: 54.32%\n",
            "Epoch [6/10], Training Loss: 1.221, Validation Accuracy: 54.71%\n",
            "Epoch [7/10], Training Loss: 1.209, Validation Accuracy: 54.39%\n",
            "Epoch [8/10], Training Loss: 1.213, Validation Accuracy: 54.64%\n",
            "Epoch [9/10], Training Loss: 1.202, Validation Accuracy: 54.44%\n",
            "Epoch [10/10], Training Loss: 1.195, Validation Accuracy: 54.43%\n",
            "Epoch [1/10], Training Loss: 1.263, Validation Accuracy: 54.73%\n",
            "Epoch [2/10], Training Loss: 1.241, Validation Accuracy: 55.25%\n",
            "Epoch [3/10], Training Loss: 1.228, Validation Accuracy: 54.92%\n",
            "Epoch [4/10], Training Loss: 1.214, Validation Accuracy: 54.86%\n",
            "Epoch [5/10], Training Loss: 1.196, Validation Accuracy: 54.77%\n",
            "Epoch [6/10], Training Loss: 1.189, Validation Accuracy: 55.52%\n",
            "Epoch [7/10], Training Loss: 1.189, Validation Accuracy: 55.64%\n",
            "Epoch [8/10], Training Loss: 1.171, Validation Accuracy: 54.16%\n",
            "Epoch [9/10], Training Loss: 1.171, Validation Accuracy: 55.82%\n",
            "Epoch [10/10], Training Loss: 1.149, Validation Accuracy: 56.19%\n",
            "Epoch [1/10], Training Loss: 1.243, Validation Accuracy: 55.79%\n",
            "Epoch [2/10], Training Loss: 1.222, Validation Accuracy: 56.13%\n",
            "Epoch [3/10], Training Loss: 1.208, Validation Accuracy: 55.05%\n",
            "Epoch [4/10], Training Loss: 1.196, Validation Accuracy: 55.00%\n",
            "Epoch [5/10], Training Loss: 1.180, Validation Accuracy: 56.10%\n",
            "Epoch [6/10], Training Loss: 1.167, Validation Accuracy: 55.98%\n",
            "Epoch [7/10], Training Loss: 1.161, Validation Accuracy: 56.19%\n",
            "Epoch [8/10], Training Loss: 1.148, Validation Accuracy: 56.18%\n",
            "Epoch [9/10], Training Loss: 1.133, Validation Accuracy: 56.07%\n",
            "Epoch [10/10], Training Loss: 1.132, Validation Accuracy: 56.53%\n",
            "Epoch [1/10], Training Loss: 1.210, Validation Accuracy: 55.64%\n",
            "Epoch [2/10], Training Loss: 1.198, Validation Accuracy: 56.22%\n",
            "Epoch [3/10], Training Loss: 1.175, Validation Accuracy: 57.02%\n",
            "Epoch [4/10], Training Loss: 1.162, Validation Accuracy: 56.59%\n",
            "Epoch [5/10], Training Loss: 1.151, Validation Accuracy: 55.97%\n",
            "Epoch [6/10], Training Loss: 1.145, Validation Accuracy: 56.86%\n",
            "Epoch [7/10], Training Loss: 1.130, Validation Accuracy: 56.61%\n",
            "Epoch [8/10], Training Loss: 1.124, Validation Accuracy: 56.09%\n",
            "Epoch [9/10], Training Loss: 1.128, Validation Accuracy: 55.81%\n",
            "Epoch [10/10], Training Loss: 1.110, Validation Accuracy: 56.76%\n",
            "Epoch [1/10], Training Loss: 1.200, Validation Accuracy: 56.70%\n",
            "Epoch [2/10], Training Loss: 1.160, Validation Accuracy: 57.37%\n",
            "Epoch [3/10], Training Loss: 1.150, Validation Accuracy: 56.84%\n",
            "Epoch [4/10], Training Loss: 1.129, Validation Accuracy: 57.20%\n",
            "Epoch [5/10], Training Loss: 1.118, Validation Accuracy: 56.90%\n",
            "Epoch [6/10], Training Loss: 1.105, Validation Accuracy: 57.62%\n",
            "Epoch [7/10], Training Loss: 1.102, Validation Accuracy: 56.97%\n",
            "Epoch [8/10], Training Loss: 1.085, Validation Accuracy: 57.24%\n",
            "Epoch [9/10], Training Loss: 1.079, Validation Accuracy: 57.36%\n",
            "Epoch [10/10], Training Loss: 1.066, Validation Accuracy: 57.20%\n",
            "Epoch [1/10], Training Loss: 1.178, Validation Accuracy: 57.55%\n",
            "Epoch [2/10], Training Loss: 1.149, Validation Accuracy: 57.81%\n",
            "Epoch [3/10], Training Loss: 1.121, Validation Accuracy: 56.84%\n",
            "Epoch [4/10], Training Loss: 1.109, Validation Accuracy: 57.49%\n",
            "Epoch [5/10], Training Loss: 1.092, Validation Accuracy: 57.42%\n",
            "Epoch [6/10], Training Loss: 1.091, Validation Accuracy: 58.18%\n",
            "Epoch [7/10], Training Loss: 1.072, Validation Accuracy: 57.78%\n",
            "Epoch [8/10], Training Loss: 1.059, Validation Accuracy: 56.59%\n",
            "Epoch [9/10], Training Loss: 1.057, Validation Accuracy: 57.80%\n",
            "Epoch [10/10], Training Loss: 1.049, Validation Accuracy: 57.47%\n",
            "Epoch [1/10], Training Loss: 1.160, Validation Accuracy: 57.94%\n",
            "Epoch [2/10], Training Loss: 1.122, Validation Accuracy: 58.61%\n",
            "Epoch [3/10], Training Loss: 1.098, Validation Accuracy: 58.21%\n",
            "Epoch [4/10], Training Loss: 1.080, Validation Accuracy: 58.79%\n",
            "Epoch [5/10], Training Loss: 1.075, Validation Accuracy: 57.76%\n",
            "Epoch [6/10], Training Loss: 1.067, Validation Accuracy: 58.71%\n",
            "Epoch [7/10], Training Loss: 1.051, Validation Accuracy: 58.41%\n",
            "Epoch [8/10], Training Loss: 1.041, Validation Accuracy: 58.22%\n",
            "Epoch [9/10], Training Loss: 1.033, Validation Accuracy: 58.68%\n",
            "Epoch [10/10], Training Loss: 1.016, Validation Accuracy: 59.16%\n",
            "Epoch [1/10], Training Loss: 1.135, Validation Accuracy: 58.69%\n",
            "Epoch [2/10], Training Loss: 1.102, Validation Accuracy: 59.39%\n",
            "Epoch [3/10], Training Loss: 1.079, Validation Accuracy: 58.91%\n",
            "Epoch [4/10], Training Loss: 1.069, Validation Accuracy: 57.47%\n",
            "Epoch [5/10], Training Loss: 1.058, Validation Accuracy: 59.22%\n",
            "Epoch [6/10], Training Loss: 1.029, Validation Accuracy: 59.29%\n",
            "Epoch [7/10], Training Loss: 1.021, Validation Accuracy: 58.90%\n",
            "Epoch [8/10], Training Loss: 1.011, Validation Accuracy: 58.89%\n",
            "Epoch [9/10], Training Loss: 1.006, Validation Accuracy: 57.81%\n",
            "Epoch [10/10], Training Loss: 0.990, Validation Accuracy: 58.62%\n",
            "Epoch [1/10], Training Loss: 1.122, Validation Accuracy: 58.88%\n",
            "Epoch [2/10], Training Loss: 1.085, Validation Accuracy: 59.58%\n",
            "Epoch [3/10], Training Loss: 1.068, Validation Accuracy: 58.48%\n",
            "Epoch [4/10], Training Loss: 1.055, Validation Accuracy: 58.84%\n",
            "Epoch [5/10], Training Loss: 1.032, Validation Accuracy: 59.26%\n",
            "Epoch [6/10], Training Loss: 1.023, Validation Accuracy: 59.26%\n",
            "Epoch [7/10], Training Loss: 1.010, Validation Accuracy: 58.50%\n",
            "Epoch [8/10], Training Loss: 0.996, Validation Accuracy: 58.54%\n",
            "Epoch [9/10], Training Loss: 0.983, Validation Accuracy: 59.60%\n",
            "Epoch [10/10], Training Loss: 0.973, Validation Accuracy: 59.30%\n",
            "Epoch [1/10], Training Loss: 1.094, Validation Accuracy: 59.35%\n",
            "Epoch [2/10], Training Loss: 1.072, Validation Accuracy: 58.52%\n",
            "Epoch [3/10], Training Loss: 1.040, Validation Accuracy: 59.57%\n",
            "Epoch [4/10], Training Loss: 1.026, Validation Accuracy: 59.36%\n",
            "Epoch [5/10], Training Loss: 1.008, Validation Accuracy: 59.96%\n",
            "Epoch [6/10], Training Loss: 0.995, Validation Accuracy: 59.30%\n",
            "Epoch [7/10], Training Loss: 0.988, Validation Accuracy: 59.60%\n",
            "Epoch [8/10], Training Loss: 0.970, Validation Accuracy: 59.25%\n",
            "Epoch [9/10], Training Loss: 0.964, Validation Accuracy: 59.95%\n",
            "Epoch [10/10], Training Loss: 0.948, Validation Accuracy: 58.49%\n",
            "Epoch [1/10], Training Loss: 1.095, Validation Accuracy: 60.00%\n",
            "Epoch [2/10], Training Loss: 1.048, Validation Accuracy: 60.30%\n",
            "Epoch [3/10], Training Loss: 1.026, Validation Accuracy: 59.92%\n",
            "Epoch [4/10], Training Loss: 1.004, Validation Accuracy: 60.21%\n",
            "Epoch [5/10], Training Loss: 0.994, Validation Accuracy: 60.03%\n",
            "Epoch [6/10], Training Loss: 0.983, Validation Accuracy: 59.33%\n",
            "Epoch [7/10], Training Loss: 0.975, Validation Accuracy: 59.84%\n",
            "Epoch [8/10], Training Loss: 0.948, Validation Accuracy: 59.82%\n",
            "Epoch [9/10], Training Loss: 0.941, Validation Accuracy: 60.28%\n",
            "Epoch [10/10], Training Loss: 0.925, Validation Accuracy: 59.73%\n",
            "Epoch [1/10], Training Loss: 1.070, Validation Accuracy: 60.40%\n",
            "Epoch [2/10], Training Loss: 1.029, Validation Accuracy: 60.05%\n",
            "Epoch [3/10], Training Loss: 0.998, Validation Accuracy: 60.54%\n",
            "Epoch [4/10], Training Loss: 0.988, Validation Accuracy: 60.07%\n",
            "Epoch [5/10], Training Loss: 0.960, Validation Accuracy: 59.74%\n",
            "Epoch [6/10], Training Loss: 0.954, Validation Accuracy: 60.45%\n",
            "Epoch [7/10], Training Loss: 0.946, Validation Accuracy: 60.39%\n",
            "Epoch [8/10], Training Loss: 0.913, Validation Accuracy: 60.10%\n",
            "Epoch [9/10], Training Loss: 0.919, Validation Accuracy: 60.14%\n",
            "Epoch [10/10], Training Loss: 0.901, Validation Accuracy: 60.85%\n",
            "Epoch [1/10], Training Loss: 1.052, Validation Accuracy: 60.43%\n",
            "Epoch [2/10], Training Loss: 1.011, Validation Accuracy: 60.62%\n",
            "Epoch [3/10], Training Loss: 0.993, Validation Accuracy: 59.90%\n",
            "Epoch [4/10], Training Loss: 0.967, Validation Accuracy: 60.80%\n",
            "Epoch [5/10], Training Loss: 0.951, Validation Accuracy: 61.21%\n",
            "Epoch [6/10], Training Loss: 0.941, Validation Accuracy: 60.30%\n",
            "Epoch [7/10], Training Loss: 0.915, Validation Accuracy: 60.94%\n",
            "Epoch [8/10], Training Loss: 0.905, Validation Accuracy: 60.44%\n",
            "Epoch [9/10], Training Loss: 0.895, Validation Accuracy: 60.73%\n",
            "Epoch [10/10], Training Loss: 0.875, Validation Accuracy: 60.68%\n",
            "Epoch [1/10], Training Loss: 1.036, Validation Accuracy: 60.89%\n",
            "Epoch [2/10], Training Loss: 0.993, Validation Accuracy: 60.95%\n",
            "Epoch [3/10], Training Loss: 0.966, Validation Accuracy: 60.41%\n",
            "Epoch [4/10], Training Loss: 0.948, Validation Accuracy: 60.85%\n",
            "Epoch [5/10], Training Loss: 0.930, Validation Accuracy: 61.27%\n",
            "Epoch [6/10], Training Loss: 0.915, Validation Accuracy: 61.11%\n",
            "Epoch [7/10], Training Loss: 0.892, Validation Accuracy: 60.97%\n",
            "Epoch [8/10], Training Loss: 0.877, Validation Accuracy: 60.56%\n",
            "Epoch [9/10], Training Loss: 0.867, Validation Accuracy: 60.72%\n",
            "Epoch [10/10], Training Loss: 0.848, Validation Accuracy: 60.37%\n",
            "Epoch [1/10], Training Loss: 1.024, Validation Accuracy: 61.48%\n",
            "Epoch [2/10], Training Loss: 0.974, Validation Accuracy: 61.37%\n",
            "Epoch [3/10], Training Loss: 0.949, Validation Accuracy: 61.87%\n",
            "Epoch [4/10], Training Loss: 0.926, Validation Accuracy: 61.73%\n",
            "Epoch [5/10], Training Loss: 0.906, Validation Accuracy: 60.65%\n",
            "Epoch [6/10], Training Loss: 0.905, Validation Accuracy: 61.14%\n",
            "Epoch [7/10], Training Loss: 0.870, Validation Accuracy: 61.99%\n",
            "Epoch [8/10], Training Loss: 0.861, Validation Accuracy: 61.81%\n",
            "Epoch [9/10], Training Loss: 0.851, Validation Accuracy: 61.04%\n",
            "Epoch [10/10], Training Loss: 0.842, Validation Accuracy: 60.97%\n",
            "Epoch [1/10], Training Loss: 1.008, Validation Accuracy: 61.45%\n",
            "Epoch [2/10], Training Loss: 0.965, Validation Accuracy: 61.56%\n",
            "Epoch [3/10], Training Loss: 0.930, Validation Accuracy: 61.72%\n",
            "Epoch [4/10], Training Loss: 0.908, Validation Accuracy: 60.94%\n",
            "Epoch [5/10], Training Loss: 0.891, Validation Accuracy: 61.34%\n",
            "Epoch [6/10], Training Loss: 0.870, Validation Accuracy: 61.45%\n",
            "Epoch [7/10], Training Loss: 0.855, Validation Accuracy: 62.02%\n",
            "Epoch [8/10], Training Loss: 0.843, Validation Accuracy: 60.89%\n",
            "Epoch [9/10], Training Loss: 0.826, Validation Accuracy: 60.62%\n",
            "Epoch [10/10], Training Loss: 0.816, Validation Accuracy: 60.84%\n",
            "Epoch [1/10], Training Loss: 1.004, Validation Accuracy: 62.11%\n",
            "Epoch [2/10], Training Loss: 0.937, Validation Accuracy: 62.00%\n",
            "Epoch [3/10], Training Loss: 0.916, Validation Accuracy: 62.10%\n",
            "Epoch [4/10], Training Loss: 0.888, Validation Accuracy: 62.07%\n",
            "Epoch [5/10], Training Loss: 0.867, Validation Accuracy: 62.32%\n",
            "Epoch [6/10], Training Loss: 0.850, Validation Accuracy: 61.56%\n",
            "Epoch [7/10], Training Loss: 0.834, Validation Accuracy: 60.80%\n",
            "Epoch [8/10], Training Loss: 0.817, Validation Accuracy: 61.99%\n",
            "Epoch [9/10], Training Loss: 0.793, Validation Accuracy: 62.06%\n",
            "Epoch [10/10], Training Loss: 0.785, Validation Accuracy: 61.74%\n",
            "Epoch [1/10], Training Loss: 0.976, Validation Accuracy: 60.94%\n",
            "Epoch [2/10], Training Loss: 0.934, Validation Accuracy: 61.91%\n",
            "Epoch [3/10], Training Loss: 0.895, Validation Accuracy: 62.11%\n",
            "Epoch [4/10], Training Loss: 0.877, Validation Accuracy: 61.24%\n",
            "Epoch [5/10], Training Loss: 0.857, Validation Accuracy: 61.41%\n",
            "Epoch [6/10], Training Loss: 0.842, Validation Accuracy: 61.96%\n",
            "Epoch [7/10], Training Loss: 0.823, Validation Accuracy: 61.70%\n",
            "Epoch [8/10], Training Loss: 0.796, Validation Accuracy: 62.01%\n",
            "Epoch [9/10], Training Loss: 0.794, Validation Accuracy: 61.27%\n",
            "Epoch [10/10], Training Loss: 0.790, Validation Accuracy: 61.17%\n",
            "Epoch [1/10], Training Loss: 0.968, Validation Accuracy: 62.08%\n",
            "Epoch [2/10], Training Loss: 0.901, Validation Accuracy: 62.37%\n",
            "Epoch [3/10], Training Loss: 0.882, Validation Accuracy: 60.55%\n",
            "Epoch [4/10], Training Loss: 0.861, Validation Accuracy: 62.63%\n",
            "Epoch [5/10], Training Loss: 0.828, Validation Accuracy: 62.16%\n",
            "Epoch [6/10], Training Loss: 0.807, Validation Accuracy: 62.25%\n",
            "Epoch [7/10], Training Loss: 0.800, Validation Accuracy: 62.45%\n",
            "Epoch [8/10], Training Loss: 0.782, Validation Accuracy: 62.01%\n",
            "Epoch [9/10], Training Loss: 0.767, Validation Accuracy: 61.97%\n",
            "Epoch [10/10], Training Loss: 0.747, Validation Accuracy: 61.91%\n",
            "Epoch [1/10], Training Loss: 0.972, Validation Accuracy: 62.68%\n",
            "Epoch [2/10], Training Loss: 0.907, Validation Accuracy: 62.10%\n",
            "Epoch [3/10], Training Loss: 0.866, Validation Accuracy: 62.43%\n",
            "Epoch [4/10], Training Loss: 0.836, Validation Accuracy: 62.96%\n",
            "Epoch [5/10], Training Loss: 0.823, Validation Accuracy: 62.73%\n",
            "Epoch [6/10], Training Loss: 0.804, Validation Accuracy: 62.52%\n",
            "Epoch [7/10], Training Loss: 0.779, Validation Accuracy: 62.76%\n",
            "Epoch [8/10], Training Loss: 0.769, Validation Accuracy: 62.59%\n",
            "Epoch [9/10], Training Loss: 0.749, Validation Accuracy: 61.87%\n",
            "Epoch [10/10], Training Loss: 0.736, Validation Accuracy: 62.63%\n",
            "Epoch [1/10], Training Loss: 0.945, Validation Accuracy: 61.85%\n",
            "Epoch [2/10], Training Loss: 0.881, Validation Accuracy: 62.11%\n",
            "Epoch [3/10], Training Loss: 0.847, Validation Accuracy: 62.80%\n",
            "Epoch [4/10], Training Loss: 0.823, Validation Accuracy: 62.11%\n",
            "Epoch [5/10], Training Loss: 0.805, Validation Accuracy: 63.09%\n",
            "Epoch [6/10], Training Loss: 0.771, Validation Accuracy: 62.39%\n",
            "Epoch [7/10], Training Loss: 0.763, Validation Accuracy: 62.11%\n",
            "Epoch [8/10], Training Loss: 0.744, Validation Accuracy: 62.09%\n",
            "Epoch [9/10], Training Loss: 0.731, Validation Accuracy: 62.50%\n",
            "Epoch [10/10], Training Loss: 0.713, Validation Accuracy: 61.99%\n",
            "Epoch [1/10], Training Loss: 0.929, Validation Accuracy: 62.50%\n",
            "Epoch [2/10], Training Loss: 0.864, Validation Accuracy: 62.06%\n",
            "Epoch [3/10], Training Loss: 0.824, Validation Accuracy: 62.75%\n",
            "Epoch [4/10], Training Loss: 0.803, Validation Accuracy: 62.40%\n",
            "Epoch [5/10], Training Loss: 0.787, Validation Accuracy: 62.71%\n",
            "Epoch [6/10], Training Loss: 0.755, Validation Accuracy: 63.21%\n",
            "Epoch [7/10], Training Loss: 0.738, Validation Accuracy: 62.56%\n",
            "Epoch [8/10], Training Loss: 0.716, Validation Accuracy: 63.08%\n",
            "Epoch [9/10], Training Loss: 0.699, Validation Accuracy: 63.09%\n",
            "Epoch [10/10], Training Loss: 0.678, Validation Accuracy: 62.80%\n",
            "Epoch [1/10], Training Loss: 0.925, Validation Accuracy: 62.07%\n",
            "Epoch [2/10], Training Loss: 0.861, Validation Accuracy: 63.03%\n",
            "Epoch [3/10], Training Loss: 0.820, Validation Accuracy: 62.94%\n",
            "Epoch [4/10], Training Loss: 0.787, Validation Accuracy: 62.42%\n",
            "Epoch [5/10], Training Loss: 0.764, Validation Accuracy: 61.92%\n",
            "Epoch [6/10], Training Loss: 0.743, Validation Accuracy: 62.82%\n",
            "Epoch [7/10], Training Loss: 0.731, Validation Accuracy: 61.72%\n",
            "Epoch [8/10], Training Loss: 0.702, Validation Accuracy: 62.13%\n",
            "Epoch [9/10], Training Loss: 0.698, Validation Accuracy: 62.68%\n",
            "Epoch [10/10], Training Loss: 0.673, Validation Accuracy: 62.18%\n",
            "Epoch [1/10], Training Loss: 0.901, Validation Accuracy: 62.87%\n",
            "Epoch [2/10], Training Loss: 0.836, Validation Accuracy: 63.00%\n",
            "Epoch [3/10], Training Loss: 0.803, Validation Accuracy: 62.22%\n",
            "Epoch [4/10], Training Loss: 0.765, Validation Accuracy: 63.25%\n",
            "Epoch [5/10], Training Loss: 0.754, Validation Accuracy: 62.57%\n",
            "Epoch [6/10], Training Loss: 0.725, Validation Accuracy: 63.32%\n",
            "Epoch [7/10], Training Loss: 0.711, Validation Accuracy: 62.95%\n",
            "Epoch [8/10], Training Loss: 0.691, Validation Accuracy: 63.14%\n",
            "Epoch [9/10], Training Loss: 0.675, Validation Accuracy: 62.74%\n",
            "Epoch [10/10], Training Loss: 0.658, Validation Accuracy: 63.10%\n",
            "Epoch [1/10], Training Loss: 0.900, Validation Accuracy: 62.88%\n",
            "Epoch [2/10], Training Loss: 0.842, Validation Accuracy: 62.94%\n",
            "Epoch [3/10], Training Loss: 0.791, Validation Accuracy: 63.69%\n",
            "Epoch [4/10], Training Loss: 0.764, Validation Accuracy: 63.04%\n",
            "Epoch [5/10], Training Loss: 0.735, Validation Accuracy: 63.49%\n",
            "Epoch [6/10], Training Loss: 0.708, Validation Accuracy: 63.58%\n",
            "Epoch [7/10], Training Loss: 0.692, Validation Accuracy: 63.32%\n",
            "Epoch [8/10], Training Loss: 0.671, Validation Accuracy: 63.02%\n",
            "Epoch [9/10], Training Loss: 0.662, Validation Accuracy: 63.46%\n",
            "Epoch [10/10], Training Loss: 0.638, Validation Accuracy: 62.64%\n",
            "Epoch [1/10], Training Loss: 0.886, Validation Accuracy: 62.93%\n",
            "Epoch [2/10], Training Loss: 0.804, Validation Accuracy: 63.60%\n",
            "Epoch [3/10], Training Loss: 0.776, Validation Accuracy: 63.74%\n",
            "Epoch [4/10], Training Loss: 0.733, Validation Accuracy: 63.11%\n",
            "Epoch [5/10], Training Loss: 0.722, Validation Accuracy: 63.13%\n",
            "Epoch [6/10], Training Loss: 0.696, Validation Accuracy: 62.12%\n",
            "Epoch [7/10], Training Loss: 0.680, Validation Accuracy: 63.14%\n",
            "Epoch [8/10], Training Loss: 0.650, Validation Accuracy: 62.05%\n",
            "Epoch [9/10], Training Loss: 0.634, Validation Accuracy: 63.29%\n",
            "Epoch [10/10], Training Loss: 0.615, Validation Accuracy: 63.31%\n",
            "Epoch [1/10], Training Loss: 0.891, Validation Accuracy: 62.34%\n",
            "Epoch [2/10], Training Loss: 0.792, Validation Accuracy: 62.90%\n",
            "Epoch [3/10], Training Loss: 0.748, Validation Accuracy: 63.47%\n",
            "Epoch [4/10], Training Loss: 0.714, Validation Accuracy: 62.45%\n",
            "Epoch [5/10], Training Loss: 0.694, Validation Accuracy: 63.35%\n",
            "Epoch [6/10], Training Loss: 0.677, Validation Accuracy: 62.45%\n",
            "Epoch [7/10], Training Loss: 0.645, Validation Accuracy: 61.89%\n",
            "Epoch [8/10], Training Loss: 0.623, Validation Accuracy: 62.48%\n",
            "Epoch [9/10], Training Loss: 0.601, Validation Accuracy: 62.42%\n",
            "Epoch [10/10], Training Loss: 0.592, Validation Accuracy: 63.17%\n",
            "Epoch [1/10], Training Loss: 0.871, Validation Accuracy: 62.82%\n",
            "Epoch [2/10], Training Loss: 0.786, Validation Accuracy: 63.08%\n",
            "Epoch [3/10], Training Loss: 0.737, Validation Accuracy: 61.56%\n",
            "Epoch [4/10], Training Loss: 0.727, Validation Accuracy: 63.07%\n",
            "Epoch [5/10], Training Loss: 0.674, Validation Accuracy: 63.33%\n",
            "Epoch [6/10], Training Loss: 0.661, Validation Accuracy: 63.32%\n",
            "Epoch [7/10], Training Loss: 0.638, Validation Accuracy: 63.23%\n",
            "Epoch [8/10], Training Loss: 0.616, Validation Accuracy: 63.02%\n",
            "Epoch [9/10], Training Loss: 0.600, Validation Accuracy: 62.14%\n",
            "Epoch [10/10], Training Loss: 0.581, Validation Accuracy: 63.06%\n",
            "Epoch [1/10], Training Loss: 0.860, Validation Accuracy: 62.60%\n",
            "Epoch [2/10], Training Loss: 0.780, Validation Accuracy: 63.06%\n",
            "Epoch [3/10], Training Loss: 0.736, Validation Accuracy: 63.53%\n",
            "Epoch [4/10], Training Loss: 0.687, Validation Accuracy: 63.20%\n",
            "Epoch [5/10], Training Loss: 0.675, Validation Accuracy: 62.76%\n",
            "Epoch [6/10], Training Loss: 0.643, Validation Accuracy: 62.81%\n",
            "Epoch [7/10], Training Loss: 0.624, Validation Accuracy: 63.26%\n",
            "Epoch [8/10], Training Loss: 0.596, Validation Accuracy: 63.10%\n",
            "Epoch [9/10], Training Loss: 0.585, Validation Accuracy: 62.93%\n",
            "Epoch [10/10], Training Loss: 0.561, Validation Accuracy: 62.60%\n",
            "Epoch [1/10], Training Loss: 0.856, Validation Accuracy: 62.76%\n",
            "Epoch [2/10], Training Loss: 0.777, Validation Accuracy: 63.57%\n",
            "Epoch [3/10], Training Loss: 0.721, Validation Accuracy: 63.31%\n",
            "Epoch [4/10], Training Loss: 0.691, Validation Accuracy: 63.14%\n",
            "Epoch [5/10], Training Loss: 0.659, Validation Accuracy: 63.74%\n",
            "Epoch [6/10], Training Loss: 0.636, Validation Accuracy: 63.00%\n",
            "Epoch [7/10], Training Loss: 0.611, Validation Accuracy: 63.29%\n",
            "Epoch [8/10], Training Loss: 0.585, Validation Accuracy: 63.04%\n",
            "Epoch [9/10], Training Loss: 0.570, Validation Accuracy: 63.22%\n",
            "Epoch [10/10], Training Loss: 0.555, Validation Accuracy: 62.72%\n",
            "Epoch [1/10], Training Loss: 0.849, Validation Accuracy: 62.47%\n",
            "Epoch [2/10], Training Loss: 0.736, Validation Accuracy: 62.82%\n",
            "Epoch [3/10], Training Loss: 0.693, Validation Accuracy: 63.14%\n",
            "Epoch [4/10], Training Loss: 0.657, Validation Accuracy: 63.46%\n",
            "Epoch [5/10], Training Loss: 0.625, Validation Accuracy: 63.69%\n",
            "Epoch [6/10], Training Loss: 0.598, Validation Accuracy: 62.76%\n",
            "Epoch [7/10], Training Loss: 0.580, Validation Accuracy: 63.23%\n",
            "Epoch [8/10], Training Loss: 0.558, Validation Accuracy: 62.69%\n",
            "Epoch [9/10], Training Loss: 0.544, Validation Accuracy: 62.70%\n",
            "Epoch [10/10], Training Loss: 0.516, Validation Accuracy: 63.69%\n",
            "Epoch [1/10], Training Loss: 0.835, Validation Accuracy: 62.32%\n",
            "Epoch [2/10], Training Loss: 0.718, Validation Accuracy: 63.00%\n",
            "Epoch [3/10], Training Loss: 0.672, Validation Accuracy: 63.43%\n",
            "Epoch [4/10], Training Loss: 0.638, Validation Accuracy: 63.19%\n",
            "Epoch [5/10], Training Loss: 0.607, Validation Accuracy: 63.16%\n",
            "Epoch [6/10], Training Loss: 0.584, Validation Accuracy: 63.24%\n",
            "Epoch [7/10], Training Loss: 0.560, Validation Accuracy: 63.22%\n",
            "Epoch [8/10], Training Loss: 0.536, Validation Accuracy: 62.97%\n",
            "Epoch [9/10], Training Loss: 0.519, Validation Accuracy: 62.73%\n",
            "Epoch [10/10], Training Loss: 0.492, Validation Accuracy: 62.00%\n",
            "Epoch [1/10], Training Loss: 0.836, Validation Accuracy: 62.25%\n",
            "Epoch [2/10], Training Loss: 0.735, Validation Accuracy: 62.68%\n",
            "Epoch [3/10], Training Loss: 0.666, Validation Accuracy: 62.97%\n",
            "Epoch [4/10], Training Loss: 0.633, Validation Accuracy: 62.98%\n",
            "Epoch [5/10], Training Loss: 0.605, Validation Accuracy: 62.69%\n",
            "Epoch [6/10], Training Loss: 0.577, Validation Accuracy: 63.27%\n",
            "Epoch [7/10], Training Loss: 0.558, Validation Accuracy: 63.03%\n",
            "Epoch [8/10], Training Loss: 0.537, Validation Accuracy: 62.34%\n",
            "Epoch [9/10], Training Loss: 0.520, Validation Accuracy: 62.74%\n",
            "Epoch [10/10], Training Loss: 0.500, Validation Accuracy: 62.42%\n",
            "Epoch [1/10], Training Loss: 0.814, Validation Accuracy: 62.62%\n",
            "Epoch [2/10], Training Loss: 0.716, Validation Accuracy: 62.38%\n",
            "Epoch [3/10], Training Loss: 0.667, Validation Accuracy: 63.33%\n",
            "Epoch [4/10], Training Loss: 0.619, Validation Accuracy: 63.23%\n",
            "Epoch [5/10], Training Loss: 0.585, Validation Accuracy: 62.97%\n",
            "Epoch [6/10], Training Loss: 0.567, Validation Accuracy: 62.69%\n",
            "Epoch [7/10], Training Loss: 0.543, Validation Accuracy: 63.03%\n",
            "Epoch [8/10], Training Loss: 0.510, Validation Accuracy: 62.93%\n",
            "Epoch [9/10], Training Loss: 0.499, Validation Accuracy: 62.85%\n",
            "Epoch [10/10], Training Loss: 0.486, Validation Accuracy: 62.66%\n",
            "Epoch [1/10], Training Loss: 0.821, Validation Accuracy: 62.96%\n",
            "Epoch [2/10], Training Loss: 0.710, Validation Accuracy: 63.02%\n",
            "Epoch [3/10], Training Loss: 0.647, Validation Accuracy: 62.98%\n",
            "Epoch [4/10], Training Loss: 0.605, Validation Accuracy: 63.17%\n",
            "Epoch [5/10], Training Loss: 0.572, Validation Accuracy: 62.14%\n",
            "Epoch [6/10], Training Loss: 0.544, Validation Accuracy: 62.93%\n",
            "Epoch [7/10], Training Loss: 0.524, Validation Accuracy: 61.94%\n",
            "Epoch [8/10], Training Loss: 0.510, Validation Accuracy: 62.71%\n",
            "Epoch [9/10], Training Loss: 0.477, Validation Accuracy: 62.36%\n",
            "Epoch [10/10], Training Loss: 0.471, Validation Accuracy: 62.60%\n",
            "Epoch [1/10], Training Loss: 0.791, Validation Accuracy: 62.06%\n",
            "Epoch [2/10], Training Loss: 0.690, Validation Accuracy: 62.34%\n",
            "Epoch [3/10], Training Loss: 0.633, Validation Accuracy: 62.30%\n",
            "Epoch [4/10], Training Loss: 0.593, Validation Accuracy: 63.05%\n",
            "Epoch [5/10], Training Loss: 0.554, Validation Accuracy: 62.03%\n",
            "Epoch [6/10], Training Loss: 0.524, Validation Accuracy: 62.40%\n",
            "Epoch [7/10], Training Loss: 0.495, Validation Accuracy: 62.57%\n",
            "Epoch [8/10], Training Loss: 0.484, Validation Accuracy: 62.64%\n",
            "Epoch [9/10], Training Loss: 0.453, Validation Accuracy: 62.45%\n",
            "Epoch [10/10], Training Loss: 0.431, Validation Accuracy: 63.02%\n",
            "Epoch [1/10], Training Loss: 0.790, Validation Accuracy: 61.28%\n",
            "Epoch [2/10], Training Loss: 0.669, Validation Accuracy: 62.58%\n",
            "Epoch [3/10], Training Loss: 0.613, Validation Accuracy: 62.60%\n",
            "Epoch [4/10], Training Loss: 0.562, Validation Accuracy: 61.92%\n",
            "Epoch [5/10], Training Loss: 0.532, Validation Accuracy: 62.11%\n",
            "Epoch [6/10], Training Loss: 0.501, Validation Accuracy: 62.80%\n",
            "Epoch [7/10], Training Loss: 0.475, Validation Accuracy: 62.51%\n",
            "Epoch [8/10], Training Loss: 0.450, Validation Accuracy: 63.00%\n",
            "Epoch [9/10], Training Loss: 0.423, Validation Accuracy: 62.46%\n",
            "Epoch [10/10], Training Loss: 0.408, Validation Accuracy: 62.37%\n",
            "Test Accuracy: 61.53%\n",
            "CPU times: user 3h 38min 55s, sys: 1min 31s, total: 3h 40min 27s\n",
            "Wall time: 3h 59min 45s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=10)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZ3TCCJO3sB_",
        "outputId": "a93928fe-e94d-4f1f-d697-79d7b229fb59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Training Loss: 2.303, Validation Accuracy: 10.19%\n",
            "Epoch [2/10], Training Loss: 2.301, Validation Accuracy: 10.19%\n",
            "Epoch [3/10], Training Loss: 2.299, Validation Accuracy: 10.17%\n",
            "Epoch [4/10], Training Loss: 2.297, Validation Accuracy: 10.21%\n",
            "Epoch [5/10], Training Loss: 2.295, Validation Accuracy: 11.53%\n",
            "Epoch [6/10], Training Loss: 2.293, Validation Accuracy: 12.61%\n",
            "Epoch [7/10], Training Loss: 2.289, Validation Accuracy: 13.04%\n",
            "Epoch [8/10], Training Loss: 2.285, Validation Accuracy: 13.43%\n",
            "Epoch [9/10], Training Loss: 2.279, Validation Accuracy: 14.08%\n",
            "Epoch [10/10], Training Loss: 2.270, Validation Accuracy: 15.52%\n",
            "Epoch [1/10], Training Loss: 2.261, Validation Accuracy: 19.22%\n",
            "Epoch [2/10], Training Loss: 2.241, Validation Accuracy: 21.62%\n",
            "Epoch [3/10], Training Loss: 2.208, Validation Accuracy: 22.73%\n",
            "Epoch [4/10], Training Loss: 2.160, Validation Accuracy: 23.62%\n",
            "Epoch [5/10], Training Loss: 2.107, Validation Accuracy: 25.88%\n",
            "Epoch [6/10], Training Loss: 2.065, Validation Accuracy: 26.30%\n",
            "Epoch [7/10], Training Loss: 2.027, Validation Accuracy: 27.92%\n",
            "Epoch [8/10], Training Loss: 1.999, Validation Accuracy: 28.43%\n",
            "Epoch [9/10], Training Loss: 1.974, Validation Accuracy: 29.31%\n",
            "Epoch [10/10], Training Loss: 1.953, Validation Accuracy: 29.36%\n",
            "Epoch [1/10], Training Loss: 1.950, Validation Accuracy: 30.12%\n",
            "Epoch [2/10], Training Loss: 1.934, Validation Accuracy: 31.27%\n",
            "Epoch [3/10], Training Loss: 1.916, Validation Accuracy: 30.91%\n",
            "Epoch [4/10], Training Loss: 1.902, Validation Accuracy: 31.68%\n",
            "Epoch [5/10], Training Loss: 1.886, Validation Accuracy: 32.49%\n",
            "Epoch [6/10], Training Loss: 1.871, Validation Accuracy: 32.93%\n",
            "Epoch [7/10], Training Loss: 1.855, Validation Accuracy: 33.41%\n",
            "Epoch [8/10], Training Loss: 1.843, Validation Accuracy: 33.02%\n",
            "Epoch [9/10], Training Loss: 1.830, Validation Accuracy: 34.03%\n",
            "Epoch [10/10], Training Loss: 1.817, Validation Accuracy: 34.50%\n",
            "Epoch [1/10], Training Loss: 1.822, Validation Accuracy: 35.06%\n",
            "Epoch [2/10], Training Loss: 1.803, Validation Accuracy: 34.91%\n",
            "Epoch [3/10], Training Loss: 1.781, Validation Accuracy: 36.24%\n",
            "Epoch [4/10], Training Loss: 1.769, Validation Accuracy: 36.36%\n",
            "Epoch [5/10], Training Loss: 1.751, Validation Accuracy: 36.54%\n",
            "Epoch [6/10], Training Loss: 1.731, Validation Accuracy: 36.98%\n",
            "Epoch [7/10], Training Loss: 1.716, Validation Accuracy: 37.45%\n",
            "Epoch [8/10], Training Loss: 1.701, Validation Accuracy: 38.03%\n",
            "Epoch [9/10], Training Loss: 1.690, Validation Accuracy: 38.54%\n",
            "Epoch [10/10], Training Loss: 1.675, Validation Accuracy: 38.89%\n",
            "Epoch [1/10], Training Loss: 1.688, Validation Accuracy: 39.27%\n",
            "Epoch [2/10], Training Loss: 1.670, Validation Accuracy: 39.74%\n",
            "Epoch [3/10], Training Loss: 1.657, Validation Accuracy: 40.14%\n",
            "Epoch [4/10], Training Loss: 1.645, Validation Accuracy: 39.81%\n",
            "Epoch [5/10], Training Loss: 1.637, Validation Accuracy: 40.92%\n",
            "Epoch [6/10], Training Loss: 1.627, Validation Accuracy: 40.76%\n",
            "Epoch [7/10], Training Loss: 1.624, Validation Accuracy: 40.65%\n",
            "Epoch [8/10], Training Loss: 1.608, Validation Accuracy: 41.23%\n",
            "Epoch [9/10], Training Loss: 1.599, Validation Accuracy: 41.46%\n",
            "Epoch [10/10], Training Loss: 1.591, Validation Accuracy: 41.41%\n",
            "Test Accuracy: 41.53%\n",
            "CPU times: user 20min 30s, sys: 9.64 s, total: 20min 40s\n",
            "Wall time: 22min 41s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=1)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_biP0ccRWcU",
        "outputId": "4cbc5610-b5d5-40c3-e6d6-78667dfd81a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Random Images per Class: [5958 6008 5989 5987 5944 5912 6049 6086 5993 6074]\n",
            "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 9.51%\n",
            "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 9.51%\n",
            "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.51%\n",
            "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 9.59%\n",
            "Epoch [5/10], Training Loss: 2.302, Validation Accuracy: 10.49%\n",
            "Epoch [6/10], Training Loss: 2.301, Validation Accuracy: 12.03%\n",
            "Epoch [7/10], Training Loss: 2.300, Validation Accuracy: 12.99%\n",
            "Epoch [8/10], Training Loss: 2.299, Validation Accuracy: 13.97%\n",
            "Epoch [9/10], Training Loss: 2.297, Validation Accuracy: 14.28%\n",
            "Epoch [10/10], Training Loss: 2.296, Validation Accuracy: 14.70%\n",
            "Epoch [1/10], Training Loss: 2.295, Validation Accuracy: 15.30%\n",
            "Epoch [2/10], Training Loss: 2.293, Validation Accuracy: 16.12%\n",
            "Epoch [3/10], Training Loss: 2.289, Validation Accuracy: 16.74%\n",
            "Epoch [4/10], Training Loss: 2.285, Validation Accuracy: 17.27%\n",
            "Epoch [5/10], Training Loss: 2.279, Validation Accuracy: 17.83%\n",
            "Epoch [6/10], Training Loss: 2.269, Validation Accuracy: 18.36%\n",
            "Epoch [7/10], Training Loss: 2.254, Validation Accuracy: 18.53%\n",
            "Epoch [8/10], Training Loss: 2.232, Validation Accuracy: 18.87%\n",
            "Epoch [9/10], Training Loss: 2.202, Validation Accuracy: 20.00%\n",
            "Epoch [10/10], Training Loss: 2.166, Validation Accuracy: 21.70%\n",
            "Epoch [1/10], Training Loss: 2.146, Validation Accuracy: 24.32%\n",
            "Epoch [2/10], Training Loss: 2.113, Validation Accuracy: 24.86%\n",
            "Epoch [3/10], Training Loss: 2.086, Validation Accuracy: 25.75%\n",
            "Epoch [4/10], Training Loss: 2.063, Validation Accuracy: 26.95%\n",
            "Epoch [5/10], Training Loss: 2.042, Validation Accuracy: 27.61%\n",
            "Epoch [6/10], Training Loss: 2.020, Validation Accuracy: 28.10%\n",
            "Epoch [7/10], Training Loss: 1.999, Validation Accuracy: 29.06%\n",
            "Epoch [8/10], Training Loss: 1.979, Validation Accuracy: 29.38%\n",
            "Epoch [9/10], Training Loss: 1.962, Validation Accuracy: 30.35%\n",
            "Epoch [10/10], Training Loss: 1.944, Validation Accuracy: 30.09%\n",
            "Epoch [1/10], Training Loss: 1.925, Validation Accuracy: 31.08%\n",
            "Epoch [2/10], Training Loss: 1.909, Validation Accuracy: 31.84%\n",
            "Epoch [3/10], Training Loss: 1.894, Validation Accuracy: 32.26%\n",
            "Epoch [4/10], Training Loss: 1.880, Validation Accuracy: 31.86%\n",
            "Epoch [5/10], Training Loss: 1.862, Validation Accuracy: 32.98%\n",
            "Epoch [6/10], Training Loss: 1.851, Validation Accuracy: 33.22%\n",
            "Epoch [7/10], Training Loss: 1.831, Validation Accuracy: 34.09%\n",
            "Epoch [8/10], Training Loss: 1.814, Validation Accuracy: 34.77%\n",
            "Epoch [9/10], Training Loss: 1.797, Validation Accuracy: 35.25%\n",
            "Epoch [10/10], Training Loss: 1.780, Validation Accuracy: 35.55%\n",
            "Epoch [1/10], Training Loss: 1.784, Validation Accuracy: 36.51%\n",
            "Epoch [2/10], Training Loss: 1.762, Validation Accuracy: 37.46%\n",
            "Epoch [3/10], Training Loss: 1.745, Validation Accuracy: 37.44%\n",
            "Epoch [4/10], Training Loss: 1.732, Validation Accuracy: 37.59%\n",
            "Epoch [5/10], Training Loss: 1.717, Validation Accuracy: 38.39%\n",
            "Epoch [6/10], Training Loss: 1.702, Validation Accuracy: 38.59%\n",
            "Epoch [7/10], Training Loss: 1.690, Validation Accuracy: 38.62%\n",
            "Epoch [8/10], Training Loss: 1.676, Validation Accuracy: 39.00%\n",
            "Epoch [9/10], Training Loss: 1.664, Validation Accuracy: 40.08%\n",
            "Epoch [10/10], Training Loss: 1.655, Validation Accuracy: 39.90%\n",
            "Epoch [1/10], Training Loss: 1.659, Validation Accuracy: 40.48%\n",
            "Epoch [2/10], Training Loss: 1.643, Validation Accuracy: 40.51%\n",
            "Epoch [3/10], Training Loss: 1.633, Validation Accuracy: 40.48%\n",
            "Epoch [4/10], Training Loss: 1.626, Validation Accuracy: 40.91%\n",
            "Epoch [5/10], Training Loss: 1.611, Validation Accuracy: 41.18%\n",
            "Epoch [6/10], Training Loss: 1.604, Validation Accuracy: 41.38%\n",
            "Epoch [7/10], Training Loss: 1.597, Validation Accuracy: 41.45%\n",
            "Epoch [8/10], Training Loss: 1.581, Validation Accuracy: 42.17%\n",
            "Epoch [9/10], Training Loss: 1.571, Validation Accuracy: 42.23%\n",
            "Epoch [10/10], Training Loss: 1.558, Validation Accuracy: 42.01%\n",
            "Epoch [1/10], Training Loss: 1.582, Validation Accuracy: 43.41%\n",
            "Epoch [2/10], Training Loss: 1.572, Validation Accuracy: 42.65%\n",
            "Epoch [3/10], Training Loss: 1.557, Validation Accuracy: 42.76%\n",
            "Epoch [4/10], Training Loss: 1.561, Validation Accuracy: 43.47%\n",
            "Epoch [5/10], Training Loss: 1.536, Validation Accuracy: 43.94%\n",
            "Epoch [6/10], Training Loss: 1.527, Validation Accuracy: 43.97%\n",
            "Epoch [7/10], Training Loss: 1.522, Validation Accuracy: 44.44%\n",
            "Epoch [8/10], Training Loss: 1.517, Validation Accuracy: 44.25%\n",
            "Epoch [9/10], Training Loss: 1.504, Validation Accuracy: 43.81%\n",
            "Epoch [10/10], Training Loss: 1.495, Validation Accuracy: 44.55%\n",
            "Epoch [1/10], Training Loss: 1.534, Validation Accuracy: 44.97%\n",
            "Epoch [2/10], Training Loss: 1.522, Validation Accuracy: 45.03%\n",
            "Epoch [3/10], Training Loss: 1.507, Validation Accuracy: 45.36%\n",
            "Epoch [4/10], Training Loss: 1.499, Validation Accuracy: 45.93%\n",
            "Epoch [5/10], Training Loss: 1.488, Validation Accuracy: 45.76%\n",
            "Epoch [6/10], Training Loss: 1.478, Validation Accuracy: 45.61%\n",
            "Epoch [7/10], Training Loss: 1.472, Validation Accuracy: 46.72%\n",
            "Epoch [8/10], Training Loss: 1.465, Validation Accuracy: 46.76%\n",
            "Epoch [9/10], Training Loss: 1.452, Validation Accuracy: 46.02%\n",
            "Epoch [10/10], Training Loss: 1.443, Validation Accuracy: 46.23%\n",
            "Epoch [1/10], Training Loss: 1.467, Validation Accuracy: 46.79%\n",
            "Epoch [2/10], Training Loss: 1.452, Validation Accuracy: 47.67%\n",
            "Epoch [3/10], Training Loss: 1.446, Validation Accuracy: 47.21%\n",
            "Epoch [4/10], Training Loss: 1.431, Validation Accuracy: 47.32%\n",
            "Epoch [5/10], Training Loss: 1.420, Validation Accuracy: 47.66%\n",
            "Epoch [6/10], Training Loss: 1.411, Validation Accuracy: 48.43%\n",
            "Epoch [7/10], Training Loss: 1.401, Validation Accuracy: 48.33%\n",
            "Epoch [8/10], Training Loss: 1.392, Validation Accuracy: 48.17%\n",
            "Epoch [9/10], Training Loss: 1.389, Validation Accuracy: 48.20%\n",
            "Epoch [10/10], Training Loss: 1.378, Validation Accuracy: 47.38%\n",
            "Epoch [1/10], Training Loss: 1.406, Validation Accuracy: 48.92%\n",
            "Epoch [2/10], Training Loss: 1.386, Validation Accuracy: 49.72%\n",
            "Epoch [3/10], Training Loss: 1.386, Validation Accuracy: 49.88%\n",
            "Epoch [4/10], Training Loss: 1.372, Validation Accuracy: 50.11%\n",
            "Epoch [5/10], Training Loss: 1.357, Validation Accuracy: 49.05%\n",
            "Epoch [6/10], Training Loss: 1.348, Validation Accuracy: 49.04%\n",
            "Epoch [7/10], Training Loss: 1.343, Validation Accuracy: 49.55%\n",
            "Epoch [8/10], Training Loss: 1.326, Validation Accuracy: 50.44%\n",
            "Epoch [9/10], Training Loss: 1.320, Validation Accuracy: 50.79%\n",
            "Epoch [10/10], Training Loss: 1.312, Validation Accuracy: 50.36%\n",
            "Epoch [1/10], Training Loss: 1.365, Validation Accuracy: 50.95%\n",
            "Epoch [2/10], Training Loss: 1.350, Validation Accuracy: 51.36%\n",
            "Epoch [3/10], Training Loss: 1.331, Validation Accuracy: 50.44%\n",
            "Epoch [4/10], Training Loss: 1.322, Validation Accuracy: 51.21%\n",
            "Epoch [5/10], Training Loss: 1.311, Validation Accuracy: 50.53%\n",
            "Epoch [6/10], Training Loss: 1.305, Validation Accuracy: 51.40%\n",
            "Epoch [7/10], Training Loss: 1.295, Validation Accuracy: 51.92%\n",
            "Epoch [8/10], Training Loss: 1.287, Validation Accuracy: 50.25%\n",
            "Epoch [9/10], Training Loss: 1.286, Validation Accuracy: 51.02%\n",
            "Epoch [10/10], Training Loss: 1.274, Validation Accuracy: 51.68%\n",
            "Epoch [1/10], Training Loss: 1.343, Validation Accuracy: 52.63%\n",
            "Epoch [2/10], Training Loss: 1.322, Validation Accuracy: 52.26%\n",
            "Epoch [3/10], Training Loss: 1.313, Validation Accuracy: 52.45%\n",
            "Epoch [4/10], Training Loss: 1.302, Validation Accuracy: 52.38%\n",
            "Epoch [5/10], Training Loss: 1.298, Validation Accuracy: 52.19%\n",
            "Epoch [6/10], Training Loss: 1.283, Validation Accuracy: 53.00%\n",
            "Epoch [7/10], Training Loss: 1.271, Validation Accuracy: 51.67%\n",
            "Epoch [8/10], Training Loss: 1.261, Validation Accuracy: 52.86%\n",
            "Epoch [9/10], Training Loss: 1.253, Validation Accuracy: 53.14%\n",
            "Epoch [10/10], Training Loss: 1.237, Validation Accuracy: 52.92%\n",
            "Epoch [1/10], Training Loss: 1.311, Validation Accuracy: 53.14%\n",
            "Epoch [2/10], Training Loss: 1.306, Validation Accuracy: 53.21%\n",
            "Epoch [3/10], Training Loss: 1.278, Validation Accuracy: 52.94%\n",
            "Epoch [4/10], Training Loss: 1.274, Validation Accuracy: 53.15%\n",
            "Epoch [5/10], Training Loss: 1.268, Validation Accuracy: 53.72%\n",
            "Epoch [6/10], Training Loss: 1.250, Validation Accuracy: 53.89%\n",
            "Epoch [7/10], Training Loss: 1.245, Validation Accuracy: 53.52%\n",
            "Epoch [8/10], Training Loss: 1.240, Validation Accuracy: 53.97%\n",
            "Epoch [9/10], Training Loss: 1.224, Validation Accuracy: 54.15%\n",
            "Epoch [10/10], Training Loss: 1.220, Validation Accuracy: 54.06%\n",
            "Epoch [1/10], Training Loss: 1.282, Validation Accuracy: 54.34%\n",
            "Epoch [2/10], Training Loss: 1.259, Validation Accuracy: 54.74%\n",
            "Epoch [3/10], Training Loss: 1.245, Validation Accuracy: 53.76%\n",
            "Epoch [4/10], Training Loss: 1.237, Validation Accuracy: 54.03%\n",
            "Epoch [5/10], Training Loss: 1.226, Validation Accuracy: 53.63%\n",
            "Epoch [6/10], Training Loss: 1.216, Validation Accuracy: 54.41%\n",
            "Epoch [7/10], Training Loss: 1.210, Validation Accuracy: 54.29%\n",
            "Epoch [8/10], Training Loss: 1.205, Validation Accuracy: 54.23%\n",
            "Epoch [9/10], Training Loss: 1.196, Validation Accuracy: 54.45%\n",
            "Epoch [10/10], Training Loss: 1.185, Validation Accuracy: 53.70%\n",
            "Epoch [1/10], Training Loss: 1.233, Validation Accuracy: 54.79%\n",
            "Epoch [2/10], Training Loss: 1.213, Validation Accuracy: 55.20%\n",
            "Epoch [3/10], Training Loss: 1.197, Validation Accuracy: 53.42%\n",
            "Epoch [4/10], Training Loss: 1.197, Validation Accuracy: 55.64%\n",
            "Epoch [5/10], Training Loss: 1.179, Validation Accuracy: 55.25%\n",
            "Epoch [6/10], Training Loss: 1.166, Validation Accuracy: 55.39%\n",
            "Epoch [7/10], Training Loss: 1.164, Validation Accuracy: 54.19%\n",
            "Epoch [8/10], Training Loss: 1.159, Validation Accuracy: 55.59%\n",
            "Epoch [9/10], Training Loss: 1.132, Validation Accuracy: 55.81%\n",
            "Epoch [10/10], Training Loss: 1.127, Validation Accuracy: 55.44%\n",
            "Epoch [1/10], Training Loss: 1.212, Validation Accuracy: 55.85%\n",
            "Epoch [2/10], Training Loss: 1.190, Validation Accuracy: 55.67%\n",
            "Epoch [3/10], Training Loss: 1.174, Validation Accuracy: 56.20%\n",
            "Epoch [4/10], Training Loss: 1.159, Validation Accuracy: 55.16%\n",
            "Epoch [5/10], Training Loss: 1.145, Validation Accuracy: 55.85%\n",
            "Epoch [6/10], Training Loss: 1.143, Validation Accuracy: 55.87%\n",
            "Epoch [7/10], Training Loss: 1.133, Validation Accuracy: 55.71%\n",
            "Epoch [8/10], Training Loss: 1.127, Validation Accuracy: 56.39%\n",
            "Epoch [9/10], Training Loss: 1.114, Validation Accuracy: 56.30%\n",
            "Epoch [10/10], Training Loss: 1.104, Validation Accuracy: 56.14%\n",
            "Epoch [1/10], Training Loss: 1.209, Validation Accuracy: 56.19%\n",
            "Epoch [2/10], Training Loss: 1.199, Validation Accuracy: 56.12%\n",
            "Epoch [3/10], Training Loss: 1.172, Validation Accuracy: 56.08%\n",
            "Epoch [4/10], Training Loss: 1.158, Validation Accuracy: 57.09%\n",
            "Epoch [5/10], Training Loss: 1.145, Validation Accuracy: 56.68%\n",
            "Epoch [6/10], Training Loss: 1.134, Validation Accuracy: 56.55%\n",
            "Epoch [7/10], Training Loss: 1.133, Validation Accuracy: 56.93%\n",
            "Epoch [8/10], Training Loss: 1.126, Validation Accuracy: 57.59%\n",
            "Epoch [9/10], Training Loss: 1.104, Validation Accuracy: 57.07%\n",
            "Epoch [10/10], Training Loss: 1.112, Validation Accuracy: 57.31%\n",
            "Epoch [1/10], Training Loss: 1.186, Validation Accuracy: 57.57%\n",
            "Epoch [2/10], Training Loss: 1.161, Validation Accuracy: 56.54%\n",
            "Epoch [3/10], Training Loss: 1.153, Validation Accuracy: 57.64%\n",
            "Epoch [4/10], Training Loss: 1.137, Validation Accuracy: 57.42%\n",
            "Epoch [5/10], Training Loss: 1.120, Validation Accuracy: 57.53%\n",
            "Epoch [6/10], Training Loss: 1.115, Validation Accuracy: 57.47%\n",
            "Epoch [7/10], Training Loss: 1.106, Validation Accuracy: 57.46%\n",
            "Epoch [8/10], Training Loss: 1.091, Validation Accuracy: 57.69%\n",
            "Epoch [9/10], Training Loss: 1.089, Validation Accuracy: 57.81%\n",
            "Epoch [10/10], Training Loss: 1.082, Validation Accuracy: 57.64%\n",
            "Epoch [1/10], Training Loss: 1.172, Validation Accuracy: 58.00%\n",
            "Epoch [2/10], Training Loss: 1.141, Validation Accuracy: 57.27%\n",
            "Epoch [3/10], Training Loss: 1.138, Validation Accuracy: 57.83%\n",
            "Epoch [4/10], Training Loss: 1.114, Validation Accuracy: 58.23%\n",
            "Epoch [5/10], Training Loss: 1.106, Validation Accuracy: 57.27%\n",
            "Epoch [6/10], Training Loss: 1.088, Validation Accuracy: 58.18%\n",
            "Epoch [7/10], Training Loss: 1.078, Validation Accuracy: 57.80%\n",
            "Epoch [8/10], Training Loss: 1.067, Validation Accuracy: 57.71%\n",
            "Epoch [9/10], Training Loss: 1.060, Validation Accuracy: 57.90%\n",
            "Epoch [10/10], Training Loss: 1.053, Validation Accuracy: 58.06%\n",
            "Epoch [1/10], Training Loss: 1.125, Validation Accuracy: 57.94%\n",
            "Epoch [2/10], Training Loss: 1.099, Validation Accuracy: 58.49%\n",
            "Epoch [3/10], Training Loss: 1.083, Validation Accuracy: 58.68%\n",
            "Epoch [4/10], Training Loss: 1.064, Validation Accuracy: 58.72%\n",
            "Epoch [5/10], Training Loss: 1.052, Validation Accuracy: 59.11%\n",
            "Epoch [6/10], Training Loss: 1.042, Validation Accuracy: 57.30%\n",
            "Epoch [7/10], Training Loss: 1.029, Validation Accuracy: 58.04%\n",
            "Epoch [8/10], Training Loss: 1.015, Validation Accuracy: 58.87%\n",
            "Epoch [9/10], Training Loss: 1.008, Validation Accuracy: 58.25%\n",
            "Epoch [10/10], Training Loss: 1.002, Validation Accuracy: 57.94%\n",
            "Epoch [1/10], Training Loss: 1.113, Validation Accuracy: 58.78%\n",
            "Epoch [2/10], Training Loss: 1.080, Validation Accuracy: 58.71%\n",
            "Epoch [3/10], Training Loss: 1.065, Validation Accuracy: 59.09%\n",
            "Epoch [4/10], Training Loss: 1.042, Validation Accuracy: 59.39%\n",
            "Epoch [5/10], Training Loss: 1.024, Validation Accuracy: 58.93%\n",
            "Epoch [6/10], Training Loss: 1.016, Validation Accuracy: 58.19%\n",
            "Epoch [7/10], Training Loss: 1.010, Validation Accuracy: 58.83%\n",
            "Epoch [8/10], Training Loss: 0.997, Validation Accuracy: 59.66%\n",
            "Epoch [9/10], Training Loss: 0.986, Validation Accuracy: 58.70%\n",
            "Epoch [10/10], Training Loss: 0.972, Validation Accuracy: 58.19%\n",
            "Epoch [1/10], Training Loss: 1.126, Validation Accuracy: 59.31%\n",
            "Epoch [2/10], Training Loss: 1.088, Validation Accuracy: 59.96%\n",
            "Epoch [3/10], Training Loss: 1.069, Validation Accuracy: 59.70%\n",
            "Epoch [4/10], Training Loss: 1.056, Validation Accuracy: 59.86%\n",
            "Epoch [5/10], Training Loss: 1.044, Validation Accuracy: 59.55%\n",
            "Epoch [6/10], Training Loss: 1.038, Validation Accuracy: 58.08%\n",
            "Epoch [7/10], Training Loss: 1.027, Validation Accuracy: 59.93%\n",
            "Epoch [8/10], Training Loss: 1.002, Validation Accuracy: 59.44%\n",
            "Epoch [9/10], Training Loss: 0.990, Validation Accuracy: 58.90%\n",
            "Epoch [10/10], Training Loss: 0.984, Validation Accuracy: 58.13%\n",
            "Epoch [1/10], Training Loss: 1.102, Validation Accuracy: 58.76%\n",
            "Epoch [2/10], Training Loss: 1.076, Validation Accuracy: 59.55%\n",
            "Epoch [3/10], Training Loss: 1.043, Validation Accuracy: 59.86%\n",
            "Epoch [4/10], Training Loss: 1.031, Validation Accuracy: 59.30%\n",
            "Epoch [5/10], Training Loss: 1.022, Validation Accuracy: 59.75%\n",
            "Epoch [6/10], Training Loss: 1.007, Validation Accuracy: 58.49%\n",
            "Epoch [7/10], Training Loss: 0.991, Validation Accuracy: 58.59%\n",
            "Epoch [8/10], Training Loss: 0.988, Validation Accuracy: 59.44%\n",
            "Epoch [9/10], Training Loss: 0.965, Validation Accuracy: 59.98%\n",
            "Epoch [10/10], Training Loss: 0.947, Validation Accuracy: 59.53%\n",
            "Epoch [1/10], Training Loss: 1.089, Validation Accuracy: 59.27%\n",
            "Epoch [2/10], Training Loss: 1.055, Validation Accuracy: 59.94%\n",
            "Epoch [3/10], Training Loss: 1.031, Validation Accuracy: 59.95%\n",
            "Epoch [4/10], Training Loss: 1.006, Validation Accuracy: 59.91%\n",
            "Epoch [5/10], Training Loss: 0.994, Validation Accuracy: 59.20%\n",
            "Epoch [6/10], Training Loss: 0.985, Validation Accuracy: 59.75%\n",
            "Epoch [7/10], Training Loss: 0.974, Validation Accuracy: 60.03%\n",
            "Epoch [8/10], Training Loss: 0.955, Validation Accuracy: 59.35%\n",
            "Epoch [9/10], Training Loss: 0.942, Validation Accuracy: 59.77%\n",
            "Epoch [10/10], Training Loss: 0.938, Validation Accuracy: 59.13%\n",
            "Epoch [1/10], Training Loss: 1.044, Validation Accuracy: 59.17%\n",
            "Epoch [2/10], Training Loss: 1.013, Validation Accuracy: 60.25%\n",
            "Epoch [3/10], Training Loss: 0.992, Validation Accuracy: 60.72%\n",
            "Epoch [4/10], Training Loss: 0.975, Validation Accuracy: 60.27%\n",
            "Epoch [5/10], Training Loss: 0.954, Validation Accuracy: 60.47%\n",
            "Epoch [6/10], Training Loss: 0.939, Validation Accuracy: 60.17%\n",
            "Epoch [7/10], Training Loss: 0.921, Validation Accuracy: 60.02%\n",
            "Epoch [8/10], Training Loss: 0.906, Validation Accuracy: 60.16%\n",
            "Epoch [9/10], Training Loss: 0.897, Validation Accuracy: 60.23%\n",
            "Epoch [10/10], Training Loss: 0.877, Validation Accuracy: 60.38%\n",
            "Epoch [1/10], Training Loss: 1.043, Validation Accuracy: 60.15%\n",
            "Epoch [2/10], Training Loss: 0.995, Validation Accuracy: 60.43%\n",
            "Epoch [3/10], Training Loss: 0.973, Validation Accuracy: 60.09%\n",
            "Epoch [4/10], Training Loss: 0.951, Validation Accuracy: 60.76%\n",
            "Epoch [5/10], Training Loss: 0.928, Validation Accuracy: 60.58%\n",
            "Epoch [6/10], Training Loss: 0.912, Validation Accuracy: 61.15%\n",
            "Epoch [7/10], Training Loss: 0.901, Validation Accuracy: 60.06%\n",
            "Epoch [8/10], Training Loss: 0.882, Validation Accuracy: 59.91%\n",
            "Epoch [9/10], Training Loss: 0.880, Validation Accuracy: 60.56%\n",
            "Epoch [10/10], Training Loss: 0.871, Validation Accuracy: 60.47%\n",
            "Epoch [1/10], Training Loss: 1.063, Validation Accuracy: 60.27%\n",
            "Epoch [2/10], Training Loss: 1.009, Validation Accuracy: 60.52%\n",
            "Epoch [3/10], Training Loss: 0.994, Validation Accuracy: 60.74%\n",
            "Epoch [4/10], Training Loss: 0.968, Validation Accuracy: 60.82%\n",
            "Epoch [5/10], Training Loss: 0.955, Validation Accuracy: 60.65%\n",
            "Epoch [6/10], Training Loss: 0.932, Validation Accuracy: 60.35%\n",
            "Epoch [7/10], Training Loss: 0.917, Validation Accuracy: 60.81%\n",
            "Epoch [8/10], Training Loss: 0.906, Validation Accuracy: 60.67%\n",
            "Epoch [9/10], Training Loss: 0.891, Validation Accuracy: 60.01%\n",
            "Epoch [10/10], Training Loss: 0.890, Validation Accuracy: 59.58%\n",
            "Epoch [1/10], Training Loss: 1.031, Validation Accuracy: 60.43%\n",
            "Epoch [2/10], Training Loss: 0.979, Validation Accuracy: 60.98%\n",
            "Epoch [3/10], Training Loss: 0.964, Validation Accuracy: 59.61%\n",
            "Epoch [4/10], Training Loss: 0.942, Validation Accuracy: 59.95%\n",
            "Epoch [5/10], Training Loss: 0.925, Validation Accuracy: 60.39%\n",
            "Epoch [6/10], Training Loss: 0.913, Validation Accuracy: 60.94%\n",
            "Epoch [7/10], Training Loss: 0.883, Validation Accuracy: 60.88%\n",
            "Epoch [8/10], Training Loss: 0.871, Validation Accuracy: 60.17%\n",
            "Epoch [9/10], Training Loss: 0.874, Validation Accuracy: 60.59%\n",
            "Epoch [10/10], Training Loss: 0.844, Validation Accuracy: 60.53%\n",
            "Epoch [1/10], Training Loss: 1.018, Validation Accuracy: 60.44%\n",
            "Epoch [2/10], Training Loss: 0.971, Validation Accuracy: 61.09%\n",
            "Epoch [3/10], Training Loss: 0.943, Validation Accuracy: 61.32%\n",
            "Epoch [4/10], Training Loss: 0.923, Validation Accuracy: 61.12%\n",
            "Epoch [5/10], Training Loss: 0.902, Validation Accuracy: 61.09%\n",
            "Epoch [6/10], Training Loss: 0.885, Validation Accuracy: 60.90%\n",
            "Epoch [7/10], Training Loss: 0.864, Validation Accuracy: 60.75%\n",
            "Epoch [8/10], Training Loss: 0.851, Validation Accuracy: 60.42%\n",
            "Epoch [9/10], Training Loss: 0.840, Validation Accuracy: 60.77%\n",
            "Epoch [10/10], Training Loss: 0.827, Validation Accuracy: 60.23%\n",
            "Epoch [1/10], Training Loss: 0.982, Validation Accuracy: 61.12%\n",
            "Epoch [2/10], Training Loss: 0.933, Validation Accuracy: 61.41%\n",
            "Epoch [3/10], Training Loss: 0.906, Validation Accuracy: 60.90%\n",
            "Epoch [4/10], Training Loss: 0.890, Validation Accuracy: 61.49%\n",
            "Epoch [5/10], Training Loss: 0.859, Validation Accuracy: 61.04%\n",
            "Epoch [6/10], Training Loss: 0.842, Validation Accuracy: 60.82%\n",
            "Epoch [7/10], Training Loss: 0.820, Validation Accuracy: 61.16%\n",
            "Epoch [8/10], Training Loss: 0.813, Validation Accuracy: 61.23%\n",
            "Epoch [9/10], Training Loss: 0.806, Validation Accuracy: 60.69%\n",
            "Epoch [10/10], Training Loss: 0.782, Validation Accuracy: 61.05%\n",
            "Epoch [1/10], Training Loss: 0.975, Validation Accuracy: 61.19%\n",
            "Epoch [2/10], Training Loss: 0.921, Validation Accuracy: 61.06%\n",
            "Epoch [3/10], Training Loss: 0.895, Validation Accuracy: 60.55%\n",
            "Epoch [4/10], Training Loss: 0.871, Validation Accuracy: 61.68%\n",
            "Epoch [5/10], Training Loss: 0.844, Validation Accuracy: 61.40%\n",
            "Epoch [6/10], Training Loss: 0.829, Validation Accuracy: 61.48%\n",
            "Epoch [7/10], Training Loss: 0.811, Validation Accuracy: 60.88%\n",
            "Epoch [8/10], Training Loss: 0.792, Validation Accuracy: 61.33%\n",
            "Epoch [9/10], Training Loss: 0.769, Validation Accuracy: 61.63%\n",
            "Epoch [10/10], Training Loss: 0.764, Validation Accuracy: 60.62%\n",
            "Epoch [1/10], Training Loss: 0.996, Validation Accuracy: 60.33%\n",
            "Epoch [2/10], Training Loss: 0.946, Validation Accuracy: 60.96%\n",
            "Epoch [3/10], Training Loss: 0.911, Validation Accuracy: 61.92%\n",
            "Epoch [4/10], Training Loss: 0.891, Validation Accuracy: 61.31%\n",
            "Epoch [5/10], Training Loss: 0.861, Validation Accuracy: 61.47%\n",
            "Epoch [6/10], Training Loss: 0.836, Validation Accuracy: 61.12%\n",
            "Epoch [7/10], Training Loss: 0.820, Validation Accuracy: 61.45%\n",
            "Epoch [8/10], Training Loss: 0.810, Validation Accuracy: 61.63%\n",
            "Epoch [9/10], Training Loss: 0.791, Validation Accuracy: 61.24%\n",
            "Epoch [10/10], Training Loss: 0.773, Validation Accuracy: 61.58%\n",
            "Epoch [1/10], Training Loss: 0.965, Validation Accuracy: 61.55%\n",
            "Epoch [2/10], Training Loss: 0.909, Validation Accuracy: 61.32%\n",
            "Epoch [3/10], Training Loss: 0.886, Validation Accuracy: 61.03%\n",
            "Epoch [4/10], Training Loss: 0.863, Validation Accuracy: 61.52%\n",
            "Epoch [5/10], Training Loss: 0.825, Validation Accuracy: 61.33%\n",
            "Epoch [6/10], Training Loss: 0.814, Validation Accuracy: 61.06%\n",
            "Epoch [7/10], Training Loss: 0.790, Validation Accuracy: 61.23%\n",
            "Epoch [8/10], Training Loss: 0.780, Validation Accuracy: 61.36%\n",
            "Epoch [9/10], Training Loss: 0.764, Validation Accuracy: 61.24%\n",
            "Epoch [10/10], Training Loss: 0.747, Validation Accuracy: 61.43%\n",
            "Epoch [1/10], Training Loss: 0.970, Validation Accuracy: 61.38%\n",
            "Epoch [2/10], Training Loss: 0.902, Validation Accuracy: 62.31%\n",
            "Epoch [3/10], Training Loss: 0.870, Validation Accuracy: 61.77%\n",
            "Epoch [4/10], Training Loss: 0.839, Validation Accuracy: 62.31%\n",
            "Epoch [5/10], Training Loss: 0.811, Validation Accuracy: 61.80%\n",
            "Epoch [6/10], Training Loss: 0.797, Validation Accuracy: 62.17%\n",
            "Epoch [7/10], Training Loss: 0.784, Validation Accuracy: 61.07%\n",
            "Epoch [8/10], Training Loss: 0.764, Validation Accuracy: 61.49%\n",
            "Epoch [9/10], Training Loss: 0.742, Validation Accuracy: 61.15%\n",
            "Epoch [10/10], Training Loss: 0.736, Validation Accuracy: 60.82%\n",
            "Epoch [1/10], Training Loss: 0.936, Validation Accuracy: 60.93%\n",
            "Epoch [2/10], Training Loss: 0.878, Validation Accuracy: 62.41%\n",
            "Epoch [3/10], Training Loss: 0.833, Validation Accuracy: 62.69%\n",
            "Epoch [4/10], Training Loss: 0.800, Validation Accuracy: 62.02%\n",
            "Epoch [5/10], Training Loss: 0.778, Validation Accuracy: 62.16%\n",
            "Epoch [6/10], Training Loss: 0.752, Validation Accuracy: 61.87%\n",
            "Epoch [7/10], Training Loss: 0.742, Validation Accuracy: 61.71%\n",
            "Epoch [8/10], Training Loss: 0.722, Validation Accuracy: 61.93%\n",
            "Epoch [9/10], Training Loss: 0.705, Validation Accuracy: 61.30%\n",
            "Epoch [10/10], Training Loss: 0.691, Validation Accuracy: 60.98%\n",
            "Epoch [1/10], Training Loss: 0.926, Validation Accuracy: 61.44%\n",
            "Epoch [2/10], Training Loss: 0.846, Validation Accuracy: 62.36%\n",
            "Epoch [3/10], Training Loss: 0.811, Validation Accuracy: 62.33%\n",
            "Epoch [4/10], Training Loss: 0.779, Validation Accuracy: 62.16%\n",
            "Epoch [5/10], Training Loss: 0.762, Validation Accuracy: 61.08%\n",
            "Epoch [6/10], Training Loss: 0.743, Validation Accuracy: 61.83%\n",
            "Epoch [7/10], Training Loss: 0.723, Validation Accuracy: 61.51%\n",
            "Epoch [8/10], Training Loss: 0.696, Validation Accuracy: 62.06%\n",
            "Epoch [9/10], Training Loss: 0.678, Validation Accuracy: 61.90%\n",
            "Epoch [10/10], Training Loss: 0.663, Validation Accuracy: 61.97%\n",
            "Epoch [1/10], Training Loss: 0.945, Validation Accuracy: 61.54%\n",
            "Epoch [2/10], Training Loss: 0.881, Validation Accuracy: 61.39%\n",
            "Epoch [3/10], Training Loss: 0.837, Validation Accuracy: 61.90%\n",
            "Epoch [4/10], Training Loss: 0.805, Validation Accuracy: 61.33%\n",
            "Epoch [5/10], Training Loss: 0.777, Validation Accuracy: 62.31%\n",
            "Epoch [6/10], Training Loss: 0.757, Validation Accuracy: 61.55%\n",
            "Epoch [7/10], Training Loss: 0.735, Validation Accuracy: 61.63%\n",
            "Epoch [8/10], Training Loss: 0.712, Validation Accuracy: 62.24%\n",
            "Epoch [9/10], Training Loss: 0.697, Validation Accuracy: 61.41%\n",
            "Epoch [10/10], Training Loss: 0.686, Validation Accuracy: 61.84%\n",
            "Epoch [1/10], Training Loss: 0.922, Validation Accuracy: 61.28%\n",
            "Epoch [2/10], Training Loss: 0.848, Validation Accuracy: 61.48%\n",
            "Epoch [3/10], Training Loss: 0.825, Validation Accuracy: 62.27%\n",
            "Epoch [4/10], Training Loss: 0.784, Validation Accuracy: 62.17%\n",
            "Epoch [5/10], Training Loss: 0.761, Validation Accuracy: 62.25%\n",
            "Epoch [6/10], Training Loss: 0.737, Validation Accuracy: 60.61%\n",
            "Epoch [7/10], Training Loss: 0.720, Validation Accuracy: 61.69%\n",
            "Epoch [8/10], Training Loss: 0.692, Validation Accuracy: 61.58%\n",
            "Epoch [9/10], Training Loss: 0.668, Validation Accuracy: 61.83%\n",
            "Epoch [10/10], Training Loss: 0.665, Validation Accuracy: 61.25%\n",
            "Epoch [1/10], Training Loss: 0.922, Validation Accuracy: 61.70%\n",
            "Epoch [2/10], Training Loss: 0.837, Validation Accuracy: 61.85%\n",
            "Epoch [3/10], Training Loss: 0.794, Validation Accuracy: 62.84%\n",
            "Epoch [4/10], Training Loss: 0.773, Validation Accuracy: 61.87%\n",
            "Epoch [5/10], Training Loss: 0.739, Validation Accuracy: 62.10%\n",
            "Epoch [6/10], Training Loss: 0.710, Validation Accuracy: 61.41%\n",
            "Epoch [7/10], Training Loss: 0.688, Validation Accuracy: 62.39%\n",
            "Epoch [8/10], Training Loss: 0.665, Validation Accuracy: 62.18%\n",
            "Epoch [9/10], Training Loss: 0.658, Validation Accuracy: 62.61%\n",
            "Epoch [10/10], Training Loss: 0.638, Validation Accuracy: 62.01%\n",
            "Epoch [1/10], Training Loss: 0.897, Validation Accuracy: 63.00%\n",
            "Epoch [2/10], Training Loss: 0.809, Validation Accuracy: 61.70%\n",
            "Epoch [3/10], Training Loss: 0.759, Validation Accuracy: 61.86%\n",
            "Epoch [4/10], Training Loss: 0.734, Validation Accuracy: 60.95%\n",
            "Epoch [5/10], Training Loss: 0.698, Validation Accuracy: 62.54%\n",
            "Epoch [6/10], Training Loss: 0.679, Validation Accuracy: 62.85%\n",
            "Epoch [7/10], Training Loss: 0.657, Validation Accuracy: 60.45%\n",
            "Epoch [8/10], Training Loss: 0.641, Validation Accuracy: 62.05%\n",
            "Epoch [9/10], Training Loss: 0.623, Validation Accuracy: 62.10%\n",
            "Epoch [10/10], Training Loss: 0.594, Validation Accuracy: 62.47%\n",
            "Epoch [1/10], Training Loss: 0.872, Validation Accuracy: 62.12%\n",
            "Epoch [2/10], Training Loss: 0.789, Validation Accuracy: 62.54%\n",
            "Epoch [3/10], Training Loss: 0.739, Validation Accuracy: 62.21%\n",
            "Epoch [4/10], Training Loss: 0.707, Validation Accuracy: 62.45%\n",
            "Epoch [5/10], Training Loss: 0.680, Validation Accuracy: 62.25%\n",
            "Epoch [6/10], Training Loss: 0.652, Validation Accuracy: 61.38%\n",
            "Epoch [7/10], Training Loss: 0.637, Validation Accuracy: 61.20%\n",
            "Epoch [8/10], Training Loss: 0.620, Validation Accuracy: 61.50%\n",
            "Epoch [9/10], Training Loss: 0.599, Validation Accuracy: 61.68%\n",
            "Epoch [10/10], Training Loss: 0.570, Validation Accuracy: 61.89%\n",
            "Epoch [1/10], Training Loss: 0.905, Validation Accuracy: 61.09%\n",
            "Epoch [2/10], Training Loss: 0.820, Validation Accuracy: 61.28%\n",
            "Epoch [3/10], Training Loss: 0.769, Validation Accuracy: 61.61%\n",
            "Epoch [4/10], Training Loss: 0.728, Validation Accuracy: 61.71%\n",
            "Epoch [5/10], Training Loss: 0.704, Validation Accuracy: 61.90%\n",
            "Epoch [6/10], Training Loss: 0.673, Validation Accuracy: 62.01%\n",
            "Epoch [7/10], Training Loss: 0.659, Validation Accuracy: 61.79%\n",
            "Epoch [8/10], Training Loss: 0.632, Validation Accuracy: 61.28%\n",
            "Epoch [9/10], Training Loss: 0.610, Validation Accuracy: 61.72%\n",
            "Epoch [10/10], Training Loss: 0.596, Validation Accuracy: 61.65%\n",
            "Epoch [1/10], Training Loss: 0.881, Validation Accuracy: 61.78%\n",
            "Epoch [2/10], Training Loss: 0.790, Validation Accuracy: 62.74%\n",
            "Epoch [3/10], Training Loss: 0.751, Validation Accuracy: 61.89%\n",
            "Epoch [4/10], Training Loss: 0.709, Validation Accuracy: 62.36%\n",
            "Epoch [5/10], Training Loss: 0.679, Validation Accuracy: 62.76%\n",
            "Epoch [6/10], Training Loss: 0.663, Validation Accuracy: 62.06%\n",
            "Epoch [7/10], Training Loss: 0.634, Validation Accuracy: 61.53%\n",
            "Epoch [8/10], Training Loss: 0.617, Validation Accuracy: 61.60%\n",
            "Epoch [9/10], Training Loss: 0.595, Validation Accuracy: 61.70%\n",
            "Epoch [10/10], Training Loss: 0.574, Validation Accuracy: 62.06%\n",
            "Epoch [1/10], Training Loss: 0.880, Validation Accuracy: 62.42%\n",
            "Epoch [2/10], Training Loss: 0.784, Validation Accuracy: 62.73%\n",
            "Epoch [3/10], Training Loss: 0.722, Validation Accuracy: 62.09%\n",
            "Epoch [4/10], Training Loss: 0.688, Validation Accuracy: 62.86%\n",
            "Epoch [5/10], Training Loss: 0.670, Validation Accuracy: 62.42%\n",
            "Epoch [6/10], Training Loss: 0.626, Validation Accuracy: 62.40%\n",
            "Epoch [7/10], Training Loss: 0.607, Validation Accuracy: 62.65%\n",
            "Epoch [8/10], Training Loss: 0.604, Validation Accuracy: 61.53%\n",
            "Epoch [9/10], Training Loss: 0.572, Validation Accuracy: 62.48%\n",
            "Epoch [10/10], Training Loss: 0.549, Validation Accuracy: 61.88%\n",
            "Epoch [1/10], Training Loss: 0.843, Validation Accuracy: 62.33%\n",
            "Epoch [2/10], Training Loss: 0.743, Validation Accuracy: 62.76%\n",
            "Epoch [3/10], Training Loss: 0.697, Validation Accuracy: 62.69%\n",
            "Epoch [4/10], Training Loss: 0.659, Validation Accuracy: 61.87%\n",
            "Epoch [5/10], Training Loss: 0.623, Validation Accuracy: 62.07%\n",
            "Epoch [6/10], Training Loss: 0.596, Validation Accuracy: 62.07%\n",
            "Epoch [7/10], Training Loss: 0.580, Validation Accuracy: 62.87%\n",
            "Epoch [8/10], Training Loss: 0.548, Validation Accuracy: 62.49%\n",
            "Epoch [9/10], Training Loss: 0.536, Validation Accuracy: 61.93%\n",
            "Epoch [10/10], Training Loss: 0.512, Validation Accuracy: 62.40%\n",
            "Epoch [1/10], Training Loss: 0.832, Validation Accuracy: 62.07%\n",
            "Epoch [2/10], Training Loss: 0.720, Validation Accuracy: 62.74%\n",
            "Epoch [3/10], Training Loss: 0.674, Validation Accuracy: 61.73%\n",
            "Epoch [4/10], Training Loss: 0.636, Validation Accuracy: 62.13%\n",
            "Epoch [5/10], Training Loss: 0.605, Validation Accuracy: 61.86%\n",
            "Epoch [6/10], Training Loss: 0.575, Validation Accuracy: 62.42%\n",
            "Epoch [7/10], Training Loss: 0.544, Validation Accuracy: 62.64%\n",
            "Epoch [8/10], Training Loss: 0.525, Validation Accuracy: 61.65%\n",
            "Epoch [9/10], Training Loss: 0.508, Validation Accuracy: 61.19%\n",
            "Epoch [10/10], Training Loss: 0.498, Validation Accuracy: 61.96%\n",
            "Epoch [1/10], Training Loss: 0.865, Validation Accuracy: 61.54%\n",
            "Epoch [2/10], Training Loss: 0.758, Validation Accuracy: 62.08%\n",
            "Epoch [3/10], Training Loss: 0.692, Validation Accuracy: 61.79%\n",
            "Epoch [4/10], Training Loss: 0.657, Validation Accuracy: 61.18%\n",
            "Epoch [5/10], Training Loss: 0.628, Validation Accuracy: 61.69%\n",
            "Epoch [6/10], Training Loss: 0.593, Validation Accuracy: 61.98%\n",
            "Epoch [7/10], Training Loss: 0.568, Validation Accuracy: 60.76%\n",
            "Epoch [8/10], Training Loss: 0.550, Validation Accuracy: 62.00%\n",
            "Epoch [9/10], Training Loss: 0.526, Validation Accuracy: 60.35%\n",
            "Epoch [10/10], Training Loss: 0.508, Validation Accuracy: 60.83%\n",
            "Epoch [1/10], Training Loss: 0.841, Validation Accuracy: 61.18%\n",
            "Epoch [2/10], Training Loss: 0.731, Validation Accuracy: 61.77%\n",
            "Epoch [3/10], Training Loss: 0.678, Validation Accuracy: 61.88%\n",
            "Epoch [4/10], Training Loss: 0.643, Validation Accuracy: 62.31%\n",
            "Epoch [5/10], Training Loss: 0.596, Validation Accuracy: 62.35%\n",
            "Epoch [6/10], Training Loss: 0.575, Validation Accuracy: 61.82%\n",
            "Epoch [7/10], Training Loss: 0.545, Validation Accuracy: 62.19%\n",
            "Epoch [8/10], Training Loss: 0.533, Validation Accuracy: 61.81%\n",
            "Epoch [9/10], Training Loss: 0.497, Validation Accuracy: 61.63%\n",
            "Epoch [10/10], Training Loss: 0.482, Validation Accuracy: 61.56%\n",
            "Epoch [1/10], Training Loss: 0.861, Validation Accuracy: 61.68%\n",
            "Epoch [2/10], Training Loss: 0.723, Validation Accuracy: 62.32%\n",
            "Epoch [3/10], Training Loss: 0.671, Validation Accuracy: 62.24%\n",
            "Epoch [4/10], Training Loss: 0.617, Validation Accuracy: 62.34%\n",
            "Epoch [5/10], Training Loss: 0.582, Validation Accuracy: 62.14%\n",
            "Epoch [6/10], Training Loss: 0.558, Validation Accuracy: 62.44%\n",
            "Epoch [7/10], Training Loss: 0.529, Validation Accuracy: 62.36%\n",
            "Epoch [8/10], Training Loss: 0.506, Validation Accuracy: 62.31%\n",
            "Epoch [9/10], Training Loss: 0.487, Validation Accuracy: 61.77%\n",
            "Epoch [10/10], Training Loss: 0.481, Validation Accuracy: 61.43%\n",
            "Epoch [1/10], Training Loss: 0.812, Validation Accuracy: 62.16%\n",
            "Epoch [2/10], Training Loss: 0.698, Validation Accuracy: 61.64%\n",
            "Epoch [3/10], Training Loss: 0.623, Validation Accuracy: 62.20%\n",
            "Epoch [4/10], Training Loss: 0.589, Validation Accuracy: 61.81%\n",
            "Epoch [5/10], Training Loss: 0.557, Validation Accuracy: 61.91%\n",
            "Epoch [6/10], Training Loss: 0.527, Validation Accuracy: 62.58%\n",
            "Epoch [7/10], Training Loss: 0.503, Validation Accuracy: 61.61%\n",
            "Epoch [8/10], Training Loss: 0.485, Validation Accuracy: 62.11%\n",
            "Epoch [9/10], Training Loss: 0.458, Validation Accuracy: 62.00%\n",
            "Epoch [10/10], Training Loss: 0.432, Validation Accuracy: 62.45%\n",
            "Confusion Matrix:\n",
            "[[681  39  40  25  37   6  14  14  99  45]\n",
            " [ 27 734   7  13  15   4   7   7  75 111]\n",
            " [ 89   8 429 111 137  56  65  60  32  13]\n",
            " [ 25  14  45 514 102 127  60  55  27  31]\n",
            " [ 30   9  72  83 618  32  48  84  17   7]\n",
            " [ 16   9  57 249  84 454  19  87  13  12]\n",
            " [  7  12  52  96  97  25 664  13  14  20]\n",
            " [ 24  10  34  61 103  47  14 671  10  26]\n",
            " [ 77  26  13  25  16   5   4   3 800  31]\n",
            " [ 37 118  11  31  21   9   7  20  68 678]]\n",
            "Test Accuracy: 62.43%\n",
            "True Positives (TP): [681 734 429 514 618 454 664 671 800 678]\n",
            "False Positives (FP): [332 245 331 694 612 311 238 343 355 296]\n",
            "True Negatives (TN): [8668 8755 8669 8306 8388 8689 8762 8657 8645 8704]\n",
            "False Negatives (FN): [319 266 571 486 382 546 336 329 200 322]\n",
            ": [10000 10000 10000 10000 10000 10000 10000 10000 10000 10000]\n",
            "Precision: [0.67226061 0.74974464 0.56447368 0.42549669 0.50243902 0.59346405\n",
            " 0.73614191 0.6617357  0.69264069 0.69609856]\n",
            "Recall: [0.681 0.734 0.429 0.514 0.618 0.454 0.664 0.671 0.8   0.678]\n",
            "F1 Score: [0.67660209 0.74178878 0.4875     0.46557971 0.55426009 0.51444759\n",
            " 0.69821241 0.66633565 0.7424594  0.68693009]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import truncnorm\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import random\n",
        "\n",
        "# Define VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.x_dim = x_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2*z_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 32x32\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :self.z_dim], h[:, self.z_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "# Define VAE training procedure\n",
        "def vae_train(vae: VAE, trainloader: DataLoader, epochs: int) -> None:\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        vae.train()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = vae(inputs)\n",
        "            loss = vae_loss(recon_x, inputs, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "# Define classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Separate dataset by class\n",
        "class_indices = {i: [] for i in range(10)}  # CIFAR-10 has 10 classes\n",
        "for idx, (_, label) in enumerate(full_dataset):\n",
        "    class_indices[label].append(idx)\n",
        "\n",
        "# Define target count per class, summing to 60,000 with random distribution\n",
        "class_counts = np.random.multinomial(60000, [0.1] * 10)  # Adjust probabilities if you want specific class biases\n",
        "print(\"Random Images per Class:\", class_counts)\n",
        "\n",
        "# Sample indices based on the specified class counts\n",
        "indices = []\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    # Ensure count does not exceed available images\n",
        "    count = min(count, len(class_indices[class_id]))\n",
        "    selected_indices = random.sample(class_indices[class_id], count)\n",
        "    indices.extend(selected_indices)\n",
        "\n",
        "# Create a custom CIFAR-10 dataset with the sampled indices\n",
        "custom_dataset = Subset(full_dataset, indices)\n",
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create training and validation loaders\n",
        "trainloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "# Define VAE loss function\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "# Define training procedure for classification model\n",
        "def train(net: nn.Module, trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / (i+1):.3f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "# Define evaluation procedure\n",
        "def evaluate(net: nn.Module, testloader: DataLoader) -> Tuple[float, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    # Calculate TP, FP, TN, FN for each class\n",
        "    tp = np.diag(cm)\n",
        "    fp = cm.sum(axis=0) - tp\n",
        "    fn = cm.sum(axis=1) - tp\n",
        "    tn = cm.sum() - (fp + fn + tp)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for each class\n",
        "    precision = precision_score(all_labels, all_predictions, average=None)\n",
        "    recall = recall_score(all_labels, all_predictions, average=None)\n",
        "    f1 = f1_score(all_labels, all_predictions, average=None)\n",
        "\n",
        "    return accuracy, tp, fp, tn, fn, precision, recall, f1\n",
        "\n",
        "# Initialize clients\n",
        "def initialize_clients(trainset, transform, batch_size, num_clients):\n",
        "    clients = {}\n",
        "    for i in range(num_clients):\n",
        "        client_trainset = torch.utils.data.Subset(trainset, range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients))\n",
        "        client_trainloader = torch.utils.data.DataLoader(client_trainset, batch_size=batch_size, shuffle=True)\n",
        "        clients[f\"client_{i}\"] = client_trainloader\n",
        "    return clients\n",
        "\n",
        "def get_distribution_info(vae: VAE) -> Dict:\n",
        "    # Implement the logic to extract distribution information from the VAE\n",
        "    # This can involve computing statistics, parameters, or any other relevant information\n",
        "    # that can be used to generate augmented data\n",
        "\n",
        "    # Example implementation:\n",
        "    distribution_info = {\n",
        "\n",
        "        \"normal\": {\n",
        "            \"mean\": vae.encoder[-1].bias.data.cpu().numpy(),\n",
        "            \"std\": torch.exp(0.5 * vae.encoder[-1].weight.data).cpu().numpy()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return distribution_info\n",
        "\n",
        "def send_distribution_info(distribution_info: Dict) -> None:\n",
        "    # Implement the logic to send the distribution information to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the distribution information to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n",
        "\n",
        "def generate_augmented_data(vae: VAE, distribution_info_normal: Dict) -> torch.Tensor:\n",
        "    # Generate augmented data using both uniform and truncated uniform distributions\n",
        "\n",
        "\n",
        "\n",
        "    mean_normal = distribution_info_normal[\"mean\"]\n",
        "    std_normal = distribution_info_normal[\"std\"]\n",
        "\n",
        "    augmented_data_normal = torch.randn(64, vae.z_dim) * std_normal + mean_normal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the average of augmented data from both distributions\n",
        "    augmented_data_average =  augmented_data_normal\n",
        "\n",
        "    return augmented_data_average\n",
        "\n",
        "def federated_train(net: nn.Module, vae: VAE, trainloaders: Dict[str, DataLoader], trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    for epoch in range(epochs):\n",
        "        for client_id, client_trainloader in trainloaders.items():\n",
        "            # Train VAE on client data\n",
        "            vae_train(vae, client_trainloader, epochs=10)\n",
        "\n",
        "            # Share distribution information with global server\n",
        "            distribution_info = get_distribution_info(vae)\n",
        "            send_distribution_info(distribution_info)\n",
        "\n",
        "            # Receive distribution information from other clients\n",
        "            other_distribution_info = receive_distribution_info()\n",
        "\n",
        "            # Generate augmented data using received distribution information\n",
        "            augmented_data = generate_augmented_data(vae, other_distribution_info[\"normal\"])\n",
        "\n",
        "            # Train classification model using local, augmented, and validation data\n",
        "            train(net, client_trainloader, valloader, epochs=10)\n",
        "\n",
        "            # Send model updates to global server\n",
        "            send_model_update(client_id, net.state_dict())\n",
        "\n",
        "# Define logic to receive distribution information from global server\n",
        "def receive_distribution_info() -> Dict:\n",
        "    # Receive distribution information logic\n",
        "    distribution_info = {\n",
        "\n",
        "        \"normal\": {\n",
        "            \"mean\": np.zeros(20),  # Adjust the size based on your latent space dimension\n",
        "            \"std\": np.ones(20)\n",
        "        }\n",
        "    }\n",
        "    return distribution_info\n",
        "\n",
        "def send_model_update(client_id: str, model_update: Dict) -> None:\n",
        "    # Implement the logic to send the model update to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the model update\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the model update to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=10)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy, tp, fp, tn, fn, precision, recall, f1 = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    print(\"True Positives (TP):\", tp)\n",
        "    print(\"False Positives (FP):\", fp)\n",
        "    print(\"True Negatives (TN):\", tn)\n",
        "    print(\"False Negatives (FN):\", fn)\n",
        "    print(\":\", fn+tn+tp+fp)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8nzuAe1nXbx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPdKra2qnYGr",
        "outputId": "f1d04a0a-709e-4795-81ae-8821249289b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracies: [9.51, 9.51, 9.51, 9.59, 10.49, 12.03, 12.99, 13.97, 14.28, 14.7, 15.3, 16.12, 16.74, 17.27, 17.83, 18.36, 18.53, 18.87, 20.0, 21.7, 24.32, 24.86, 25.75, 26.95, 27.61, 28.1, 29.06, 29.38, 30.35, 30.09, 31.08, 31.84, 32.26, 31.86, 32.98, 33.22, 34.09, 34.77, 35.25, 35.55, 36.51, 37.46, 37.44, 37.59, 38.39, 38.59, 38.62, 39.0, 40.08, 39.9, 40.48, 40.51, 40.48, 40.91, 41.18, 41.38, 41.45, 42.17, 42.23, 42.01, 43.41, 42.65, 42.76, 43.47, 43.94, 43.97, 44.44, 44.25, 43.81, 44.55, 44.97, 45.03, 45.36, 45.93, 45.76, 45.61, 46.72, 46.76, 46.02, 46.23, 46.79, 47.67, 47.21, 47.32, 47.66, 48.43, 48.33, 48.17, 48.2, 47.38, 48.92, 49.72, 49.88, 50.11, 49.05, 49.04, 49.55, 50.44, 50.79, 50.36, 50.95, 51.36, 50.44, 51.21, 50.53, 51.4, 51.92, 50.25, 51.02, 51.68, 52.63, 52.26, 52.45, 52.38, 52.19, 53.0, 51.67, 52.86, 53.14, 52.92, 53.14, 53.21, 52.94, 53.15, 53.72, 53.89, 53.52, 53.97, 54.15, 54.06, 54.34, 54.74, 53.76, 54.03, 53.63, 54.41, 54.29, 54.23, 54.45, 53.7, 54.79, 55.2, 53.42, 55.64, 55.25, 55.39, 54.19, 55.59, 55.81, 55.44, 55.85, 55.67, 56.2, 55.16, 55.85, 55.87, 55.71, 56.39, 56.3, 56.14, 56.19, 56.12, 56.08, 57.09, 56.68, 56.55, 56.93, 57.59, 57.07, 57.31, 57.57, 56.54, 57.64, 57.42, 57.53, 57.47, 57.46, 57.69, 57.81, 57.64, 58.0, 57.27, 57.83, 58.23, 57.27, 58.18, 57.8, 57.71, 57.9, 58.06, 57.94, 58.49, 58.68, 58.72, 59.11, 57.3, 58.04, 58.87, 58.25, 57.94, 58.78, 58.71, 59.09, 59.39, 58.93, 58.19, 58.83, 59.66, 58.7, 58.19, 59.31, 59.96, 59.7, 59.86, 59.55, 58.08, 59.93, 59.44, 58.9, 58.13, 58.76, 59.55, 59.86, 59.3, 59.75, 58.49, 58.59, 59.44, 59.98, 59.53, 59.27, 59.94, 59.95, 59.91, 59.2, 59.75, 60.03, 59.35, 59.77, 59.13, 59.17, 60.25, 60.72, 60.27, 60.47, 60.17, 60.02, 60.16, 60.23, 60.38, 60.15, 60.43, 60.09, 60.76, 60.58, 61.15, 60.06, 59.91, 60.56, 60.47, 60.27, 60.52, 60.74, 60.82, 60.65, 60.35, 60.81, 60.67, 60.01, 59.58, 60.43, 60.98, 59.61, 59.95, 60.39, 60.94, 60.88, 60.17, 60.59, 60.53, 60.44, 61.09, 61.32, 61.12, 61.09, 60.9, 60.75, 60.42, 60.77, 60.23, 61.12, 61.41, 60.9, 61.49, 61.04, 60.82, 61.16, 61.23, 60.69, 61.05, 61.19, 61.06, 60.55, 61.68, 61.4, 61.48, 60.88, 61.33, 61.63, 60.62, 60.33, 60.96, 61.92, 61.31, 61.47, 61.12, 61.45, 61.63, 61.24, 61.58, 61.55, 61.32, 61.03, 61.52, 61.33, 61.06, 61.23, 61.36, 61.24, 61.43, 61.38, 62.31, 61.77, 62.31, 61.8, 62.17, 61.07, 61.49, 61.15, 60.82, 60.93, 62.41, 62.69, 62.02, 62.16, 61.87, 61.71, 61.93, 61.3, 60.98, 61.44, 62.36, 62.33, 62.16, 61.08, 61.83, 61.51, 62.06, 61.9, 61.97, 61.54, 61.39, 61.9, 61.33, 62.31, 61.55, 61.63, 62.24, 61.41, 61.84, 61.28, 61.48, 62.27, 62.17, 62.25, 60.61, 61.69, 61.58, 61.83, 61.25, 61.7, 61.85, 62.84, 61.87, 62.1, 61.41, 62.39, 62.18, 62.61, 62.01, 63.0, 61.7, 61.86, 60.95, 62.54, 62.85, 60.45, 62.05, 62.1, 62.47, 62.12, 62.54, 62.21, 62.45, 62.25, 61.38, 61.2, 61.5, 61.68, 61.89, 61.09, 61.28, 61.61, 61.71, 61.9, 62.01, 61.79, 61.28, 61.72, 61.65, 61.78, 62.74, 61.89, 62.36, 62.76, 62.06, 61.53, 61.6, 61.7, 62.06, 62.42, 62.73, 62.09, 62.86, 62.42, 62.4, 62.65, 61.53, 62.48, 61.88, 62.33, 62.76, 62.69, 61.87, 62.07, 62.07, 62.87, 62.49, 61.93, 62.4, 62.07, 62.74, 61.73, 62.13, 61.86, 62.42, 62.64, 61.65, 61.19, 61.96, 61.54, 62.08, 61.79, 61.18, 61.69, 61.98, 60.76, 62.0, 60.35, 60.83, 61.18, 61.77, 61.88, 62.31, 62.35, 61.82, 62.19, 61.81, 61.63, 61.56, 61.68, 62.32, 62.24, 62.34, 62.14, 62.44, 62.36, 62.31, 61.77, 61.43, 62.16, 61.64, 62.2, 61.81, 61.91, 62.58, 61.61, 62.11, 62.0, 62.45]\n",
            "Size of array: 500\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Your provided text\n",
        "log = \"\"\"\n",
        "Epoch [1/10], Training Loss: 2.306, Validation Accuracy: 9.51%\n",
        "Epoch [2/10], Training Loss: 2.305, Validation Accuracy: 9.51%\n",
        "Epoch [3/10], Training Loss: 2.304, Validation Accuracy: 9.51%\n",
        "Epoch [4/10], Training Loss: 2.303, Validation Accuracy: 9.59%\n",
        "Epoch [5/10], Training Loss: 2.302, Validation Accuracy: 10.49%\n",
        "Epoch [6/10], Training Loss: 2.301, Validation Accuracy: 12.03%\n",
        "Epoch [7/10], Training Loss: 2.300, Validation Accuracy: 12.99%\n",
        "Epoch [8/10], Training Loss: 2.299, Validation Accuracy: 13.97%\n",
        "Epoch [9/10], Training Loss: 2.297, Validation Accuracy: 14.28%\n",
        "Epoch [10/10], Training Loss: 2.296, Validation Accuracy: 14.70%\n",
        "Epoch [1/10], Training Loss: 2.295, Validation Accuracy: 15.30%\n",
        "Epoch [2/10], Training Loss: 2.293, Validation Accuracy: 16.12%\n",
        "Epoch [3/10], Training Loss: 2.289, Validation Accuracy: 16.74%\n",
        "Epoch [4/10], Training Loss: 2.285, Validation Accuracy: 17.27%\n",
        "Epoch [5/10], Training Loss: 2.279, Validation Accuracy: 17.83%\n",
        "Epoch [6/10], Training Loss: 2.269, Validation Accuracy: 18.36%\n",
        "Epoch [7/10], Training Loss: 2.254, Validation Accuracy: 18.53%\n",
        "Epoch [8/10], Training Loss: 2.232, Validation Accuracy: 18.87%\n",
        "Epoch [9/10], Training Loss: 2.202, Validation Accuracy: 20.00%\n",
        "Epoch [10/10], Training Loss: 2.166, Validation Accuracy: 21.70%\n",
        "Epoch [1/10], Training Loss: 2.146, Validation Accuracy: 24.32%\n",
        "Epoch [2/10], Training Loss: 2.113, Validation Accuracy: 24.86%\n",
        "Epoch [3/10], Training Loss: 2.086, Validation Accuracy: 25.75%\n",
        "Epoch [4/10], Training Loss: 2.063, Validation Accuracy: 26.95%\n",
        "Epoch [5/10], Training Loss: 2.042, Validation Accuracy: 27.61%\n",
        "Epoch [6/10], Training Loss: 2.020, Validation Accuracy: 28.10%\n",
        "Epoch [7/10], Training Loss: 1.999, Validation Accuracy: 29.06%\n",
        "Epoch [8/10], Training Loss: 1.979, Validation Accuracy: 29.38%\n",
        "Epoch [9/10], Training Loss: 1.962, Validation Accuracy: 30.35%\n",
        "Epoch [10/10], Training Loss: 1.944, Validation Accuracy: 30.09%\n",
        "Epoch [1/10], Training Loss: 1.925, Validation Accuracy: 31.08%\n",
        "Epoch [2/10], Training Loss: 1.909, Validation Accuracy: 31.84%\n",
        "Epoch [3/10], Training Loss: 1.894, Validation Accuracy: 32.26%\n",
        "Epoch [4/10], Training Loss: 1.880, Validation Accuracy: 31.86%\n",
        "Epoch [5/10], Training Loss: 1.862, Validation Accuracy: 32.98%\n",
        "Epoch [6/10], Training Loss: 1.851, Validation Accuracy: 33.22%\n",
        "Epoch [7/10], Training Loss: 1.831, Validation Accuracy: 34.09%\n",
        "Epoch [8/10], Training Loss: 1.814, Validation Accuracy: 34.77%\n",
        "Epoch [9/10], Training Loss: 1.797, Validation Accuracy: 35.25%\n",
        "Epoch [10/10], Training Loss: 1.780, Validation Accuracy: 35.55%\n",
        "Epoch [1/10], Training Loss: 1.784, Validation Accuracy: 36.51%\n",
        "Epoch [2/10], Training Loss: 1.762, Validation Accuracy: 37.46%\n",
        "Epoch [3/10], Training Loss: 1.745, Validation Accuracy: 37.44%\n",
        "Epoch [4/10], Training Loss: 1.732, Validation Accuracy: 37.59%\n",
        "Epoch [5/10], Training Loss: 1.717, Validation Accuracy: 38.39%\n",
        "Epoch [6/10], Training Loss: 1.702, Validation Accuracy: 38.59%\n",
        "Epoch [7/10], Training Loss: 1.690, Validation Accuracy: 38.62%\n",
        "Epoch [8/10], Training Loss: 1.676, Validation Accuracy: 39.00%\n",
        "Epoch [9/10], Training Loss: 1.664, Validation Accuracy: 40.08%\n",
        "Epoch [10/10], Training Loss: 1.655, Validation Accuracy: 39.90%\n",
        "Epoch [1/10], Training Loss: 1.659, Validation Accuracy: 40.48%\n",
        "Epoch [2/10], Training Loss: 1.643, Validation Accuracy: 40.51%\n",
        "Epoch [3/10], Training Loss: 1.633, Validation Accuracy: 40.48%\n",
        "Epoch [4/10], Training Loss: 1.626, Validation Accuracy: 40.91%\n",
        "Epoch [5/10], Training Loss: 1.611, Validation Accuracy: 41.18%\n",
        "Epoch [6/10], Training Loss: 1.604, Validation Accuracy: 41.38%\n",
        "Epoch [7/10], Training Loss: 1.597, Validation Accuracy: 41.45%\n",
        "Epoch [8/10], Training Loss: 1.581, Validation Accuracy: 42.17%\n",
        "Epoch [9/10], Training Loss: 1.571, Validation Accuracy: 42.23%\n",
        "Epoch [10/10], Training Loss: 1.558, Validation Accuracy: 42.01%\n",
        "Epoch [1/10], Training Loss: 1.582, Validation Accuracy: 43.41%\n",
        "Epoch [2/10], Training Loss: 1.572, Validation Accuracy: 42.65%\n",
        "Epoch [3/10], Training Loss: 1.557, Validation Accuracy: 42.76%\n",
        "Epoch [4/10], Training Loss: 1.561, Validation Accuracy: 43.47%\n",
        "Epoch [5/10], Training Loss: 1.536, Validation Accuracy: 43.94%\n",
        "Epoch [6/10], Training Loss: 1.527, Validation Accuracy: 43.97%\n",
        "Epoch [7/10], Training Loss: 1.522, Validation Accuracy: 44.44%\n",
        "Epoch [8/10], Training Loss: 1.517, Validation Accuracy: 44.25%\n",
        "Epoch [9/10], Training Loss: 1.504, Validation Accuracy: 43.81%\n",
        "Epoch [10/10], Training Loss: 1.495, Validation Accuracy: 44.55%\n",
        "Epoch [1/10], Training Loss: 1.534, Validation Accuracy: 44.97%\n",
        "Epoch [2/10], Training Loss: 1.522, Validation Accuracy: 45.03%\n",
        "Epoch [3/10], Training Loss: 1.507, Validation Accuracy: 45.36%\n",
        "Epoch [4/10], Training Loss: 1.499, Validation Accuracy: 45.93%\n",
        "Epoch [5/10], Training Loss: 1.488, Validation Accuracy: 45.76%\n",
        "Epoch [6/10], Training Loss: 1.478, Validation Accuracy: 45.61%\n",
        "Epoch [7/10], Training Loss: 1.472, Validation Accuracy: 46.72%\n",
        "Epoch [8/10], Training Loss: 1.465, Validation Accuracy: 46.76%\n",
        "Epoch [9/10], Training Loss: 1.452, Validation Accuracy: 46.02%\n",
        "Epoch [10/10], Training Loss: 1.443, Validation Accuracy: 46.23%\n",
        "Epoch [1/10], Training Loss: 1.467, Validation Accuracy: 46.79%\n",
        "Epoch [2/10], Training Loss: 1.452, Validation Accuracy: 47.67%\n",
        "Epoch [3/10], Training Loss: 1.446, Validation Accuracy: 47.21%\n",
        "Epoch [4/10], Training Loss: 1.431, Validation Accuracy: 47.32%\n",
        "Epoch [5/10], Training Loss: 1.420, Validation Accuracy: 47.66%\n",
        "Epoch [6/10], Training Loss: 1.411, Validation Accuracy: 48.43%\n",
        "Epoch [7/10], Training Loss: 1.401, Validation Accuracy: 48.33%\n",
        "Epoch [8/10], Training Loss: 1.392, Validation Accuracy: 48.17%\n",
        "Epoch [9/10], Training Loss: 1.389, Validation Accuracy: 48.20%\n",
        "Epoch [10/10], Training Loss: 1.378, Validation Accuracy: 47.38%\n",
        "Epoch [1/10], Training Loss: 1.406, Validation Accuracy: 48.92%\n",
        "Epoch [2/10], Training Loss: 1.386, Validation Accuracy: 49.72%\n",
        "Epoch [3/10], Training Loss: 1.386, Validation Accuracy: 49.88%\n",
        "Epoch [4/10], Training Loss: 1.372, Validation Accuracy: 50.11%\n",
        "Epoch [5/10], Training Loss: 1.357, Validation Accuracy: 49.05%\n",
        "Epoch [6/10], Training Loss: 1.348, Validation Accuracy: 49.04%\n",
        "Epoch [7/10], Training Loss: 1.343, Validation Accuracy: 49.55%\n",
        "Epoch [8/10], Training Loss: 1.326, Validation Accuracy: 50.44%\n",
        "Epoch [9/10], Training Loss: 1.320, Validation Accuracy: 50.79%\n",
        "Epoch [10/10], Training Loss: 1.312, Validation Accuracy: 50.36%\n",
        "Epoch [1/10], Training Loss: 1.365, Validation Accuracy: 50.95%\n",
        "Epoch [2/10], Training Loss: 1.350, Validation Accuracy: 51.36%\n",
        "Epoch [3/10], Training Loss: 1.331, Validation Accuracy: 50.44%\n",
        "Epoch [4/10], Training Loss: 1.322, Validation Accuracy: 51.21%\n",
        "Epoch [5/10], Training Loss: 1.311, Validation Accuracy: 50.53%\n",
        "Epoch [6/10], Training Loss: 1.305, Validation Accuracy: 51.40%\n",
        "Epoch [7/10], Training Loss: 1.295, Validation Accuracy: 51.92%\n",
        "Epoch [8/10], Training Loss: 1.287, Validation Accuracy: 50.25%\n",
        "Epoch [9/10], Training Loss: 1.286, Validation Accuracy: 51.02%\n",
        "Epoch [10/10], Training Loss: 1.274, Validation Accuracy: 51.68%\n",
        "Epoch [1/10], Training Loss: 1.343, Validation Accuracy: 52.63%\n",
        "Epoch [2/10], Training Loss: 1.322, Validation Accuracy: 52.26%\n",
        "Epoch [3/10], Training Loss: 1.313, Validation Accuracy: 52.45%\n",
        "Epoch [4/10], Training Loss: 1.302, Validation Accuracy: 52.38%\n",
        "Epoch [5/10], Training Loss: 1.298, Validation Accuracy: 52.19%\n",
        "Epoch [6/10], Training Loss: 1.283, Validation Accuracy: 53.00%\n",
        "Epoch [7/10], Training Loss: 1.271, Validation Accuracy: 51.67%\n",
        "Epoch [8/10], Training Loss: 1.261, Validation Accuracy: 52.86%\n",
        "Epoch [9/10], Training Loss: 1.253, Validation Accuracy: 53.14%\n",
        "Epoch [10/10], Training Loss: 1.237, Validation Accuracy: 52.92%\n",
        "Epoch [1/10], Training Loss: 1.311, Validation Accuracy: 53.14%\n",
        "Epoch [2/10], Training Loss: 1.306, Validation Accuracy: 53.21%\n",
        "Epoch [3/10], Training Loss: 1.278, Validation Accuracy: 52.94%\n",
        "Epoch [4/10], Training Loss: 1.274, Validation Accuracy: 53.15%\n",
        "Epoch [5/10], Training Loss: 1.268, Validation Accuracy: 53.72%\n",
        "Epoch [6/10], Training Loss: 1.250, Validation Accuracy: 53.89%\n",
        "Epoch [7/10], Training Loss: 1.245, Validation Accuracy: 53.52%\n",
        "Epoch [8/10], Training Loss: 1.240, Validation Accuracy: 53.97%\n",
        "Epoch [9/10], Training Loss: 1.224, Validation Accuracy: 54.15%\n",
        "Epoch [10/10], Training Loss: 1.220, Validation Accuracy: 54.06%\n",
        "Epoch [1/10], Training Loss: 1.282, Validation Accuracy: 54.34%\n",
        "Epoch [2/10], Training Loss: 1.259, Validation Accuracy: 54.74%\n",
        "Epoch [3/10], Training Loss: 1.245, Validation Accuracy: 53.76%\n",
        "Epoch [4/10], Training Loss: 1.237, Validation Accuracy: 54.03%\n",
        "Epoch [5/10], Training Loss: 1.226, Validation Accuracy: 53.63%\n",
        "Epoch [6/10], Training Loss: 1.216, Validation Accuracy: 54.41%\n",
        "Epoch [7/10], Training Loss: 1.210, Validation Accuracy: 54.29%\n",
        "Epoch [8/10], Training Loss: 1.205, Validation Accuracy: 54.23%\n",
        "Epoch [9/10], Training Loss: 1.196, Validation Accuracy: 54.45%\n",
        "Epoch [10/10], Training Loss: 1.185, Validation Accuracy: 53.70%\n",
        "Epoch [1/10], Training Loss: 1.233, Validation Accuracy: 54.79%\n",
        "Epoch [2/10], Training Loss: 1.213, Validation Accuracy: 55.20%\n",
        "Epoch [3/10], Training Loss: 1.197, Validation Accuracy: 53.42%\n",
        "Epoch [4/10], Training Loss: 1.197, Validation Accuracy: 55.64%\n",
        "Epoch [5/10], Training Loss: 1.179, Validation Accuracy: 55.25%\n",
        "Epoch [6/10], Training Loss: 1.166, Validation Accuracy: 55.39%\n",
        "Epoch [7/10], Training Loss: 1.164, Validation Accuracy: 54.19%\n",
        "Epoch [8/10], Training Loss: 1.159, Validation Accuracy: 55.59%\n",
        "Epoch [9/10], Training Loss: 1.132, Validation Accuracy: 55.81%\n",
        "Epoch [10/10], Training Loss: 1.127, Validation Accuracy: 55.44%\n",
        "Epoch [1/10], Training Loss: 1.212, Validation Accuracy: 55.85%\n",
        "Epoch [2/10], Training Loss: 1.190, Validation Accuracy: 55.67%\n",
        "Epoch [3/10], Training Loss: 1.174, Validation Accuracy: 56.20%\n",
        "Epoch [4/10], Training Loss: 1.159, Validation Accuracy: 55.16%\n",
        "Epoch [5/10], Training Loss: 1.145, Validation Accuracy: 55.85%\n",
        "Epoch [6/10], Training Loss: 1.143, Validation Accuracy: 55.87%\n",
        "Epoch [7/10], Training Loss: 1.133, Validation Accuracy: 55.71%\n",
        "Epoch [8/10], Training Loss: 1.127, Validation Accuracy: 56.39%\n",
        "Epoch [9/10], Training Loss: 1.114, Validation Accuracy: 56.30%\n",
        "Epoch [10/10], Training Loss: 1.104, Validation Accuracy: 56.14%\n",
        "Epoch [1/10], Training Loss: 1.209, Validation Accuracy: 56.19%\n",
        "Epoch [2/10], Training Loss: 1.199, Validation Accuracy: 56.12%\n",
        "Epoch [3/10], Training Loss: 1.172, Validation Accuracy: 56.08%\n",
        "Epoch [4/10], Training Loss: 1.158, Validation Accuracy: 57.09%\n",
        "Epoch [5/10], Training Loss: 1.145, Validation Accuracy: 56.68%\n",
        "Epoch [6/10], Training Loss: 1.134, Validation Accuracy: 56.55%\n",
        "Epoch [7/10], Training Loss: 1.133, Validation Accuracy: 56.93%\n",
        "Epoch [8/10], Training Loss: 1.126, Validation Accuracy: 57.59%\n",
        "Epoch [9/10], Training Loss: 1.104, Validation Accuracy: 57.07%\n",
        "Epoch [10/10], Training Loss: 1.112, Validation Accuracy: 57.31%\n",
        "Epoch [1/10], Training Loss: 1.186, Validation Accuracy: 57.57%\n",
        "Epoch [2/10], Training Loss: 1.161, Validation Accuracy: 56.54%\n",
        "Epoch [3/10], Training Loss: 1.153, Validation Accuracy: 57.64%\n",
        "Epoch [4/10], Training Loss: 1.137, Validation Accuracy: 57.42%\n",
        "Epoch [5/10], Training Loss: 1.120, Validation Accuracy: 57.53%\n",
        "Epoch [6/10], Training Loss: 1.115, Validation Accuracy: 57.47%\n",
        "Epoch [7/10], Training Loss: 1.106, Validation Accuracy: 57.46%\n",
        "Epoch [8/10], Training Loss: 1.091, Validation Accuracy: 57.69%\n",
        "Epoch [9/10], Training Loss: 1.089, Validation Accuracy: 57.81%\n",
        "Epoch [10/10], Training Loss: 1.082, Validation Accuracy: 57.64%\n",
        "Epoch [1/10], Training Loss: 1.172, Validation Accuracy: 58.00%\n",
        "Epoch [2/10], Training Loss: 1.141, Validation Accuracy: 57.27%\n",
        "Epoch [3/10], Training Loss: 1.138, Validation Accuracy: 57.83%\n",
        "Epoch [4/10], Training Loss: 1.114, Validation Accuracy: 58.23%\n",
        "Epoch [5/10], Training Loss: 1.106, Validation Accuracy: 57.27%\n",
        "Epoch [6/10], Training Loss: 1.088, Validation Accuracy: 58.18%\n",
        "Epoch [7/10], Training Loss: 1.078, Validation Accuracy: 57.80%\n",
        "Epoch [8/10], Training Loss: 1.067, Validation Accuracy: 57.71%\n",
        "Epoch [9/10], Training Loss: 1.060, Validation Accuracy: 57.90%\n",
        "Epoch [10/10], Training Loss: 1.053, Validation Accuracy: 58.06%\n",
        "Epoch [1/10], Training Loss: 1.125, Validation Accuracy: 57.94%\n",
        "Epoch [2/10], Training Loss: 1.099, Validation Accuracy: 58.49%\n",
        "Epoch [3/10], Training Loss: 1.083, Validation Accuracy: 58.68%\n",
        "Epoch [4/10], Training Loss: 1.064, Validation Accuracy: 58.72%\n",
        "Epoch [5/10], Training Loss: 1.052, Validation Accuracy: 59.11%\n",
        "Epoch [6/10], Training Loss: 1.042, Validation Accuracy: 57.30%\n",
        "Epoch [7/10], Training Loss: 1.029, Validation Accuracy: 58.04%\n",
        "Epoch [8/10], Training Loss: 1.015, Validation Accuracy: 58.87%\n",
        "Epoch [9/10], Training Loss: 1.008, Validation Accuracy: 58.25%\n",
        "Epoch [10/10], Training Loss: 1.002, Validation Accuracy: 57.94%\n",
        "Epoch [1/10], Training Loss: 1.113, Validation Accuracy: 58.78%\n",
        "Epoch [2/10], Training Loss: 1.080, Validation Accuracy: 58.71%\n",
        "Epoch [3/10], Training Loss: 1.065, Validation Accuracy: 59.09%\n",
        "Epoch [4/10], Training Loss: 1.042, Validation Accuracy: 59.39%\n",
        "Epoch [5/10], Training Loss: 1.024, Validation Accuracy: 58.93%\n",
        "Epoch [6/10], Training Loss: 1.016, Validation Accuracy: 58.19%\n",
        "Epoch [7/10], Training Loss: 1.010, Validation Accuracy: 58.83%\n",
        "Epoch [8/10], Training Loss: 0.997, Validation Accuracy: 59.66%\n",
        "Epoch [9/10], Training Loss: 0.986, Validation Accuracy: 58.70%\n",
        "Epoch [10/10], Training Loss: 0.972, Validation Accuracy: 58.19%\n",
        "Epoch [1/10], Training Loss: 1.126, Validation Accuracy: 59.31%\n",
        "Epoch [2/10], Training Loss: 1.088, Validation Accuracy: 59.96%\n",
        "Epoch [3/10], Training Loss: 1.069, Validation Accuracy: 59.70%\n",
        "Epoch [4/10], Training Loss: 1.056, Validation Accuracy: 59.86%\n",
        "Epoch [5/10], Training Loss: 1.044, Validation Accuracy: 59.55%\n",
        "Epoch [6/10], Training Loss: 1.038, Validation Accuracy: 58.08%\n",
        "Epoch [7/10], Training Loss: 1.027, Validation Accuracy: 59.93%\n",
        "Epoch [8/10], Training Loss: 1.002, Validation Accuracy: 59.44%\n",
        "Epoch [9/10], Training Loss: 0.990, Validation Accuracy: 58.90%\n",
        "Epoch [10/10], Training Loss: 0.984, Validation Accuracy: 58.13%\n",
        "Epoch [1/10], Training Loss: 1.102, Validation Accuracy: 58.76%\n",
        "Epoch [2/10], Training Loss: 1.076, Validation Accuracy: 59.55%\n",
        "Epoch [3/10], Training Loss: 1.043, Validation Accuracy: 59.86%\n",
        "Epoch [4/10], Training Loss: 1.031, Validation Accuracy: 59.30%\n",
        "Epoch [5/10], Training Loss: 1.022, Validation Accuracy: 59.75%\n",
        "Epoch [6/10], Training Loss: 1.007, Validation Accuracy: 58.49%\n",
        "Epoch [7/10], Training Loss: 0.991, Validation Accuracy: 58.59%\n",
        "Epoch [8/10], Training Loss: 0.988, Validation Accuracy: 59.44%\n",
        "Epoch [9/10], Training Loss: 0.965, Validation Accuracy: 59.98%\n",
        "Epoch [10/10], Training Loss: 0.947, Validation Accuracy: 59.53%\n",
        "Epoch [1/10], Training Loss: 1.089, Validation Accuracy: 59.27%\n",
        "Epoch [2/10], Training Loss: 1.055, Validation Accuracy: 59.94%\n",
        "Epoch [3/10], Training Loss: 1.031, Validation Accuracy: 59.95%\n",
        "Epoch [4/10], Training Loss: 1.006, Validation Accuracy: 59.91%\n",
        "Epoch [5/10], Training Loss: 0.994, Validation Accuracy: 59.20%\n",
        "Epoch [6/10], Training Loss: 0.985, Validation Accuracy: 59.75%\n",
        "Epoch [7/10], Training Loss: 0.974, Validation Accuracy: 60.03%\n",
        "Epoch [8/10], Training Loss: 0.955, Validation Accuracy: 59.35%\n",
        "Epoch [9/10], Training Loss: 0.942, Validation Accuracy: 59.77%\n",
        "Epoch [10/10], Training Loss: 0.938, Validation Accuracy: 59.13%\n",
        "Epoch [1/10], Training Loss: 1.044, Validation Accuracy: 59.17%\n",
        "Epoch [2/10], Training Loss: 1.013, Validation Accuracy: 60.25%\n",
        "Epoch [3/10], Training Loss: 0.992, Validation Accuracy: 60.72%\n",
        "Epoch [4/10], Training Loss: 0.975, Validation Accuracy: 60.27%\n",
        "Epoch [5/10], Training Loss: 0.954, Validation Accuracy: 60.47%\n",
        "Epoch [6/10], Training Loss: 0.939, Validation Accuracy: 60.17%\n",
        "Epoch [7/10], Training Loss: 0.921, Validation Accuracy: 60.02%\n",
        "Epoch [8/10], Training Loss: 0.906, Validation Accuracy: 60.16%\n",
        "Epoch [9/10], Training Loss: 0.897, Validation Accuracy: 60.23%\n",
        "Epoch [10/10], Training Loss: 0.877, Validation Accuracy: 60.38%\n",
        "Epoch [1/10], Training Loss: 1.043, Validation Accuracy: 60.15%\n",
        "Epoch [2/10], Training Loss: 0.995, Validation Accuracy: 60.43%\n",
        "Epoch [3/10], Training Loss: 0.973, Validation Accuracy: 60.09%\n",
        "Epoch [4/10], Training Loss: 0.951, Validation Accuracy: 60.76%\n",
        "Epoch [5/10], Training Loss: 0.928, Validation Accuracy: 60.58%\n",
        "Epoch [6/10], Training Loss: 0.912, Validation Accuracy: 61.15%\n",
        "Epoch [7/10], Training Loss: 0.901, Validation Accuracy: 60.06%\n",
        "Epoch [8/10], Training Loss: 0.882, Validation Accuracy: 59.91%\n",
        "Epoch [9/10], Training Loss: 0.880, Validation Accuracy: 60.56%\n",
        "Epoch [10/10], Training Loss: 0.871, Validation Accuracy: 60.47%\n",
        "Epoch [1/10], Training Loss: 1.063, Validation Accuracy: 60.27%\n",
        "Epoch [2/10], Training Loss: 1.009, Validation Accuracy: 60.52%\n",
        "Epoch [3/10], Training Loss: 0.994, Validation Accuracy: 60.74%\n",
        "Epoch [4/10], Training Loss: 0.968, Validation Accuracy: 60.82%\n",
        "Epoch [5/10], Training Loss: 0.955, Validation Accuracy: 60.65%\n",
        "Epoch [6/10], Training Loss: 0.932, Validation Accuracy: 60.35%\n",
        "Epoch [7/10], Training Loss: 0.917, Validation Accuracy: 60.81%\n",
        "Epoch [8/10], Training Loss: 0.906, Validation Accuracy: 60.67%\n",
        "Epoch [9/10], Training Loss: 0.891, Validation Accuracy: 60.01%\n",
        "Epoch [10/10], Training Loss: 0.890, Validation Accuracy: 59.58%\n",
        "Epoch [1/10], Training Loss: 1.031, Validation Accuracy: 60.43%\n",
        "Epoch [2/10], Training Loss: 0.979, Validation Accuracy: 60.98%\n",
        "Epoch [3/10], Training Loss: 0.964, Validation Accuracy: 59.61%\n",
        "Epoch [4/10], Training Loss: 0.942, Validation Accuracy: 59.95%\n",
        "Epoch [5/10], Training Loss: 0.925, Validation Accuracy: 60.39%\n",
        "Epoch [6/10], Training Loss: 0.913, Validation Accuracy: 60.94%\n",
        "Epoch [7/10], Training Loss: 0.883, Validation Accuracy: 60.88%\n",
        "Epoch [8/10], Training Loss: 0.871, Validation Accuracy: 60.17%\n",
        "Epoch [9/10], Training Loss: 0.874, Validation Accuracy: 60.59%\n",
        "Epoch [10/10], Training Loss: 0.844, Validation Accuracy: 60.53%\n",
        "Epoch [1/10], Training Loss: 1.018, Validation Accuracy: 60.44%\n",
        "Epoch [2/10], Training Loss: 0.971, Validation Accuracy: 61.09%\n",
        "Epoch [3/10], Training Loss: 0.943, Validation Accuracy: 61.32%\n",
        "Epoch [4/10], Training Loss: 0.923, Validation Accuracy: 61.12%\n",
        "Epoch [5/10], Training Loss: 0.902, Validation Accuracy: 61.09%\n",
        "Epoch [6/10], Training Loss: 0.885, Validation Accuracy: 60.90%\n",
        "Epoch [7/10], Training Loss: 0.864, Validation Accuracy: 60.75%\n",
        "Epoch [8/10], Training Loss: 0.851, Validation Accuracy: 60.42%\n",
        "Epoch [9/10], Training Loss: 0.840, Validation Accuracy: 60.77%\n",
        "Epoch [10/10], Training Loss: 0.827, Validation Accuracy: 60.23%\n",
        "Epoch [1/10], Training Loss: 0.982, Validation Accuracy: 61.12%\n",
        "Epoch [2/10], Training Loss: 0.933, Validation Accuracy: 61.41%\n",
        "Epoch [3/10], Training Loss: 0.906, Validation Accuracy: 60.90%\n",
        "Epoch [4/10], Training Loss: 0.890, Validation Accuracy: 61.49%\n",
        "Epoch [5/10], Training Loss: 0.859, Validation Accuracy: 61.04%\n",
        "Epoch [6/10], Training Loss: 0.842, Validation Accuracy: 60.82%\n",
        "Epoch [7/10], Training Loss: 0.820, Validation Accuracy: 61.16%\n",
        "Epoch [8/10], Training Loss: 0.813, Validation Accuracy: 61.23%\n",
        "Epoch [9/10], Training Loss: 0.806, Validation Accuracy: 60.69%\n",
        "Epoch [10/10], Training Loss: 0.782, Validation Accuracy: 61.05%\n",
        "Epoch [1/10], Training Loss: 0.975, Validation Accuracy: 61.19%\n",
        "Epoch [2/10], Training Loss: 0.921, Validation Accuracy: 61.06%\n",
        "Epoch [3/10], Training Loss: 0.895, Validation Accuracy: 60.55%\n",
        "Epoch [4/10], Training Loss: 0.871, Validation Accuracy: 61.68%\n",
        "Epoch [5/10], Training Loss: 0.844, Validation Accuracy: 61.40%\n",
        "Epoch [6/10], Training Loss: 0.829, Validation Accuracy: 61.48%\n",
        "Epoch [7/10], Training Loss: 0.811, Validation Accuracy: 60.88%\n",
        "Epoch [8/10], Training Loss: 0.792, Validation Accuracy: 61.33%\n",
        "Epoch [9/10], Training Loss: 0.769, Validation Accuracy: 61.63%\n",
        "Epoch [10/10], Training Loss: 0.764, Validation Accuracy: 60.62%\n",
        "Epoch [1/10], Training Loss: 0.996, Validation Accuracy: 60.33%\n",
        "Epoch [2/10], Training Loss: 0.946, Validation Accuracy: 60.96%\n",
        "Epoch [3/10], Training Loss: 0.911, Validation Accuracy: 61.92%\n",
        "Epoch [4/10], Training Loss: 0.891, Validation Accuracy: 61.31%\n",
        "Epoch [5/10], Training Loss: 0.861, Validation Accuracy: 61.47%\n",
        "Epoch [6/10], Training Loss: 0.836, Validation Accuracy: 61.12%\n",
        "Epoch [7/10], Training Loss: 0.820, Validation Accuracy: 61.45%\n",
        "Epoch [8/10], Training Loss: 0.810, Validation Accuracy: 61.63%\n",
        "Epoch [9/10], Training Loss: 0.791, Validation Accuracy: 61.24%\n",
        "Epoch [10/10], Training Loss: 0.773, Validation Accuracy: 61.58%\n",
        "Epoch [1/10], Training Loss: 0.965, Validation Accuracy: 61.55%\n",
        "Epoch [2/10], Training Loss: 0.909, Validation Accuracy: 61.32%\n",
        "Epoch [3/10], Training Loss: 0.886, Validation Accuracy: 61.03%\n",
        "Epoch [4/10], Training Loss: 0.863, Validation Accuracy: 61.52%\n",
        "Epoch [5/10], Training Loss: 0.825, Validation Accuracy: 61.33%\n",
        "Epoch [6/10], Training Loss: 0.814, Validation Accuracy: 61.06%\n",
        "Epoch [7/10], Training Loss: 0.790, Validation Accuracy: 61.23%\n",
        "Epoch [8/10], Training Loss: 0.780, Validation Accuracy: 61.36%\n",
        "Epoch [9/10], Training Loss: 0.764, Validation Accuracy: 61.24%\n",
        "Epoch [10/10], Training Loss: 0.747, Validation Accuracy: 61.43%\n",
        "Epoch [1/10], Training Loss: 0.970, Validation Accuracy: 61.38%\n",
        "Epoch [2/10], Training Loss: 0.902, Validation Accuracy: 62.31%\n",
        "Epoch [3/10], Training Loss: 0.870, Validation Accuracy: 61.77%\n",
        "Epoch [4/10], Training Loss: 0.839, Validation Accuracy: 62.31%\n",
        "Epoch [5/10], Training Loss: 0.811, Validation Accuracy: 61.80%\n",
        "Epoch [6/10], Training Loss: 0.797, Validation Accuracy: 62.17%\n",
        "Epoch [7/10], Training Loss: 0.784, Validation Accuracy: 61.07%\n",
        "Epoch [8/10], Training Loss: 0.764, Validation Accuracy: 61.49%\n",
        "Epoch [9/10], Training Loss: 0.742, Validation Accuracy: 61.15%\n",
        "Epoch [10/10], Training Loss: 0.736, Validation Accuracy: 60.82%\n",
        "Epoch [1/10], Training Loss: 0.936, Validation Accuracy: 60.93%\n",
        "Epoch [2/10], Training Loss: 0.878, Validation Accuracy: 62.41%\n",
        "Epoch [3/10], Training Loss: 0.833, Validation Accuracy: 62.69%\n",
        "Epoch [4/10], Training Loss: 0.800, Validation Accuracy: 62.02%\n",
        "Epoch [5/10], Training Loss: 0.778, Validation Accuracy: 62.16%\n",
        "Epoch [6/10], Training Loss: 0.752, Validation Accuracy: 61.87%\n",
        "Epoch [7/10], Training Loss: 0.742, Validation Accuracy: 61.71%\n",
        "Epoch [8/10], Training Loss: 0.722, Validation Accuracy: 61.93%\n",
        "Epoch [9/10], Training Loss: 0.705, Validation Accuracy: 61.30%\n",
        "Epoch [10/10], Training Loss: 0.691, Validation Accuracy: 60.98%\n",
        "Epoch [1/10], Training Loss: 0.926, Validation Accuracy: 61.44%\n",
        "Epoch [2/10], Training Loss: 0.846, Validation Accuracy: 62.36%\n",
        "Epoch [3/10], Training Loss: 0.811, Validation Accuracy: 62.33%\n",
        "Epoch [4/10], Training Loss: 0.779, Validation Accuracy: 62.16%\n",
        "Epoch [5/10], Training Loss: 0.762, Validation Accuracy: 61.08%\n",
        "Epoch [6/10], Training Loss: 0.743, Validation Accuracy: 61.83%\n",
        "Epoch [7/10], Training Loss: 0.723, Validation Accuracy: 61.51%\n",
        "Epoch [8/10], Training Loss: 0.696, Validation Accuracy: 62.06%\n",
        "Epoch [9/10], Training Loss: 0.678, Validation Accuracy: 61.90%\n",
        "Epoch [10/10], Training Loss: 0.663, Validation Accuracy: 61.97%\n",
        "Epoch [1/10], Training Loss: 0.945, Validation Accuracy: 61.54%\n",
        "Epoch [2/10], Training Loss: 0.881, Validation Accuracy: 61.39%\n",
        "Epoch [3/10], Training Loss: 0.837, Validation Accuracy: 61.90%\n",
        "Epoch [4/10], Training Loss: 0.805, Validation Accuracy: 61.33%\n",
        "Epoch [5/10], Training Loss: 0.777, Validation Accuracy: 62.31%\n",
        "Epoch [6/10], Training Loss: 0.757, Validation Accuracy: 61.55%\n",
        "Epoch [7/10], Training Loss: 0.735, Validation Accuracy: 61.63%\n",
        "Epoch [8/10], Training Loss: 0.712, Validation Accuracy: 62.24%\n",
        "Epoch [9/10], Training Loss: 0.697, Validation Accuracy: 61.41%\n",
        "Epoch [10/10], Training Loss: 0.686, Validation Accuracy: 61.84%\n",
        "Epoch [1/10], Training Loss: 0.922, Validation Accuracy: 61.28%\n",
        "Epoch [2/10], Training Loss: 0.848, Validation Accuracy: 61.48%\n",
        "Epoch [3/10], Training Loss: 0.825, Validation Accuracy: 62.27%\n",
        "Epoch [4/10], Training Loss: 0.784, Validation Accuracy: 62.17%\n",
        "Epoch [5/10], Training Loss: 0.761, Validation Accuracy: 62.25%\n",
        "Epoch [6/10], Training Loss: 0.737, Validation Accuracy: 60.61%\n",
        "Epoch [7/10], Training Loss: 0.720, Validation Accuracy: 61.69%\n",
        "Epoch [8/10], Training Loss: 0.692, Validation Accuracy: 61.58%\n",
        "Epoch [9/10], Training Loss: 0.668, Validation Accuracy: 61.83%\n",
        "Epoch [10/10], Training Loss: 0.665, Validation Accuracy: 61.25%\n",
        "Epoch [1/10], Training Loss: 0.922, Validation Accuracy: 61.70%\n",
        "Epoch [2/10], Training Loss: 0.837, Validation Accuracy: 61.85%\n",
        "Epoch [3/10], Training Loss: 0.794, Validation Accuracy: 62.84%\n",
        "Epoch [4/10], Training Loss: 0.773, Validation Accuracy: 61.87%\n",
        "Epoch [5/10], Training Loss: 0.739, Validation Accuracy: 62.10%\n",
        "Epoch [6/10], Training Loss: 0.710, Validation Accuracy: 61.41%\n",
        "Epoch [7/10], Training Loss: 0.688, Validation Accuracy: 62.39%\n",
        "Epoch [8/10], Training Loss: 0.665, Validation Accuracy: 62.18%\n",
        "Epoch [9/10], Training Loss: 0.658, Validation Accuracy: 62.61%\n",
        "Epoch [10/10], Training Loss: 0.638, Validation Accuracy: 62.01%\n",
        "Epoch [1/10], Training Loss: 0.897, Validation Accuracy: 63.00%\n",
        "Epoch [2/10], Training Loss: 0.809, Validation Accuracy: 61.70%\n",
        "Epoch [3/10], Training Loss: 0.759, Validation Accuracy: 61.86%\n",
        "Epoch [4/10], Training Loss: 0.734, Validation Accuracy: 60.95%\n",
        "Epoch [5/10], Training Loss: 0.698, Validation Accuracy: 62.54%\n",
        "Epoch [6/10], Training Loss: 0.679, Validation Accuracy: 62.85%\n",
        "Epoch [7/10], Training Loss: 0.657, Validation Accuracy: 60.45%\n",
        "Epoch [8/10], Training Loss: 0.641, Validation Accuracy: 62.05%\n",
        "Epoch [9/10], Training Loss: 0.623, Validation Accuracy: 62.10%\n",
        "Epoch [10/10], Training Loss: 0.594, Validation Accuracy: 62.47%\n",
        "Epoch [1/10], Training Loss: 0.872, Validation Accuracy: 62.12%\n",
        "Epoch [2/10], Training Loss: 0.789, Validation Accuracy: 62.54%\n",
        "Epoch [3/10], Training Loss: 0.739, Validation Accuracy: 62.21%\n",
        "Epoch [4/10], Training Loss: 0.707, Validation Accuracy: 62.45%\n",
        "Epoch [5/10], Training Loss: 0.680, Validation Accuracy: 62.25%\n",
        "Epoch [6/10], Training Loss: 0.652, Validation Accuracy: 61.38%\n",
        "Epoch [7/10], Training Loss: 0.637, Validation Accuracy: 61.20%\n",
        "Epoch [8/10], Training Loss: 0.620, Validation Accuracy: 61.50%\n",
        "Epoch [9/10], Training Loss: 0.599, Validation Accuracy: 61.68%\n",
        "Epoch [10/10], Training Loss: 0.570, Validation Accuracy: 61.89%\n",
        "Epoch [1/10], Training Loss: 0.905, Validation Accuracy: 61.09%\n",
        "Epoch [2/10], Training Loss: 0.820, Validation Accuracy: 61.28%\n",
        "Epoch [3/10], Training Loss: 0.769, Validation Accuracy: 61.61%\n",
        "Epoch [4/10], Training Loss: 0.728, Validation Accuracy: 61.71%\n",
        "Epoch [5/10], Training Loss: 0.704, Validation Accuracy: 61.90%\n",
        "Epoch [6/10], Training Loss: 0.673, Validation Accuracy: 62.01%\n",
        "Epoch [7/10], Training Loss: 0.659, Validation Accuracy: 61.79%\n",
        "Epoch [8/10], Training Loss: 0.632, Validation Accuracy: 61.28%\n",
        "Epoch [9/10], Training Loss: 0.610, Validation Accuracy: 61.72%\n",
        "Epoch [10/10], Training Loss: 0.596, Validation Accuracy: 61.65%\n",
        "Epoch [1/10], Training Loss: 0.881, Validation Accuracy: 61.78%\n",
        "Epoch [2/10], Training Loss: 0.790, Validation Accuracy: 62.74%\n",
        "Epoch [3/10], Training Loss: 0.751, Validation Accuracy: 61.89%\n",
        "Epoch [4/10], Training Loss: 0.709, Validation Accuracy: 62.36%\n",
        "Epoch [5/10], Training Loss: 0.679, Validation Accuracy: 62.76%\n",
        "Epoch [6/10], Training Loss: 0.663, Validation Accuracy: 62.06%\n",
        "Epoch [7/10], Training Loss: 0.634, Validation Accuracy: 61.53%\n",
        "Epoch [8/10], Training Loss: 0.617, Validation Accuracy: 61.60%\n",
        "Epoch [9/10], Training Loss: 0.595, Validation Accuracy: 61.70%\n",
        "Epoch [10/10], Training Loss: 0.574, Validation Accuracy: 62.06%\n",
        "Epoch [1/10], Training Loss: 0.880, Validation Accuracy: 62.42%\n",
        "Epoch [2/10], Training Loss: 0.784, Validation Accuracy: 62.73%\n",
        "Epoch [3/10], Training Loss: 0.722, Validation Accuracy: 62.09%\n",
        "Epoch [4/10], Training Loss: 0.688, Validation Accuracy: 62.86%\n",
        "Epoch [5/10], Training Loss: 0.670, Validation Accuracy: 62.42%\n",
        "Epoch [6/10], Training Loss: 0.626, Validation Accuracy: 62.40%\n",
        "Epoch [7/10], Training Loss: 0.607, Validation Accuracy: 62.65%\n",
        "Epoch [8/10], Training Loss: 0.604, Validation Accuracy: 61.53%\n",
        "Epoch [9/10], Training Loss: 0.572, Validation Accuracy: 62.48%\n",
        "Epoch [10/10], Training Loss: 0.549, Validation Accuracy: 61.88%\n",
        "Epoch [1/10], Training Loss: 0.843, Validation Accuracy: 62.33%\n",
        "Epoch [2/10], Training Loss: 0.743, Validation Accuracy: 62.76%\n",
        "Epoch [3/10], Training Loss: 0.697, Validation Accuracy: 62.69%\n",
        "Epoch [4/10], Training Loss: 0.659, Validation Accuracy: 61.87%\n",
        "Epoch [5/10], Training Loss: 0.623, Validation Accuracy: 62.07%\n",
        "Epoch [6/10], Training Loss: 0.596, Validation Accuracy: 62.07%\n",
        "Epoch [7/10], Training Loss: 0.580, Validation Accuracy: 62.87%\n",
        "Epoch [8/10], Training Loss: 0.548, Validation Accuracy: 62.49%\n",
        "Epoch [9/10], Training Loss: 0.536, Validation Accuracy: 61.93%\n",
        "Epoch [10/10], Training Loss: 0.512, Validation Accuracy: 62.40%\n",
        "Epoch [1/10], Training Loss: 0.832, Validation Accuracy: 62.07%\n",
        "Epoch [2/10], Training Loss: 0.720, Validation Accuracy: 62.74%\n",
        "Epoch [3/10], Training Loss: 0.674, Validation Accuracy: 61.73%\n",
        "Epoch [4/10], Training Loss: 0.636, Validation Accuracy: 62.13%\n",
        "Epoch [5/10], Training Loss: 0.605, Validation Accuracy: 61.86%\n",
        "Epoch [6/10], Training Loss: 0.575, Validation Accuracy: 62.42%\n",
        "Epoch [7/10], Training Loss: 0.544, Validation Accuracy: 62.64%\n",
        "Epoch [8/10], Training Loss: 0.525, Validation Accuracy: 61.65%\n",
        "Epoch [9/10], Training Loss: 0.508, Validation Accuracy: 61.19%\n",
        "Epoch [10/10], Training Loss: 0.498, Validation Accuracy: 61.96%\n",
        "Epoch [1/10], Training Loss: 0.865, Validation Accuracy: 61.54%\n",
        "Epoch [2/10], Training Loss: 0.758, Validation Accuracy: 62.08%\n",
        "Epoch [3/10], Training Loss: 0.692, Validation Accuracy: 61.79%\n",
        "Epoch [4/10], Training Loss: 0.657, Validation Accuracy: 61.18%\n",
        "Epoch [5/10], Training Loss: 0.628, Validation Accuracy: 61.69%\n",
        "Epoch [6/10], Training Loss: 0.593, Validation Accuracy: 61.98%\n",
        "Epoch [7/10], Training Loss: 0.568, Validation Accuracy: 60.76%\n",
        "Epoch [8/10], Training Loss: 0.550, Validation Accuracy: 62.00%\n",
        "Epoch [9/10], Training Loss: 0.526, Validation Accuracy: 60.35%\n",
        "Epoch [10/10], Training Loss: 0.508, Validation Accuracy: 60.83%\n",
        "Epoch [1/10], Training Loss: 0.841, Validation Accuracy: 61.18%\n",
        "Epoch [2/10], Training Loss: 0.731, Validation Accuracy: 61.77%\n",
        "Epoch [3/10], Training Loss: 0.678, Validation Accuracy: 61.88%\n",
        "Epoch [4/10], Training Loss: 0.643, Validation Accuracy: 62.31%\n",
        "Epoch [5/10], Training Loss: 0.596, Validation Accuracy: 62.35%\n",
        "Epoch [6/10], Training Loss: 0.575, Validation Accuracy: 61.82%\n",
        "Epoch [7/10], Training Loss: 0.545, Validation Accuracy: 62.19%\n",
        "Epoch [8/10], Training Loss: 0.533, Validation Accuracy: 61.81%\n",
        "Epoch [9/10], Training Loss: 0.497, Validation Accuracy: 61.63%\n",
        "Epoch [10/10], Training Loss: 0.482, Validation Accuracy: 61.56%\n",
        "Epoch [1/10], Training Loss: 0.861, Validation Accuracy: 61.68%\n",
        "Epoch [2/10], Training Loss: 0.723, Validation Accuracy: 62.32%\n",
        "Epoch [3/10], Training Loss: 0.671, Validation Accuracy: 62.24%\n",
        "Epoch [4/10], Training Loss: 0.617, Validation Accuracy: 62.34%\n",
        "Epoch [5/10], Training Loss: 0.582, Validation Accuracy: 62.14%\n",
        "Epoch [6/10], Training Loss: 0.558, Validation Accuracy: 62.44%\n",
        "Epoch [7/10], Training Loss: 0.529, Validation Accuracy: 62.36%\n",
        "Epoch [8/10], Training Loss: 0.506, Validation Accuracy: 62.31%\n",
        "Epoch [9/10], Training Loss: 0.487, Validation Accuracy: 61.77%\n",
        "Epoch [10/10], Training Loss: 0.481, Validation Accuracy: 61.43%\n",
        "Epoch [1/10], Training Loss: 0.812, Validation Accuracy: 62.16%\n",
        "Epoch [2/10], Training Loss: 0.698, Validation Accuracy: 61.64%\n",
        "Epoch [3/10], Training Loss: 0.623, Validation Accuracy: 62.20%\n",
        "Epoch [4/10], Training Loss: 0.589, Validation Accuracy: 61.81%\n",
        "Epoch [5/10], Training Loss: 0.557, Validation Accuracy: 61.91%\n",
        "Epoch [6/10], Training Loss: 0.527, Validation Accuracy: 62.58%\n",
        "Epoch [7/10], Training Loss: 0.503, Validation Accuracy: 61.61%\n",
        "Epoch [8/10], Training Loss: 0.485, Validation Accuracy: 62.11%\n",
        "Epoch [9/10], Training Loss: 0.458, Validation Accuracy: 62.00%\n",
        "Epoch [10/10], Training Loss: 0.432, Validation Accuracy: 62.45%\n",
        "\"\"\"\n",
        "\n",
        "# Regular expression to find validation accuracies\n",
        "accuracies = re.findall(r'Validation Accuracy: (\\d+\\.\\d+)%', log)\n",
        "\n",
        "# Convert accuracies from string to float\n",
        "accuracies = [float(acc) for acc in accuracies]\n",
        "\n",
        "# Print accuracies\n",
        "print(\"Accuracies:\", accuracies)\n",
        "\n",
        "# Print size of the array\n",
        "print(\"Size of array:\", len(accuracies))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W-x2SiLmfsN",
        "outputId": "d511ab9b-ec69-4c37-eaa7-bbf0816e35b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Random Images per Class: [5987 5897 5878 6031 6114 6065 6057 6028 5940 6003]\n",
            "Epoch [1/10], Training Loss: 2.304, Validation Accuracy: 10.63%\n",
            "Epoch [2/10], Training Loss: 2.303, Validation Accuracy: 10.65%\n",
            "Epoch [3/10], Training Loss: 2.301, Validation Accuracy: 12.53%\n",
            "Epoch [4/10], Training Loss: 2.300, Validation Accuracy: 15.01%\n",
            "Epoch [5/10], Training Loss: 2.298, Validation Accuracy: 15.84%\n",
            "Epoch [6/10], Training Loss: 2.296, Validation Accuracy: 16.61%\n",
            "Epoch [7/10], Training Loss: 2.292, Validation Accuracy: 17.22%\n",
            "Epoch [8/10], Training Loss: 2.288, Validation Accuracy: 17.73%\n",
            "Epoch [9/10], Training Loss: 2.281, Validation Accuracy: 18.03%\n",
            "Epoch [10/10], Training Loss: 2.271, Validation Accuracy: 18.24%\n",
            "Epoch [1/10], Training Loss: 2.256, Validation Accuracy: 18.29%\n",
            "Epoch [2/10], Training Loss: 2.232, Validation Accuracy: 18.64%\n",
            "Epoch [3/10], Training Loss: 2.199, Validation Accuracy: 19.14%\n",
            "Epoch [4/10], Training Loss: 2.165, Validation Accuracy: 20.29%\n",
            "Epoch [5/10], Training Loss: 2.134, Validation Accuracy: 22.04%\n",
            "Epoch [6/10], Training Loss: 2.106, Validation Accuracy: 23.48%\n",
            "Epoch [7/10], Training Loss: 2.081, Validation Accuracy: 24.06%\n",
            "Epoch [8/10], Training Loss: 2.058, Validation Accuracy: 24.25%\n",
            "Epoch [9/10], Training Loss: 2.040, Validation Accuracy: 25.54%\n",
            "Epoch [10/10], Training Loss: 2.025, Validation Accuracy: 25.73%\n",
            "Epoch [1/10], Training Loss: 2.022, Validation Accuracy: 26.48%\n",
            "Epoch [2/10], Training Loss: 2.008, Validation Accuracy: 27.31%\n",
            "Epoch [3/10], Training Loss: 1.993, Validation Accuracy: 27.95%\n",
            "Epoch [4/10], Training Loss: 1.981, Validation Accuracy: 27.97%\n",
            "Epoch [5/10], Training Loss: 1.968, Validation Accuracy: 28.70%\n",
            "Epoch [6/10], Training Loss: 1.955, Validation Accuracy: 29.93%\n",
            "Epoch [7/10], Training Loss: 1.942, Validation Accuracy: 30.11%\n",
            "Epoch [8/10], Training Loss: 1.930, Validation Accuracy: 30.36%\n",
            "Epoch [9/10], Training Loss: 1.915, Validation Accuracy: 31.10%\n",
            "Epoch [10/10], Training Loss: 1.901, Validation Accuracy: 31.93%\n",
            "Epoch [1/10], Training Loss: 1.876, Validation Accuracy: 32.49%\n",
            "Epoch [2/10], Training Loss: 1.856, Validation Accuracy: 33.43%\n",
            "Epoch [3/10], Training Loss: 1.841, Validation Accuracy: 33.96%\n",
            "Epoch [4/10], Training Loss: 1.819, Validation Accuracy: 34.24%\n",
            "Epoch [5/10], Training Loss: 1.800, Validation Accuracy: 35.30%\n",
            "Epoch [6/10], Training Loss: 1.779, Validation Accuracy: 36.12%\n",
            "Epoch [7/10], Training Loss: 1.759, Validation Accuracy: 35.80%\n",
            "Epoch [8/10], Training Loss: 1.738, Validation Accuracy: 36.71%\n",
            "Epoch [9/10], Training Loss: 1.720, Validation Accuracy: 37.00%\n",
            "Epoch [10/10], Training Loss: 1.701, Validation Accuracy: 37.50%\n",
            "Epoch [1/10], Training Loss: 1.710, Validation Accuracy: 37.77%\n",
            "Epoch [2/10], Training Loss: 1.693, Validation Accuracy: 38.55%\n",
            "Epoch [3/10], Training Loss: 1.676, Validation Accuracy: 38.23%\n",
            "Epoch [4/10], Training Loss: 1.663, Validation Accuracy: 39.57%\n",
            "Epoch [5/10], Training Loss: 1.651, Validation Accuracy: 39.43%\n",
            "Epoch [6/10], Training Loss: 1.638, Validation Accuracy: 40.00%\n",
            "Epoch [7/10], Training Loss: 1.626, Validation Accuracy: 40.53%\n",
            "Epoch [8/10], Training Loss: 1.619, Validation Accuracy: 40.64%\n",
            "Epoch [9/10], Training Loss: 1.609, Validation Accuracy: 41.21%\n",
            "Epoch [10/10], Training Loss: 1.594, Validation Accuracy: 41.65%\n",
            "Epoch [1/10], Training Loss: 1.632, Validation Accuracy: 41.89%\n",
            "Epoch [2/10], Training Loss: 1.619, Validation Accuracy: 41.41%\n",
            "Epoch [3/10], Training Loss: 1.600, Validation Accuracy: 42.37%\n",
            "Epoch [4/10], Training Loss: 1.598, Validation Accuracy: 42.68%\n",
            "Epoch [5/10], Training Loss: 1.588, Validation Accuracy: 42.57%\n",
            "Epoch [6/10], Training Loss: 1.572, Validation Accuracy: 43.18%\n",
            "Epoch [7/10], Training Loss: 1.568, Validation Accuracy: 43.22%\n",
            "Epoch [8/10], Training Loss: 1.559, Validation Accuracy: 43.70%\n",
            "Epoch [9/10], Training Loss: 1.548, Validation Accuracy: 44.55%\n",
            "Epoch [10/10], Training Loss: 1.545, Validation Accuracy: 44.10%\n",
            "Epoch [1/10], Training Loss: 1.560, Validation Accuracy: 44.37%\n",
            "Epoch [2/10], Training Loss: 1.543, Validation Accuracy: 45.17%\n",
            "Epoch [3/10], Training Loss: 1.537, Validation Accuracy: 44.57%\n",
            "Epoch [4/10], Training Loss: 1.524, Validation Accuracy: 45.02%\n",
            "Epoch [5/10], Training Loss: 1.515, Validation Accuracy: 44.36%\n",
            "Epoch [6/10], Training Loss: 1.507, Validation Accuracy: 44.68%\n",
            "Epoch [7/10], Training Loss: 1.496, Validation Accuracy: 45.39%\n",
            "Epoch [8/10], Training Loss: 1.491, Validation Accuracy: 45.88%\n",
            "Epoch [9/10], Training Loss: 1.489, Validation Accuracy: 44.94%\n",
            "Epoch [10/10], Training Loss: 1.482, Validation Accuracy: 46.33%\n",
            "Epoch [1/10], Training Loss: 1.499, Validation Accuracy: 46.75%\n",
            "Epoch [2/10], Training Loss: 1.488, Validation Accuracy: 46.79%\n",
            "Epoch [3/10], Training Loss: 1.476, Validation Accuracy: 47.10%\n",
            "Epoch [4/10], Training Loss: 1.470, Validation Accuracy: 46.53%\n",
            "Epoch [5/10], Training Loss: 1.455, Validation Accuracy: 46.49%\n",
            "Epoch [6/10], Training Loss: 1.451, Validation Accuracy: 46.99%\n",
            "Epoch [7/10], Training Loss: 1.443, Validation Accuracy: 47.39%\n",
            "Epoch [8/10], Training Loss: 1.430, Validation Accuracy: 46.19%\n",
            "Epoch [9/10], Training Loss: 1.436, Validation Accuracy: 47.79%\n",
            "Epoch [10/10], Training Loss: 1.419, Validation Accuracy: 47.39%\n",
            "Epoch [1/10], Training Loss: 1.451, Validation Accuracy: 47.94%\n",
            "Epoch [2/10], Training Loss: 1.437, Validation Accuracy: 47.87%\n",
            "Epoch [3/10], Training Loss: 1.425, Validation Accuracy: 48.20%\n",
            "Epoch [4/10], Training Loss: 1.422, Validation Accuracy: 48.09%\n",
            "Epoch [5/10], Training Loss: 1.404, Validation Accuracy: 48.60%\n",
            "Epoch [6/10], Training Loss: 1.395, Validation Accuracy: 48.58%\n",
            "Epoch [7/10], Training Loss: 1.391, Validation Accuracy: 48.44%\n",
            "Epoch [8/10], Training Loss: 1.380, Validation Accuracy: 49.38%\n",
            "Epoch [9/10], Training Loss: 1.379, Validation Accuracy: 49.27%\n",
            "Epoch [10/10], Training Loss: 1.372, Validation Accuracy: 48.94%\n",
            "Epoch [1/10], Training Loss: 1.403, Validation Accuracy: 49.25%\n",
            "Epoch [2/10], Training Loss: 1.378, Validation Accuracy: 50.23%\n",
            "Epoch [3/10], Training Loss: 1.367, Validation Accuracy: 49.71%\n",
            "Epoch [4/10], Training Loss: 1.359, Validation Accuracy: 50.06%\n",
            "Epoch [5/10], Training Loss: 1.355, Validation Accuracy: 50.22%\n",
            "Epoch [6/10], Training Loss: 1.342, Validation Accuracy: 50.55%\n",
            "Epoch [7/10], Training Loss: 1.336, Validation Accuracy: 50.25%\n",
            "Epoch [8/10], Training Loss: 1.325, Validation Accuracy: 50.75%\n",
            "Epoch [9/10], Training Loss: 1.315, Validation Accuracy: 50.64%\n",
            "Epoch [10/10], Training Loss: 1.309, Validation Accuracy: 51.10%\n",
            "Epoch [1/10], Training Loss: 1.387, Validation Accuracy: 50.93%\n",
            "Epoch [2/10], Training Loss: 1.370, Validation Accuracy: 49.48%\n",
            "Epoch [3/10], Training Loss: 1.366, Validation Accuracy: 51.56%\n",
            "Epoch [4/10], Training Loss: 1.344, Validation Accuracy: 51.36%\n",
            "Epoch [5/10], Training Loss: 1.336, Validation Accuracy: 51.61%\n",
            "Epoch [6/10], Training Loss: 1.326, Validation Accuracy: 51.57%\n",
            "Epoch [7/10], Training Loss: 1.318, Validation Accuracy: 51.84%\n",
            "Epoch [8/10], Training Loss: 1.306, Validation Accuracy: 50.76%\n",
            "Epoch [9/10], Training Loss: 1.306, Validation Accuracy: 51.94%\n",
            "Epoch [10/10], Training Loss: 1.298, Validation Accuracy: 52.48%\n",
            "Epoch [1/10], Training Loss: 1.349, Validation Accuracy: 51.30%\n",
            "Epoch [2/10], Training Loss: 1.335, Validation Accuracy: 51.24%\n",
            "Epoch [3/10], Training Loss: 1.315, Validation Accuracy: 52.84%\n",
            "Epoch [4/10], Training Loss: 1.308, Validation Accuracy: 52.46%\n",
            "Epoch [5/10], Training Loss: 1.302, Validation Accuracy: 52.85%\n",
            "Epoch [6/10], Training Loss: 1.287, Validation Accuracy: 52.53%\n",
            "Epoch [7/10], Training Loss: 1.283, Validation Accuracy: 52.29%\n",
            "Epoch [8/10], Training Loss: 1.274, Validation Accuracy: 52.66%\n",
            "Epoch [9/10], Training Loss: 1.262, Validation Accuracy: 52.52%\n",
            "Epoch [10/10], Training Loss: 1.254, Validation Accuracy: 52.70%\n",
            "Epoch [1/10], Training Loss: 1.310, Validation Accuracy: 52.43%\n",
            "Epoch [2/10], Training Loss: 1.289, Validation Accuracy: 53.74%\n",
            "Epoch [3/10], Training Loss: 1.274, Validation Accuracy: 53.61%\n",
            "Epoch [4/10], Training Loss: 1.257, Validation Accuracy: 53.54%\n",
            "Epoch [5/10], Training Loss: 1.251, Validation Accuracy: 52.69%\n",
            "Epoch [6/10], Training Loss: 1.249, Validation Accuracy: 53.28%\n",
            "Epoch [7/10], Training Loss: 1.230, Validation Accuracy: 52.36%\n",
            "Epoch [8/10], Training Loss: 1.229, Validation Accuracy: 51.92%\n",
            "Epoch [9/10], Training Loss: 1.222, Validation Accuracy: 53.71%\n",
            "Epoch [10/10], Training Loss: 1.207, Validation Accuracy: 54.17%\n",
            "Epoch [1/10], Training Loss: 1.285, Validation Accuracy: 52.43%\n",
            "Epoch [2/10], Training Loss: 1.265, Validation Accuracy: 52.70%\n",
            "Epoch [3/10], Training Loss: 1.246, Validation Accuracy: 54.28%\n",
            "Epoch [4/10], Training Loss: 1.238, Validation Accuracy: 54.36%\n",
            "Epoch [5/10], Training Loss: 1.222, Validation Accuracy: 54.34%\n",
            "Epoch [6/10], Training Loss: 1.213, Validation Accuracy: 54.22%\n",
            "Epoch [7/10], Training Loss: 1.215, Validation Accuracy: 54.97%\n",
            "Epoch [8/10], Training Loss: 1.196, Validation Accuracy: 54.17%\n",
            "Epoch [9/10], Training Loss: 1.194, Validation Accuracy: 54.32%\n",
            "Epoch [10/10], Training Loss: 1.184, Validation Accuracy: 55.15%\n",
            "Epoch [1/10], Training Loss: 1.227, Validation Accuracy: 54.46%\n",
            "Epoch [2/10], Training Loss: 1.207, Validation Accuracy: 55.00%\n",
            "Epoch [3/10], Training Loss: 1.190, Validation Accuracy: 54.94%\n",
            "Epoch [4/10], Training Loss: 1.180, Validation Accuracy: 55.22%\n",
            "Epoch [5/10], Training Loss: 1.171, Validation Accuracy: 56.01%\n",
            "Epoch [6/10], Training Loss: 1.169, Validation Accuracy: 54.93%\n",
            "Epoch [7/10], Training Loss: 1.164, Validation Accuracy: 54.98%\n",
            "Epoch [8/10], Training Loss: 1.143, Validation Accuracy: 55.47%\n",
            "Epoch [9/10], Training Loss: 1.132, Validation Accuracy: 55.57%\n",
            "Epoch [10/10], Training Loss: 1.128, Validation Accuracy: 56.00%\n",
            "Epoch [1/10], Training Loss: 1.228, Validation Accuracy: 55.98%\n",
            "Epoch [2/10], Training Loss: 1.197, Validation Accuracy: 56.21%\n",
            "Epoch [3/10], Training Loss: 1.180, Validation Accuracy: 55.72%\n",
            "Epoch [4/10], Training Loss: 1.172, Validation Accuracy: 56.28%\n",
            "Epoch [5/10], Training Loss: 1.164, Validation Accuracy: 56.37%\n",
            "Epoch [6/10], Training Loss: 1.152, Validation Accuracy: 55.90%\n",
            "Epoch [7/10], Training Loss: 1.142, Validation Accuracy: 56.08%\n",
            "Epoch [8/10], Training Loss: 1.138, Validation Accuracy: 55.32%\n",
            "Epoch [9/10], Training Loss: 1.124, Validation Accuracy: 56.73%\n",
            "Epoch [10/10], Training Loss: 1.115, Validation Accuracy: 56.45%\n",
            "Epoch [1/10], Training Loss: 1.209, Validation Accuracy: 56.68%\n",
            "Epoch [2/10], Training Loss: 1.187, Validation Accuracy: 57.28%\n",
            "Epoch [3/10], Training Loss: 1.171, Validation Accuracy: 56.49%\n",
            "Epoch [4/10], Training Loss: 1.173, Validation Accuracy: 56.33%\n",
            "Epoch [5/10], Training Loss: 1.148, Validation Accuracy: 57.36%\n",
            "Epoch [6/10], Training Loss: 1.133, Validation Accuracy: 55.98%\n",
            "Epoch [7/10], Training Loss: 1.129, Validation Accuracy: 56.85%\n",
            "Epoch [8/10], Training Loss: 1.114, Validation Accuracy: 56.79%\n",
            "Epoch [9/10], Training Loss: 1.100, Validation Accuracy: 57.22%\n",
            "Epoch [10/10], Training Loss: 1.102, Validation Accuracy: 56.48%\n",
            "Epoch [1/10], Training Loss: 1.182, Validation Accuracy: 57.33%\n",
            "Epoch [2/10], Training Loss: 1.151, Validation Accuracy: 57.68%\n",
            "Epoch [3/10], Training Loss: 1.137, Validation Accuracy: 57.91%\n",
            "Epoch [4/10], Training Loss: 1.119, Validation Accuracy: 57.68%\n",
            "Epoch [5/10], Training Loss: 1.107, Validation Accuracy: 57.98%\n",
            "Epoch [6/10], Training Loss: 1.094, Validation Accuracy: 57.94%\n",
            "Epoch [7/10], Training Loss: 1.084, Validation Accuracy: 57.55%\n",
            "Epoch [8/10], Training Loss: 1.076, Validation Accuracy: 57.62%\n",
            "Epoch [9/10], Training Loss: 1.073, Validation Accuracy: 56.00%\n",
            "Epoch [10/10], Training Loss: 1.073, Validation Accuracy: 57.69%\n",
            "Epoch [1/10], Training Loss: 1.169, Validation Accuracy: 57.75%\n",
            "Epoch [2/10], Training Loss: 1.141, Validation Accuracy: 58.10%\n",
            "Epoch [3/10], Training Loss: 1.116, Validation Accuracy: 57.15%\n",
            "Epoch [4/10], Training Loss: 1.107, Validation Accuracy: 57.99%\n",
            "Epoch [5/10], Training Loss: 1.096, Validation Accuracy: 58.34%\n",
            "Epoch [6/10], Training Loss: 1.083, Validation Accuracy: 58.27%\n",
            "Epoch [7/10], Training Loss: 1.067, Validation Accuracy: 57.81%\n",
            "Epoch [8/10], Training Loss: 1.059, Validation Accuracy: 58.32%\n",
            "Epoch [9/10], Training Loss: 1.054, Validation Accuracy: 58.00%\n",
            "Epoch [10/10], Training Loss: 1.044, Validation Accuracy: 57.47%\n",
            "Epoch [1/10], Training Loss: 1.115, Validation Accuracy: 58.75%\n",
            "Epoch [2/10], Training Loss: 1.086, Validation Accuracy: 58.98%\n",
            "Epoch [3/10], Training Loss: 1.071, Validation Accuracy: 59.21%\n",
            "Epoch [4/10], Training Loss: 1.056, Validation Accuracy: 58.97%\n",
            "Epoch [5/10], Training Loss: 1.042, Validation Accuracy: 58.33%\n",
            "Epoch [6/10], Training Loss: 1.032, Validation Accuracy: 58.78%\n",
            "Epoch [7/10], Training Loss: 1.019, Validation Accuracy: 58.66%\n",
            "Epoch [8/10], Training Loss: 1.006, Validation Accuracy: 58.97%\n",
            "Epoch [9/10], Training Loss: 1.000, Validation Accuracy: 57.36%\n",
            "Epoch [10/10], Training Loss: 0.998, Validation Accuracy: 57.88%\n",
            "Epoch [1/10], Training Loss: 1.117, Validation Accuracy: 59.28%\n",
            "Epoch [2/10], Training Loss: 1.080, Validation Accuracy: 58.01%\n",
            "Epoch [3/10], Training Loss: 1.074, Validation Accuracy: 59.07%\n",
            "Epoch [4/10], Training Loss: 1.048, Validation Accuracy: 59.23%\n",
            "Epoch [5/10], Training Loss: 1.033, Validation Accuracy: 59.39%\n",
            "Epoch [6/10], Training Loss: 1.016, Validation Accuracy: 59.44%\n",
            "Epoch [7/10], Training Loss: 1.011, Validation Accuracy: 59.20%\n",
            "Epoch [8/10], Training Loss: 0.994, Validation Accuracy: 59.21%\n",
            "Epoch [9/10], Training Loss: 0.981, Validation Accuracy: 59.03%\n",
            "Epoch [10/10], Training Loss: 0.979, Validation Accuracy: 59.34%\n",
            "Epoch [1/10], Training Loss: 1.119, Validation Accuracy: 59.81%\n",
            "Epoch [2/10], Training Loss: 1.079, Validation Accuracy: 58.81%\n",
            "Epoch [3/10], Training Loss: 1.061, Validation Accuracy: 59.75%\n",
            "Epoch [4/10], Training Loss: 1.045, Validation Accuracy: 59.39%\n",
            "Epoch [5/10], Training Loss: 1.027, Validation Accuracy: 59.81%\n",
            "Epoch [6/10], Training Loss: 1.024, Validation Accuracy: 59.56%\n",
            "Epoch [7/10], Training Loss: 1.004, Validation Accuracy: 59.60%\n",
            "Epoch [8/10], Training Loss: 0.987, Validation Accuracy: 59.85%\n",
            "Epoch [9/10], Training Loss: 0.985, Validation Accuracy: 59.78%\n",
            "Epoch [10/10], Training Loss: 0.963, Validation Accuracy: 59.50%\n",
            "Epoch [1/10], Training Loss: 1.086, Validation Accuracy: 59.98%\n",
            "Epoch [2/10], Training Loss: 1.050, Validation Accuracy: 59.18%\n",
            "Epoch [3/10], Training Loss: 1.031, Validation Accuracy: 60.33%\n",
            "Epoch [4/10], Training Loss: 1.018, Validation Accuracy: 60.49%\n",
            "Epoch [5/10], Training Loss: 0.994, Validation Accuracy: 59.89%\n",
            "Epoch [6/10], Training Loss: 0.982, Validation Accuracy: 59.23%\n",
            "Epoch [7/10], Training Loss: 0.970, Validation Accuracy: 60.72%\n",
            "Epoch [8/10], Training Loss: 0.954, Validation Accuracy: 59.97%\n",
            "Epoch [9/10], Training Loss: 0.941, Validation Accuracy: 59.01%\n",
            "Epoch [10/10], Training Loss: 0.927, Validation Accuracy: 60.00%\n",
            "Epoch [1/10], Training Loss: 1.080, Validation Accuracy: 59.98%\n",
            "Epoch [2/10], Training Loss: 1.044, Validation Accuracy: 60.24%\n",
            "Epoch [3/10], Training Loss: 1.019, Validation Accuracy: 60.55%\n",
            "Epoch [4/10], Training Loss: 0.989, Validation Accuracy: 60.77%\n",
            "Epoch [5/10], Training Loss: 0.982, Validation Accuracy: 59.94%\n",
            "Epoch [6/10], Training Loss: 0.968, Validation Accuracy: 60.14%\n",
            "Epoch [7/10], Training Loss: 0.961, Validation Accuracy: 59.85%\n",
            "Epoch [8/10], Training Loss: 0.946, Validation Accuracy: 58.95%\n",
            "Epoch [9/10], Training Loss: 0.927, Validation Accuracy: 59.42%\n",
            "Epoch [10/10], Training Loss: 0.916, Validation Accuracy: 60.84%\n",
            "Epoch [1/10], Training Loss: 1.042, Validation Accuracy: 59.78%\n",
            "Epoch [2/10], Training Loss: 0.999, Validation Accuracy: 60.12%\n",
            "Epoch [3/10], Training Loss: 0.979, Validation Accuracy: 60.28%\n",
            "Epoch [4/10], Training Loss: 0.954, Validation Accuracy: 60.79%\n",
            "Epoch [5/10], Training Loss: 0.940, Validation Accuracy: 60.07%\n",
            "Epoch [6/10], Training Loss: 0.926, Validation Accuracy: 60.27%\n",
            "Epoch [7/10], Training Loss: 0.913, Validation Accuracy: 59.44%\n",
            "Epoch [8/10], Training Loss: 0.897, Validation Accuracy: 61.15%\n",
            "Epoch [9/10], Training Loss: 0.877, Validation Accuracy: 60.50%\n",
            "Epoch [10/10], Training Loss: 0.876, Validation Accuracy: 60.23%\n",
            "Epoch [1/10], Training Loss: 1.040, Validation Accuracy: 60.70%\n",
            "Epoch [2/10], Training Loss: 0.994, Validation Accuracy: 60.94%\n",
            "Epoch [3/10], Training Loss: 0.972, Validation Accuracy: 61.05%\n",
            "Epoch [4/10], Training Loss: 0.947, Validation Accuracy: 60.53%\n",
            "Epoch [5/10], Training Loss: 0.932, Validation Accuracy: 61.31%\n",
            "Epoch [6/10], Training Loss: 0.914, Validation Accuracy: 60.56%\n",
            "Epoch [7/10], Training Loss: 0.899, Validation Accuracy: 60.94%\n",
            "Epoch [8/10], Training Loss: 0.882, Validation Accuracy: 60.89%\n",
            "Epoch [9/10], Training Loss: 0.873, Validation Accuracy: 59.55%\n",
            "Epoch [10/10], Training Loss: 0.869, Validation Accuracy: 60.91%\n",
            "Epoch [1/10], Training Loss: 1.046, Validation Accuracy: 61.31%\n",
            "Epoch [2/10], Training Loss: 1.004, Validation Accuracy: 61.77%\n",
            "Epoch [3/10], Training Loss: 0.975, Validation Accuracy: 61.61%\n",
            "Epoch [4/10], Training Loss: 0.950, Validation Accuracy: 61.15%\n",
            "Epoch [5/10], Training Loss: 0.922, Validation Accuracy: 61.35%\n",
            "Epoch [6/10], Training Loss: 0.912, Validation Accuracy: 60.90%\n",
            "Epoch [7/10], Training Loss: 0.894, Validation Accuracy: 61.88%\n",
            "Epoch [8/10], Training Loss: 0.874, Validation Accuracy: 61.71%\n",
            "Epoch [9/10], Training Loss: 0.865, Validation Accuracy: 61.25%\n",
            "Epoch [10/10], Training Loss: 0.846, Validation Accuracy: 61.17%\n",
            "Epoch [1/10], Training Loss: 1.026, Validation Accuracy: 61.36%\n",
            "Epoch [2/10], Training Loss: 0.974, Validation Accuracy: 61.74%\n",
            "Epoch [3/10], Training Loss: 0.930, Validation Accuracy: 60.86%\n",
            "Epoch [4/10], Training Loss: 0.913, Validation Accuracy: 61.20%\n",
            "Epoch [5/10], Training Loss: 0.907, Validation Accuracy: 60.93%\n",
            "Epoch [6/10], Training Loss: 0.882, Validation Accuracy: 61.64%\n",
            "Epoch [7/10], Training Loss: 0.873, Validation Accuracy: 61.39%\n",
            "Epoch [8/10], Training Loss: 0.849, Validation Accuracy: 61.24%\n",
            "Epoch [9/10], Training Loss: 0.828, Validation Accuracy: 61.33%\n",
            "Epoch [10/10], Training Loss: 0.817, Validation Accuracy: 61.02%\n",
            "Epoch [1/10], Training Loss: 1.018, Validation Accuracy: 61.08%\n",
            "Epoch [2/10], Training Loss: 0.961, Validation Accuracy: 61.25%\n",
            "Epoch [3/10], Training Loss: 0.934, Validation Accuracy: 61.20%\n",
            "Epoch [4/10], Training Loss: 0.913, Validation Accuracy: 61.89%\n",
            "Epoch [5/10], Training Loss: 0.881, Validation Accuracy: 61.66%\n",
            "Epoch [6/10], Training Loss: 0.869, Validation Accuracy: 61.63%\n",
            "Epoch [7/10], Training Loss: 0.852, Validation Accuracy: 61.39%\n",
            "Epoch [8/10], Training Loss: 0.838, Validation Accuracy: 61.56%\n",
            "Epoch [9/10], Training Loss: 0.831, Validation Accuracy: 61.28%\n",
            "Epoch [10/10], Training Loss: 0.809, Validation Accuracy: 61.71%\n",
            "Epoch [1/10], Training Loss: 0.975, Validation Accuracy: 61.37%\n",
            "Epoch [2/10], Training Loss: 0.933, Validation Accuracy: 62.03%\n",
            "Epoch [3/10], Training Loss: 0.893, Validation Accuracy: 62.50%\n",
            "Epoch [4/10], Training Loss: 0.861, Validation Accuracy: 62.30%\n",
            "Epoch [5/10], Training Loss: 0.846, Validation Accuracy: 61.76%\n",
            "Epoch [6/10], Training Loss: 0.824, Validation Accuracy: 61.54%\n",
            "Epoch [7/10], Training Loss: 0.813, Validation Accuracy: 61.39%\n",
            "Epoch [8/10], Training Loss: 0.797, Validation Accuracy: 61.42%\n",
            "Epoch [9/10], Training Loss: 0.779, Validation Accuracy: 61.78%\n",
            "Epoch [10/10], Training Loss: 0.772, Validation Accuracy: 62.17%\n",
            "Epoch [1/10], Training Loss: 0.962, Validation Accuracy: 62.01%\n",
            "Epoch [2/10], Training Loss: 0.909, Validation Accuracy: 62.07%\n",
            "Epoch [3/10], Training Loss: 0.881, Validation Accuracy: 61.96%\n",
            "Epoch [4/10], Training Loss: 0.852, Validation Accuracy: 62.36%\n",
            "Epoch [5/10], Training Loss: 0.830, Validation Accuracy: 62.06%\n",
            "Epoch [6/10], Training Loss: 0.814, Validation Accuracy: 60.31%\n",
            "Epoch [7/10], Training Loss: 0.802, Validation Accuracy: 61.94%\n",
            "Epoch [8/10], Training Loss: 0.783, Validation Accuracy: 61.65%\n",
            "Epoch [9/10], Training Loss: 0.760, Validation Accuracy: 61.27%\n",
            "Epoch [10/10], Training Loss: 0.761, Validation Accuracy: 61.31%\n",
            "Epoch [1/10], Training Loss: 0.984, Validation Accuracy: 62.82%\n",
            "Epoch [2/10], Training Loss: 0.913, Validation Accuracy: 61.88%\n",
            "Epoch [3/10], Training Loss: 0.875, Validation Accuracy: 62.51%\n",
            "Epoch [4/10], Training Loss: 0.856, Validation Accuracy: 61.77%\n",
            "Epoch [5/10], Training Loss: 0.833, Validation Accuracy: 61.87%\n",
            "Epoch [6/10], Training Loss: 0.806, Validation Accuracy: 62.11%\n",
            "Epoch [7/10], Training Loss: 0.794, Validation Accuracy: 62.11%\n",
            "Epoch [8/10], Training Loss: 0.777, Validation Accuracy: 62.24%\n",
            "Epoch [9/10], Training Loss: 0.761, Validation Accuracy: 61.71%\n",
            "Epoch [10/10], Training Loss: 0.747, Validation Accuracy: 61.55%\n",
            "Epoch [1/10], Training Loss: 0.964, Validation Accuracy: 61.15%\n",
            "Epoch [2/10], Training Loss: 0.900, Validation Accuracy: 61.98%\n",
            "Epoch [3/10], Training Loss: 0.868, Validation Accuracy: 62.19%\n",
            "Epoch [4/10], Training Loss: 0.830, Validation Accuracy: 61.46%\n",
            "Epoch [5/10], Training Loss: 0.801, Validation Accuracy: 61.92%\n",
            "Epoch [6/10], Training Loss: 0.780, Validation Accuracy: 62.14%\n",
            "Epoch [7/10], Training Loss: 0.771, Validation Accuracy: 61.97%\n",
            "Epoch [8/10], Training Loss: 0.757, Validation Accuracy: 62.40%\n",
            "Epoch [9/10], Training Loss: 0.733, Validation Accuracy: 61.76%\n",
            "Epoch [10/10], Training Loss: 0.728, Validation Accuracy: 61.65%\n",
            "Epoch [1/10], Training Loss: 0.957, Validation Accuracy: 61.02%\n",
            "Epoch [2/10], Training Loss: 0.894, Validation Accuracy: 62.18%\n",
            "Epoch [3/10], Training Loss: 0.851, Validation Accuracy: 62.01%\n",
            "Epoch [4/10], Training Loss: 0.836, Validation Accuracy: 61.51%\n",
            "Epoch [5/10], Training Loss: 0.803, Validation Accuracy: 61.93%\n",
            "Epoch [6/10], Training Loss: 0.778, Validation Accuracy: 62.08%\n",
            "Epoch [7/10], Training Loss: 0.764, Validation Accuracy: 61.96%\n",
            "Epoch [8/10], Training Loss: 0.748, Validation Accuracy: 62.61%\n",
            "Epoch [9/10], Training Loss: 0.732, Validation Accuracy: 62.16%\n",
            "Epoch [10/10], Training Loss: 0.716, Validation Accuracy: 62.02%\n",
            "Epoch [1/10], Training Loss: 0.926, Validation Accuracy: 62.14%\n",
            "Epoch [2/10], Training Loss: 0.853, Validation Accuracy: 62.81%\n",
            "Epoch [3/10], Training Loss: 0.821, Validation Accuracy: 62.08%\n",
            "Epoch [4/10], Training Loss: 0.785, Validation Accuracy: 62.62%\n",
            "Epoch [5/10], Training Loss: 0.757, Validation Accuracy: 62.62%\n",
            "Epoch [6/10], Training Loss: 0.732, Validation Accuracy: 62.68%\n",
            "Epoch [7/10], Training Loss: 0.715, Validation Accuracy: 62.16%\n",
            "Epoch [8/10], Training Loss: 0.704, Validation Accuracy: 62.47%\n",
            "Epoch [9/10], Training Loss: 0.680, Validation Accuracy: 61.38%\n",
            "Epoch [10/10], Training Loss: 0.666, Validation Accuracy: 62.46%\n",
            "Epoch [1/10], Training Loss: 0.901, Validation Accuracy: 62.48%\n",
            "Epoch [2/10], Training Loss: 0.840, Validation Accuracy: 62.62%\n",
            "Epoch [3/10], Training Loss: 0.804, Validation Accuracy: 61.85%\n",
            "Epoch [4/10], Training Loss: 0.769, Validation Accuracy: 62.37%\n",
            "Epoch [5/10], Training Loss: 0.742, Validation Accuracy: 62.50%\n",
            "Epoch [6/10], Training Loss: 0.716, Validation Accuracy: 61.66%\n",
            "Epoch [7/10], Training Loss: 0.698, Validation Accuracy: 62.00%\n",
            "Epoch [8/10], Training Loss: 0.691, Validation Accuracy: 62.00%\n",
            "Epoch [9/10], Training Loss: 0.671, Validation Accuracy: 61.97%\n",
            "Epoch [10/10], Training Loss: 0.653, Validation Accuracy: 61.91%\n",
            "Epoch [1/10], Training Loss: 0.933, Validation Accuracy: 59.38%\n",
            "Epoch [2/10], Training Loss: 0.844, Validation Accuracy: 62.10%\n",
            "Epoch [3/10], Training Loss: 0.795, Validation Accuracy: 62.88%\n",
            "Epoch [4/10], Training Loss: 0.767, Validation Accuracy: 61.25%\n",
            "Epoch [5/10], Training Loss: 0.751, Validation Accuracy: 62.06%\n",
            "Epoch [6/10], Training Loss: 0.720, Validation Accuracy: 62.89%\n",
            "Epoch [7/10], Training Loss: 0.691, Validation Accuracy: 62.56%\n",
            "Epoch [8/10], Training Loss: 0.679, Validation Accuracy: 62.20%\n",
            "Epoch [9/10], Training Loss: 0.664, Validation Accuracy: 61.96%\n",
            "Epoch [10/10], Training Loss: 0.640, Validation Accuracy: 61.56%\n",
            "Epoch [1/10], Training Loss: 0.920, Validation Accuracy: 62.30%\n",
            "Epoch [2/10], Training Loss: 0.841, Validation Accuracy: 61.76%\n",
            "Epoch [3/10], Training Loss: 0.784, Validation Accuracy: 62.60%\n",
            "Epoch [4/10], Training Loss: 0.744, Validation Accuracy: 62.27%\n",
            "Epoch [5/10], Training Loss: 0.725, Validation Accuracy: 62.12%\n",
            "Epoch [6/10], Training Loss: 0.705, Validation Accuracy: 62.26%\n",
            "Epoch [7/10], Training Loss: 0.676, Validation Accuracy: 62.73%\n",
            "Epoch [8/10], Training Loss: 0.657, Validation Accuracy: 62.36%\n",
            "Epoch [9/10], Training Loss: 0.637, Validation Accuracy: 62.41%\n",
            "Epoch [10/10], Training Loss: 0.626, Validation Accuracy: 60.60%\n",
            "Epoch [1/10], Training Loss: 0.914, Validation Accuracy: 62.22%\n",
            "Epoch [2/10], Training Loss: 0.819, Validation Accuracy: 61.65%\n",
            "Epoch [3/10], Training Loss: 0.782, Validation Accuracy: 62.38%\n",
            "Epoch [4/10], Training Loss: 0.744, Validation Accuracy: 62.31%\n",
            "Epoch [5/10], Training Loss: 0.723, Validation Accuracy: 60.94%\n",
            "Epoch [6/10], Training Loss: 0.696, Validation Accuracy: 62.36%\n",
            "Epoch [7/10], Training Loss: 0.672, Validation Accuracy: 61.94%\n",
            "Epoch [8/10], Training Loss: 0.651, Validation Accuracy: 61.31%\n",
            "Epoch [9/10], Training Loss: 0.636, Validation Accuracy: 62.41%\n",
            "Epoch [10/10], Training Loss: 0.613, Validation Accuracy: 62.07%\n",
            "Epoch [1/10], Training Loss: 0.879, Validation Accuracy: 62.84%\n",
            "Epoch [2/10], Training Loss: 0.779, Validation Accuracy: 62.94%\n",
            "Epoch [3/10], Training Loss: 0.739, Validation Accuracy: 62.57%\n",
            "Epoch [4/10], Training Loss: 0.707, Validation Accuracy: 62.28%\n",
            "Epoch [5/10], Training Loss: 0.673, Validation Accuracy: 62.85%\n",
            "Epoch [6/10], Training Loss: 0.647, Validation Accuracy: 62.39%\n",
            "Epoch [7/10], Training Loss: 0.624, Validation Accuracy: 62.36%\n",
            "Epoch [8/10], Training Loss: 0.616, Validation Accuracy: 61.94%\n",
            "Epoch [9/10], Training Loss: 0.587, Validation Accuracy: 61.37%\n",
            "Epoch [10/10], Training Loss: 0.568, Validation Accuracy: 61.22%\n",
            "Epoch [1/10], Training Loss: 0.845, Validation Accuracy: 62.47%\n",
            "Epoch [2/10], Training Loss: 0.778, Validation Accuracy: 62.24%\n",
            "Epoch [3/10], Training Loss: 0.722, Validation Accuracy: 62.19%\n",
            "Epoch [4/10], Training Loss: 0.689, Validation Accuracy: 62.25%\n",
            "Epoch [5/10], Training Loss: 0.660, Validation Accuracy: 61.55%\n",
            "Epoch [6/10], Training Loss: 0.640, Validation Accuracy: 62.41%\n",
            "Epoch [7/10], Training Loss: 0.607, Validation Accuracy: 62.02%\n",
            "Epoch [8/10], Training Loss: 0.583, Validation Accuracy: 61.86%\n",
            "Epoch [9/10], Training Loss: 0.568, Validation Accuracy: 61.82%\n",
            "Epoch [10/10], Training Loss: 0.543, Validation Accuracy: 62.03%\n",
            "Epoch [1/10], Training Loss: 0.866, Validation Accuracy: 61.28%\n",
            "Epoch [2/10], Training Loss: 0.772, Validation Accuracy: 62.00%\n",
            "Epoch [3/10], Training Loss: 0.725, Validation Accuracy: 62.71%\n",
            "Epoch [4/10], Training Loss: 0.674, Validation Accuracy: 62.20%\n",
            "Epoch [5/10], Training Loss: 0.655, Validation Accuracy: 62.34%\n",
            "Epoch [6/10], Training Loss: 0.624, Validation Accuracy: 61.64%\n",
            "Epoch [7/10], Training Loss: 0.606, Validation Accuracy: 62.33%\n",
            "Epoch [8/10], Training Loss: 0.578, Validation Accuracy: 61.62%\n",
            "Epoch [9/10], Training Loss: 0.555, Validation Accuracy: 61.96%\n",
            "Epoch [10/10], Training Loss: 0.535, Validation Accuracy: 61.76%\n",
            "Epoch [1/10], Training Loss: 0.867, Validation Accuracy: 61.26%\n",
            "Epoch [2/10], Training Loss: 0.764, Validation Accuracy: 61.98%\n",
            "Epoch [3/10], Training Loss: 0.715, Validation Accuracy: 61.67%\n",
            "Epoch [4/10], Training Loss: 0.669, Validation Accuracy: 62.42%\n",
            "Epoch [5/10], Training Loss: 0.646, Validation Accuracy: 62.57%\n",
            "Epoch [6/10], Training Loss: 0.609, Validation Accuracy: 62.40%\n",
            "Epoch [7/10], Training Loss: 0.592, Validation Accuracy: 62.25%\n",
            "Epoch [8/10], Training Loss: 0.571, Validation Accuracy: 61.84%\n",
            "Epoch [9/10], Training Loss: 0.544, Validation Accuracy: 61.90%\n",
            "Epoch [10/10], Training Loss: 0.532, Validation Accuracy: 62.21%\n",
            "Epoch [1/10], Training Loss: 0.889, Validation Accuracy: 61.69%\n",
            "Epoch [2/10], Training Loss: 0.766, Validation Accuracy: 61.84%\n",
            "Epoch [3/10], Training Loss: 0.714, Validation Accuracy: 62.00%\n",
            "Epoch [4/10], Training Loss: 0.681, Validation Accuracy: 62.58%\n",
            "Epoch [5/10], Training Loss: 0.637, Validation Accuracy: 61.48%\n",
            "Epoch [6/10], Training Loss: 0.607, Validation Accuracy: 62.14%\n",
            "Epoch [7/10], Training Loss: 0.578, Validation Accuracy: 62.17%\n",
            "Epoch [8/10], Training Loss: 0.555, Validation Accuracy: 62.04%\n",
            "Epoch [9/10], Training Loss: 0.549, Validation Accuracy: 61.94%\n",
            "Epoch [10/10], Training Loss: 0.519, Validation Accuracy: 61.31%\n",
            "Epoch [1/10], Training Loss: 0.824, Validation Accuracy: 61.41%\n",
            "Epoch [2/10], Training Loss: 0.720, Validation Accuracy: 62.61%\n",
            "Epoch [3/10], Training Loss: 0.661, Validation Accuracy: 62.41%\n",
            "Epoch [4/10], Training Loss: 0.622, Validation Accuracy: 62.09%\n",
            "Epoch [5/10], Training Loss: 0.594, Validation Accuracy: 62.43%\n",
            "Epoch [6/10], Training Loss: 0.566, Validation Accuracy: 62.50%\n",
            "Epoch [7/10], Training Loss: 0.539, Validation Accuracy: 62.33%\n",
            "Epoch [8/10], Training Loss: 0.515, Validation Accuracy: 62.54%\n",
            "Epoch [9/10], Training Loss: 0.498, Validation Accuracy: 62.14%\n",
            "Epoch [10/10], Training Loss: 0.474, Validation Accuracy: 62.02%\n",
            "Epoch [1/10], Training Loss: 0.813, Validation Accuracy: 62.09%\n",
            "Epoch [2/10], Training Loss: 0.704, Validation Accuracy: 62.24%\n",
            "Epoch [3/10], Training Loss: 0.650, Validation Accuracy: 61.97%\n",
            "Epoch [4/10], Training Loss: 0.615, Validation Accuracy: 61.10%\n",
            "Epoch [5/10], Training Loss: 0.582, Validation Accuracy: 61.58%\n",
            "Epoch [6/10], Training Loss: 0.544, Validation Accuracy: 62.18%\n",
            "Epoch [7/10], Training Loss: 0.527, Validation Accuracy: 61.91%\n",
            "Epoch [8/10], Training Loss: 0.495, Validation Accuracy: 62.12%\n",
            "Epoch [9/10], Training Loss: 0.479, Validation Accuracy: 62.02%\n",
            "Epoch [10/10], Training Loss: 0.456, Validation Accuracy: 61.96%\n",
            "Epoch [1/10], Training Loss: 0.833, Validation Accuracy: 60.07%\n",
            "Epoch [2/10], Training Loss: 0.709, Validation Accuracy: 62.37%\n",
            "Epoch [3/10], Training Loss: 0.641, Validation Accuracy: 62.13%\n",
            "Epoch [4/10], Training Loss: 0.593, Validation Accuracy: 62.20%\n",
            "Epoch [5/10], Training Loss: 0.564, Validation Accuracy: 62.38%\n",
            "Epoch [6/10], Training Loss: 0.542, Validation Accuracy: 62.29%\n",
            "Epoch [7/10], Training Loss: 0.509, Validation Accuracy: 62.03%\n",
            "Epoch [8/10], Training Loss: 0.480, Validation Accuracy: 62.12%\n",
            "Epoch [9/10], Training Loss: 0.463, Validation Accuracy: 61.53%\n",
            "Epoch [10/10], Training Loss: 0.442, Validation Accuracy: 61.38%\n",
            "Epoch [1/10], Training Loss: 0.836, Validation Accuracy: 61.01%\n",
            "Epoch [2/10], Training Loss: 0.711, Validation Accuracy: 61.97%\n",
            "Epoch [3/10], Training Loss: 0.638, Validation Accuracy: 61.92%\n",
            "Epoch [4/10], Training Loss: 0.592, Validation Accuracy: 61.95%\n",
            "Epoch [5/10], Training Loss: 0.567, Validation Accuracy: 61.84%\n",
            "Epoch [6/10], Training Loss: 0.525, Validation Accuracy: 61.86%\n",
            "Epoch [7/10], Training Loss: 0.495, Validation Accuracy: 62.05%\n",
            "Epoch [8/10], Training Loss: 0.483, Validation Accuracy: 61.44%\n",
            "Epoch [9/10], Training Loss: 0.458, Validation Accuracy: 61.32%\n",
            "Epoch [10/10], Training Loss: 0.433, Validation Accuracy: 61.93%\n",
            "Epoch [1/10], Training Loss: 0.831, Validation Accuracy: 61.10%\n",
            "Epoch [2/10], Training Loss: 0.693, Validation Accuracy: 61.29%\n",
            "Epoch [3/10], Training Loss: 0.638, Validation Accuracy: 61.46%\n",
            "Epoch [4/10], Training Loss: 0.594, Validation Accuracy: 62.03%\n",
            "Epoch [5/10], Training Loss: 0.555, Validation Accuracy: 61.52%\n",
            "Epoch [6/10], Training Loss: 0.523, Validation Accuracy: 61.88%\n",
            "Epoch [7/10], Training Loss: 0.494, Validation Accuracy: 61.80%\n",
            "Epoch [8/10], Training Loss: 0.472, Validation Accuracy: 60.82%\n",
            "Epoch [9/10], Training Loss: 0.462, Validation Accuracy: 61.37%\n",
            "Epoch [10/10], Training Loss: 0.432, Validation Accuracy: 60.73%\n",
            "Epoch [1/10], Training Loss: 0.810, Validation Accuracy: 61.07%\n",
            "Epoch [2/10], Training Loss: 0.676, Validation Accuracy: 61.70%\n",
            "Epoch [3/10], Training Loss: 0.604, Validation Accuracy: 61.66%\n",
            "Epoch [4/10], Training Loss: 0.551, Validation Accuracy: 62.01%\n",
            "Epoch [5/10], Training Loss: 0.510, Validation Accuracy: 62.14%\n",
            "Epoch [6/10], Training Loss: 0.484, Validation Accuracy: 62.45%\n",
            "Epoch [7/10], Training Loss: 0.456, Validation Accuracy: 62.15%\n",
            "Epoch [8/10], Training Loss: 0.428, Validation Accuracy: 62.43%\n",
            "Epoch [9/10], Training Loss: 0.404, Validation Accuracy: 61.46%\n",
            "Epoch [10/10], Training Loss: 0.385, Validation Accuracy: 62.23%\n",
            "Confusion Matrix:\n",
            "[[622  36 103  22  27  12  16  12  96  54]\n",
            " [ 21 761  25  16   4   9  14   6  39 105]\n",
            " [ 67   8 547  59  83  83  82  34  19  18]\n",
            " [ 17  23  91 430  59 197  86  49  20  28]\n",
            " [ 30   9 112  85 509  58  91  82  16   8]\n",
            " [  9   7  73 209  63 526  35  53   6  19]\n",
            " [ 10  10  71  75  40  39 730  12   6   7]\n",
            " [ 21  10  54  51  71  98  18 631   6  40]\n",
            " [ 82  58  32  14  12  10  13   5 733  41]\n",
            " [ 31 128  22  32   7  19  17  20  42 682]]\n",
            "Test Accuracy: 61.71%\n",
            "True Positives (TP): [622 761 547 430 509 526 730 631 733 682]\n",
            "False Positives (FP): [288 289 583 563 366 525 372 273 250 320]\n",
            "True Negatives (TN): [8712 8711 8417 8437 8634 8475 8628 8727 8750 8680]\n",
            "False Negatives (FN): [378 239 453 570 491 474 270 369 267 318]\n",
            ": [10000 10000 10000 10000 10000 10000 10000 10000 10000 10000]\n",
            "Precision: [0.68351648 0.7247619  0.4840708  0.43303122 0.58171429 0.50047574\n",
            " 0.66243194 0.69800885 0.7456765  0.68063872]\n",
            "Recall: [0.622 0.761 0.547 0.43  0.509 0.526 0.73  0.631 0.733 0.682]\n",
            "F1 Score: [0.6513089  0.74243902 0.51361502 0.43151029 0.54293333 0.51292053\n",
            " 0.69457659 0.66281513 0.73928391 0.68131868]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import truncnorm\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from typing import Dict, Tuple\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "import random\n",
        "\n",
        "# Define VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.x_dim = x_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2*z_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 32x32\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :self.z_dim], h[:, self.z_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "# Define VAE training procedure\n",
        "def vae_train(vae: VAE, trainloader: DataLoader, epochs: int) -> None:\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        vae.train()\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = vae(inputs)\n",
        "            loss = vae_loss(recon_x, inputs, mu, logvar)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "# Define classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "\n",
        "# Separate dataset by class\n",
        "class_indices = {i: [] for i in range(10)}  # CIFAR-10 has 10 classes\n",
        "for idx, (_, label) in enumerate(full_dataset):\n",
        "    class_indices[label].append(idx)\n",
        "\n",
        "# Define target count per class, summing to 60,000 with random distribution\n",
        "class_counts = np.random.multinomial(60000, [0.1] * 10)  # Adjust probabilities if you want specific class biases\n",
        "print(\"Random Images per Class:\", class_counts)\n",
        "\n",
        "# Sample indices based on the specified class counts\n",
        "indices = []\n",
        "for class_id, count in enumerate(class_counts):\n",
        "    # Ensure count does not exceed available images\n",
        "    count = min(count, len(class_indices[class_id]))\n",
        "    selected_indices = random.sample(class_indices[class_id], count)\n",
        "    indices.extend(selected_indices)\n",
        "\n",
        "# Create a custom CIFAR-10 dataset with the sampled indices\n",
        "custom_dataset = Subset(full_dataset, indices)\n",
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n",
        "\n",
        "# Create training and validation loaders\n",
        "trainloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "\n",
        "# Define VAE loss function\n",
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD\n",
        "\n",
        "# Define training procedure for classification model\n",
        "def train(net: nn.Module, trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / (i+1):.3f}, Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "# Define evaluation procedure\n",
        "def evaluate(net: nn.Module, testloader: DataLoader) -> Tuple[float, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    # Calculate TP, FP, TN, FN for each class\n",
        "    tp = np.diag(cm)\n",
        "    fp = cm.sum(axis=0) - tp\n",
        "    fn = cm.sum(axis=1) - tp\n",
        "    tn = cm.sum() - (fp + fn + tp)\n",
        "\n",
        "    # Calculate precision, recall, and F1 score for each class\n",
        "    precision = precision_score(all_labels, all_predictions, average=None)\n",
        "    recall = recall_score(all_labels, all_predictions, average=None)\n",
        "    f1 = f1_score(all_labels, all_predictions, average=None)\n",
        "\n",
        "    return accuracy, tp, fp, tn, fn, precision, recall, f1\n",
        "\n",
        "# Initialize clients\n",
        "def initialize_clients(trainset, transform, batch_size, num_clients):\n",
        "    clients = {}\n",
        "    for i in range(num_clients):\n",
        "        client_trainset = torch.utils.data.Subset(trainset, range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients))\n",
        "        client_trainloader = torch.utils.data.DataLoader(client_trainset, batch_size=batch_size, shuffle=True)\n",
        "        clients[f\"client_{i}\"] = client_trainloader\n",
        "    return clients\n",
        "\n",
        "def get_distribution_info(vae: VAE) -> Dict:\n",
        "    # Implement the logic to extract distribution information from the VAE\n",
        "    # This can involve computing statistics, parameters, or any other relevant information\n",
        "    # that can be used to generate augmented data\n",
        "\n",
        "    # Example implementation:\n",
        "    distribution_info = {\n",
        "\n",
        "        \"normal\": {\n",
        "            \"mean\": vae.encoder[-1].bias.data.cpu().numpy(),\n",
        "            \"std\": torch.exp(0.5 * vae.encoder[-1].weight.data).cpu().numpy()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return distribution_info\n",
        "\n",
        "def send_distribution_info(distribution_info: Dict) -> None:\n",
        "    # Implement the logic to send the distribution information to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the distribution information to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n",
        "\n",
        "def generate_augmented_data(vae: VAE, distribution_info_normal: Dict) -> torch.Tensor:\n",
        "    # Generate augmented data using both uniform and truncated uniform distributions\n",
        "\n",
        "\n",
        "\n",
        "    mean_normal = distribution_info_normal[\"mean\"]\n",
        "    std_normal = distribution_info_normal[\"std\"]\n",
        "\n",
        "    augmented_data_normal = torch.randn(64, vae.z_dim) * std_normal + mean_normal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Calculate the average of augmented data from both distributions\n",
        "    augmented_data_average =  augmented_data_normal\n",
        "\n",
        "    return augmented_data_average\n",
        "\n",
        "def federated_train(net: nn.Module, vae: VAE, trainloaders: Dict[str, DataLoader], trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    for epoch in range(epochs):\n",
        "        for client_id, client_trainloader in trainloaders.items():\n",
        "            # Train VAE on client data\n",
        "            vae_train(vae, client_trainloader, epochs=10)\n",
        "\n",
        "            # Share distribution information with global server\n",
        "            distribution_info = get_distribution_info(vae)\n",
        "            send_distribution_info(distribution_info)\n",
        "\n",
        "            # Receive distribution information from other clients\n",
        "            other_distribution_info = receive_distribution_info()\n",
        "\n",
        "            # Generate augmented data using received distribution information\n",
        "            augmented_data = generate_augmented_data(vae, other_distribution_info[\"normal\"])\n",
        "\n",
        "            # Train classification model using local, augmented, and validation data\n",
        "            train(net, client_trainloader, valloader, epochs=10)\n",
        "\n",
        "            # Send model updates to global server\n",
        "            send_model_update(client_id, net.state_dict())\n",
        "\n",
        "# Define logic to receive distribution information from global server\n",
        "def receive_distribution_info() -> Dict:\n",
        "    # Receive distribution information logic\n",
        "    distribution_info = {\n",
        "\n",
        "        \"normal\": {\n",
        "            \"mean\": np.zeros(20),  # Adjust the size based on your latent space dimension\n",
        "            \"std\": np.ones(20)\n",
        "        }\n",
        "    }\n",
        "    return distribution_info\n",
        "\n",
        "def send_model_update(client_id: str, model_update: Dict) -> None:\n",
        "    # Implement the logic to send the model update to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the model update\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the model update to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=10)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy, tp, fp, tn, fn, precision, recall, f1 = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "    print(\"True Positives (TP):\", tp)\n",
        "    print(\"False Positives (FP):\", fp)\n",
        "    print(\"True Negatives (TN):\", tn)\n",
        "    print(\"False Negatives (FN):\", fn)\n",
        "    print(\":\", fn+tn+tp+fp)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Score:\", f1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AJVQwsneKKTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb59e72-5ef0-4261-884a-4f499f18d013",
        "id": "MwGpON3mKKqs"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracies: [10.63, 10.65, 12.53, 15.01, 15.84, 16.61, 17.22, 17.73, 18.03, 18.24, 18.29, 18.64, 19.14, 20.29, 22.04, 23.48, 24.06, 24.25, 25.54, 25.73, 26.48, 27.31, 27.95, 27.97, 28.7, 29.93, 30.11, 30.36, 31.1, 31.93, 32.49, 33.43, 33.96, 34.24, 35.3, 36.12, 35.8, 36.71, 37.0, 37.5, 37.77, 38.55, 38.23, 39.57, 39.43, 40.0, 40.53, 40.64, 41.21, 41.65, 41.89, 41.41, 42.37, 42.68, 42.57, 43.18, 43.22, 43.7, 44.55, 44.1, 44.37, 45.17, 44.57, 45.02, 44.36, 44.68, 45.39, 45.88, 44.94, 46.33, 46.75, 46.79, 47.1, 46.53, 46.49, 46.99, 47.39, 46.19, 47.79, 47.39, 47.94, 47.87, 48.2, 48.09, 48.6, 48.58, 48.44, 49.38, 49.27, 48.94, 49.25, 50.23, 49.71, 50.06, 50.22, 50.55, 50.25, 50.75, 50.64, 51.1, 50.93, 49.48, 51.56, 51.36, 51.61, 51.57, 51.84, 50.76, 51.94, 52.48, 51.3, 51.24, 52.84, 52.46, 52.85, 52.53, 52.29, 52.66, 52.52, 52.7, 52.43, 53.74, 53.61, 53.54, 52.69, 53.28, 52.36, 51.92, 53.71, 54.17, 52.43, 52.7, 54.28, 54.36, 54.34, 54.22, 54.97, 54.17, 54.32, 55.15, 54.46, 55.0, 54.94, 55.22, 56.01, 54.93, 54.98, 55.47, 55.57, 56.0, 55.98, 56.21, 55.72, 56.28, 56.37, 55.9, 56.08, 55.32, 56.73, 56.45, 56.68, 57.28, 56.49, 56.33, 57.36, 55.98, 56.85, 56.79, 57.22, 56.48, 57.33, 57.68, 57.91, 57.68, 57.98, 57.94, 57.55, 57.62, 56.0, 57.69, 57.75, 58.1, 57.15, 57.99, 58.34, 58.27, 57.81, 58.32, 58.0, 57.47, 58.75, 58.98, 59.21, 58.97, 58.33, 58.78, 58.66, 58.97, 57.36, 57.88, 59.28, 58.01, 59.07, 59.23, 59.39, 59.44, 59.2, 59.21, 59.03, 59.34, 59.81, 58.81, 59.75, 59.39, 59.81, 59.56, 59.6, 59.85, 59.78, 59.5, 59.98, 59.18, 60.33, 60.49, 59.89, 59.23, 60.72, 59.97, 59.01, 60.0, 59.98, 60.24, 60.55, 60.77, 59.94, 60.14, 59.85, 58.95, 59.42, 60.84, 59.78, 60.12, 60.28, 60.79, 60.07, 60.27, 59.44, 61.15, 60.5, 60.23, 60.7, 60.94, 61.05, 60.53, 61.31, 60.56, 60.94, 60.89, 59.55, 60.91, 61.31, 61.77, 61.61, 61.15, 61.35, 60.9, 61.88, 61.71, 61.25, 61.17, 61.36, 61.74, 60.86, 61.2, 60.93, 61.64, 61.39, 61.24, 61.33, 61.02, 61.08, 61.25, 61.2, 61.89, 61.66, 61.63, 61.39, 61.56, 61.28, 61.71, 61.37, 62.03, 62.5, 62.3, 61.76, 61.54, 61.39, 61.42, 61.78, 62.17, 62.01, 62.07, 61.96, 62.36, 62.06, 60.31, 61.94, 61.65, 61.27, 61.31, 62.82, 61.88, 62.51, 61.77, 61.87, 62.11, 62.11, 62.24, 61.71, 61.55, 61.15, 61.98, 62.19, 61.46, 61.92, 62.14, 61.97, 62.4, 61.76, 61.65, 61.02, 62.18, 62.01, 61.51, 61.93, 62.08, 61.96, 62.61, 62.16, 62.02, 62.14, 62.81, 62.08, 62.62, 62.62, 62.68, 62.16, 62.47, 61.38, 62.46, 62.48, 62.62, 61.85, 62.37, 62.5, 61.66, 62.0, 62.0, 61.97, 61.91, 59.38, 62.1, 62.88, 61.25, 62.06, 62.89, 62.56, 62.2, 61.96, 61.56, 62.3, 61.76, 62.6, 62.27, 62.12, 62.26, 62.73, 62.36, 62.41, 60.6, 62.22, 61.65, 62.38, 62.31, 60.94, 62.36, 61.94, 61.31, 62.41, 62.07, 62.84, 62.94, 62.57, 62.28, 62.85, 62.39, 62.36, 61.94, 61.37, 61.22, 62.47, 62.24, 62.19, 62.25, 61.55, 62.41, 62.02, 61.86, 61.82, 62.03, 61.28, 62.0, 62.71, 62.2, 62.34, 61.64, 62.33, 61.62, 61.96, 61.76, 61.26, 61.98, 61.67, 62.42, 62.57, 62.4, 62.25, 61.84, 61.9, 62.21, 61.69, 61.84, 62.0, 62.58, 61.48, 62.14, 62.17, 62.04, 61.94, 61.31, 61.41, 62.61, 62.41, 62.09, 62.43, 62.5, 62.33, 62.54, 62.14, 62.02, 62.09, 62.24, 61.97, 61.1, 61.58, 62.18, 61.91, 62.12, 62.02, 61.96, 60.07, 62.37, 62.13, 62.2, 62.38, 62.29, 62.03, 62.12, 61.53, 61.38, 61.01, 61.97, 61.92, 61.95, 61.84, 61.86, 62.05, 61.44, 61.32, 61.93, 61.1, 61.29, 61.46, 62.03, 61.52, 61.88, 61.8, 60.82, 61.37, 60.73, 61.07, 61.7, 61.66, 62.01, 62.14, 62.45, 62.15, 62.43, 61.46, 62.23]\n",
            "Size of array: 500\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# Your provided text\n",
        "log = \"\"\"\n",
        "Epoch [1/10], Training Loss: 2.304, Validation Accuracy: 10.63%\n",
        "Epoch [2/10], Training Loss: 2.303, Validation Accuracy: 10.65%\n",
        "Epoch [3/10], Training Loss: 2.301, Validation Accuracy: 12.53%\n",
        "Epoch [4/10], Training Loss: 2.300, Validation Accuracy: 15.01%\n",
        "Epoch [5/10], Training Loss: 2.298, Validation Accuracy: 15.84%\n",
        "Epoch [6/10], Training Loss: 2.296, Validation Accuracy: 16.61%\n",
        "Epoch [7/10], Training Loss: 2.292, Validation Accuracy: 17.22%\n",
        "Epoch [8/10], Training Loss: 2.288, Validation Accuracy: 17.73%\n",
        "Epoch [9/10], Training Loss: 2.281, Validation Accuracy: 18.03%\n",
        "Epoch [10/10], Training Loss: 2.271, Validation Accuracy: 18.24%\n",
        "Epoch [1/10], Training Loss: 2.256, Validation Accuracy: 18.29%\n",
        "Epoch [2/10], Training Loss: 2.232, Validation Accuracy: 18.64%\n",
        "Epoch [3/10], Training Loss: 2.199, Validation Accuracy: 19.14%\n",
        "Epoch [4/10], Training Loss: 2.165, Validation Accuracy: 20.29%\n",
        "Epoch [5/10], Training Loss: 2.134, Validation Accuracy: 22.04%\n",
        "Epoch [6/10], Training Loss: 2.106, Validation Accuracy: 23.48%\n",
        "Epoch [7/10], Training Loss: 2.081, Validation Accuracy: 24.06%\n",
        "Epoch [8/10], Training Loss: 2.058, Validation Accuracy: 24.25%\n",
        "Epoch [9/10], Training Loss: 2.040, Validation Accuracy: 25.54%\n",
        "Epoch [10/10], Training Loss: 2.025, Validation Accuracy: 25.73%\n",
        "Epoch [1/10], Training Loss: 2.022, Validation Accuracy: 26.48%\n",
        "Epoch [2/10], Training Loss: 2.008, Validation Accuracy: 27.31%\n",
        "Epoch [3/10], Training Loss: 1.993, Validation Accuracy: 27.95%\n",
        "Epoch [4/10], Training Loss: 1.981, Validation Accuracy: 27.97%\n",
        "Epoch [5/10], Training Loss: 1.968, Validation Accuracy: 28.70%\n",
        "Epoch [6/10], Training Loss: 1.955, Validation Accuracy: 29.93%\n",
        "Epoch [7/10], Training Loss: 1.942, Validation Accuracy: 30.11%\n",
        "Epoch [8/10], Training Loss: 1.930, Validation Accuracy: 30.36%\n",
        "Epoch [9/10], Training Loss: 1.915, Validation Accuracy: 31.10%\n",
        "Epoch [10/10], Training Loss: 1.901, Validation Accuracy: 31.93%\n",
        "Epoch [1/10], Training Loss: 1.876, Validation Accuracy: 32.49%\n",
        "Epoch [2/10], Training Loss: 1.856, Validation Accuracy: 33.43%\n",
        "Epoch [3/10], Training Loss: 1.841, Validation Accuracy: 33.96%\n",
        "Epoch [4/10], Training Loss: 1.819, Validation Accuracy: 34.24%\n",
        "Epoch [5/10], Training Loss: 1.800, Validation Accuracy: 35.30%\n",
        "Epoch [6/10], Training Loss: 1.779, Validation Accuracy: 36.12%\n",
        "Epoch [7/10], Training Loss: 1.759, Validation Accuracy: 35.80%\n",
        "Epoch [8/10], Training Loss: 1.738, Validation Accuracy: 36.71%\n",
        "Epoch [9/10], Training Loss: 1.720, Validation Accuracy: 37.00%\n",
        "Epoch [10/10], Training Loss: 1.701, Validation Accuracy: 37.50%\n",
        "Epoch [1/10], Training Loss: 1.710, Validation Accuracy: 37.77%\n",
        "Epoch [2/10], Training Loss: 1.693, Validation Accuracy: 38.55%\n",
        "Epoch [3/10], Training Loss: 1.676, Validation Accuracy: 38.23%\n",
        "Epoch [4/10], Training Loss: 1.663, Validation Accuracy: 39.57%\n",
        "Epoch [5/10], Training Loss: 1.651, Validation Accuracy: 39.43%\n",
        "Epoch [6/10], Training Loss: 1.638, Validation Accuracy: 40.00%\n",
        "Epoch [7/10], Training Loss: 1.626, Validation Accuracy: 40.53%\n",
        "Epoch [8/10], Training Loss: 1.619, Validation Accuracy: 40.64%\n",
        "Epoch [9/10], Training Loss: 1.609, Validation Accuracy: 41.21%\n",
        "Epoch [10/10], Training Loss: 1.594, Validation Accuracy: 41.65%\n",
        "Epoch [1/10], Training Loss: 1.632, Validation Accuracy: 41.89%\n",
        "Epoch [2/10], Training Loss: 1.619, Validation Accuracy: 41.41%\n",
        "Epoch [3/10], Training Loss: 1.600, Validation Accuracy: 42.37%\n",
        "Epoch [4/10], Training Loss: 1.598, Validation Accuracy: 42.68%\n",
        "Epoch [5/10], Training Loss: 1.588, Validation Accuracy: 42.57%\n",
        "Epoch [6/10], Training Loss: 1.572, Validation Accuracy: 43.18%\n",
        "Epoch [7/10], Training Loss: 1.568, Validation Accuracy: 43.22%\n",
        "Epoch [8/10], Training Loss: 1.559, Validation Accuracy: 43.70%\n",
        "Epoch [9/10], Training Loss: 1.548, Validation Accuracy: 44.55%\n",
        "Epoch [10/10], Training Loss: 1.545, Validation Accuracy: 44.10%\n",
        "Epoch [1/10], Training Loss: 1.560, Validation Accuracy: 44.37%\n",
        "Epoch [2/10], Training Loss: 1.543, Validation Accuracy: 45.17%\n",
        "Epoch [3/10], Training Loss: 1.537, Validation Accuracy: 44.57%\n",
        "Epoch [4/10], Training Loss: 1.524, Validation Accuracy: 45.02%\n",
        "Epoch [5/10], Training Loss: 1.515, Validation Accuracy: 44.36%\n",
        "Epoch [6/10], Training Loss: 1.507, Validation Accuracy: 44.68%\n",
        "Epoch [7/10], Training Loss: 1.496, Validation Accuracy: 45.39%\n",
        "Epoch [8/10], Training Loss: 1.491, Validation Accuracy: 45.88%\n",
        "Epoch [9/10], Training Loss: 1.489, Validation Accuracy: 44.94%\n",
        "Epoch [10/10], Training Loss: 1.482, Validation Accuracy: 46.33%\n",
        "Epoch [1/10], Training Loss: 1.499, Validation Accuracy: 46.75%\n",
        "Epoch [2/10], Training Loss: 1.488, Validation Accuracy: 46.79%\n",
        "Epoch [3/10], Training Loss: 1.476, Validation Accuracy: 47.10%\n",
        "Epoch [4/10], Training Loss: 1.470, Validation Accuracy: 46.53%\n",
        "Epoch [5/10], Training Loss: 1.455, Validation Accuracy: 46.49%\n",
        "Epoch [6/10], Training Loss: 1.451, Validation Accuracy: 46.99%\n",
        "Epoch [7/10], Training Loss: 1.443, Validation Accuracy: 47.39%\n",
        "Epoch [8/10], Training Loss: 1.430, Validation Accuracy: 46.19%\n",
        "Epoch [9/10], Training Loss: 1.436, Validation Accuracy: 47.79%\n",
        "Epoch [10/10], Training Loss: 1.419, Validation Accuracy: 47.39%\n",
        "Epoch [1/10], Training Loss: 1.451, Validation Accuracy: 47.94%\n",
        "Epoch [2/10], Training Loss: 1.437, Validation Accuracy: 47.87%\n",
        "Epoch [3/10], Training Loss: 1.425, Validation Accuracy: 48.20%\n",
        "Epoch [4/10], Training Loss: 1.422, Validation Accuracy: 48.09%\n",
        "Epoch [5/10], Training Loss: 1.404, Validation Accuracy: 48.60%\n",
        "Epoch [6/10], Training Loss: 1.395, Validation Accuracy: 48.58%\n",
        "Epoch [7/10], Training Loss: 1.391, Validation Accuracy: 48.44%\n",
        "Epoch [8/10], Training Loss: 1.380, Validation Accuracy: 49.38%\n",
        "Epoch [9/10], Training Loss: 1.379, Validation Accuracy: 49.27%\n",
        "Epoch [10/10], Training Loss: 1.372, Validation Accuracy: 48.94%\n",
        "Epoch [1/10], Training Loss: 1.403, Validation Accuracy: 49.25%\n",
        "Epoch [2/10], Training Loss: 1.378, Validation Accuracy: 50.23%\n",
        "Epoch [3/10], Training Loss: 1.367, Validation Accuracy: 49.71%\n",
        "Epoch [4/10], Training Loss: 1.359, Validation Accuracy: 50.06%\n",
        "Epoch [5/10], Training Loss: 1.355, Validation Accuracy: 50.22%\n",
        "Epoch [6/10], Training Loss: 1.342, Validation Accuracy: 50.55%\n",
        "Epoch [7/10], Training Loss: 1.336, Validation Accuracy: 50.25%\n",
        "Epoch [8/10], Training Loss: 1.325, Validation Accuracy: 50.75%\n",
        "Epoch [9/10], Training Loss: 1.315, Validation Accuracy: 50.64%\n",
        "Epoch [10/10], Training Loss: 1.309, Validation Accuracy: 51.10%\n",
        "Epoch [1/10], Training Loss: 1.387, Validation Accuracy: 50.93%\n",
        "Epoch [2/10], Training Loss: 1.370, Validation Accuracy: 49.48%\n",
        "Epoch [3/10], Training Loss: 1.366, Validation Accuracy: 51.56%\n",
        "Epoch [4/10], Training Loss: 1.344, Validation Accuracy: 51.36%\n",
        "Epoch [5/10], Training Loss: 1.336, Validation Accuracy: 51.61%\n",
        "Epoch [6/10], Training Loss: 1.326, Validation Accuracy: 51.57%\n",
        "Epoch [7/10], Training Loss: 1.318, Validation Accuracy: 51.84%\n",
        "Epoch [8/10], Training Loss: 1.306, Validation Accuracy: 50.76%\n",
        "Epoch [9/10], Training Loss: 1.306, Validation Accuracy: 51.94%\n",
        "Epoch [10/10], Training Loss: 1.298, Validation Accuracy: 52.48%\n",
        "Epoch [1/10], Training Loss: 1.349, Validation Accuracy: 51.30%\n",
        "Epoch [2/10], Training Loss: 1.335, Validation Accuracy: 51.24%\n",
        "Epoch [3/10], Training Loss: 1.315, Validation Accuracy: 52.84%\n",
        "Epoch [4/10], Training Loss: 1.308, Validation Accuracy: 52.46%\n",
        "Epoch [5/10], Training Loss: 1.302, Validation Accuracy: 52.85%\n",
        "Epoch [6/10], Training Loss: 1.287, Validation Accuracy: 52.53%\n",
        "Epoch [7/10], Training Loss: 1.283, Validation Accuracy: 52.29%\n",
        "Epoch [8/10], Training Loss: 1.274, Validation Accuracy: 52.66%\n",
        "Epoch [9/10], Training Loss: 1.262, Validation Accuracy: 52.52%\n",
        "Epoch [10/10], Training Loss: 1.254, Validation Accuracy: 52.70%\n",
        "Epoch [1/10], Training Loss: 1.310, Validation Accuracy: 52.43%\n",
        "Epoch [2/10], Training Loss: 1.289, Validation Accuracy: 53.74%\n",
        "Epoch [3/10], Training Loss: 1.274, Validation Accuracy: 53.61%\n",
        "Epoch [4/10], Training Loss: 1.257, Validation Accuracy: 53.54%\n",
        "Epoch [5/10], Training Loss: 1.251, Validation Accuracy: 52.69%\n",
        "Epoch [6/10], Training Loss: 1.249, Validation Accuracy: 53.28%\n",
        "Epoch [7/10], Training Loss: 1.230, Validation Accuracy: 52.36%\n",
        "Epoch [8/10], Training Loss: 1.229, Validation Accuracy: 51.92%\n",
        "Epoch [9/10], Training Loss: 1.222, Validation Accuracy: 53.71%\n",
        "Epoch [10/10], Training Loss: 1.207, Validation Accuracy: 54.17%\n",
        "Epoch [1/10], Training Loss: 1.285, Validation Accuracy: 52.43%\n",
        "Epoch [2/10], Training Loss: 1.265, Validation Accuracy: 52.70%\n",
        "Epoch [3/10], Training Loss: 1.246, Validation Accuracy: 54.28%\n",
        "Epoch [4/10], Training Loss: 1.238, Validation Accuracy: 54.36%\n",
        "Epoch [5/10], Training Loss: 1.222, Validation Accuracy: 54.34%\n",
        "Epoch [6/10], Training Loss: 1.213, Validation Accuracy: 54.22%\n",
        "Epoch [7/10], Training Loss: 1.215, Validation Accuracy: 54.97%\n",
        "Epoch [8/10], Training Loss: 1.196, Validation Accuracy: 54.17%\n",
        "Epoch [9/10], Training Loss: 1.194, Validation Accuracy: 54.32%\n",
        "Epoch [10/10], Training Loss: 1.184, Validation Accuracy: 55.15%\n",
        "Epoch [1/10], Training Loss: 1.227, Validation Accuracy: 54.46%\n",
        "Epoch [2/10], Training Loss: 1.207, Validation Accuracy: 55.00%\n",
        "Epoch [3/10], Training Loss: 1.190, Validation Accuracy: 54.94%\n",
        "Epoch [4/10], Training Loss: 1.180, Validation Accuracy: 55.22%\n",
        "Epoch [5/10], Training Loss: 1.171, Validation Accuracy: 56.01%\n",
        "Epoch [6/10], Training Loss: 1.169, Validation Accuracy: 54.93%\n",
        "Epoch [7/10], Training Loss: 1.164, Validation Accuracy: 54.98%\n",
        "Epoch [8/10], Training Loss: 1.143, Validation Accuracy: 55.47%\n",
        "Epoch [9/10], Training Loss: 1.132, Validation Accuracy: 55.57%\n",
        "Epoch [10/10], Training Loss: 1.128, Validation Accuracy: 56.00%\n",
        "Epoch [1/10], Training Loss: 1.228, Validation Accuracy: 55.98%\n",
        "Epoch [2/10], Training Loss: 1.197, Validation Accuracy: 56.21%\n",
        "Epoch [3/10], Training Loss: 1.180, Validation Accuracy: 55.72%\n",
        "Epoch [4/10], Training Loss: 1.172, Validation Accuracy: 56.28%\n",
        "Epoch [5/10], Training Loss: 1.164, Validation Accuracy: 56.37%\n",
        "Epoch [6/10], Training Loss: 1.152, Validation Accuracy: 55.90%\n",
        "Epoch [7/10], Training Loss: 1.142, Validation Accuracy: 56.08%\n",
        "Epoch [8/10], Training Loss: 1.138, Validation Accuracy: 55.32%\n",
        "Epoch [9/10], Training Loss: 1.124, Validation Accuracy: 56.73%\n",
        "Epoch [10/10], Training Loss: 1.115, Validation Accuracy: 56.45%\n",
        "Epoch [1/10], Training Loss: 1.209, Validation Accuracy: 56.68%\n",
        "Epoch [2/10], Training Loss: 1.187, Validation Accuracy: 57.28%\n",
        "Epoch [3/10], Training Loss: 1.171, Validation Accuracy: 56.49%\n",
        "Epoch [4/10], Training Loss: 1.173, Validation Accuracy: 56.33%\n",
        "Epoch [5/10], Training Loss: 1.148, Validation Accuracy: 57.36%\n",
        "Epoch [6/10], Training Loss: 1.133, Validation Accuracy: 55.98%\n",
        "Epoch [7/10], Training Loss: 1.129, Validation Accuracy: 56.85%\n",
        "Epoch [8/10], Training Loss: 1.114, Validation Accuracy: 56.79%\n",
        "Epoch [9/10], Training Loss: 1.100, Validation Accuracy: 57.22%\n",
        "Epoch [10/10], Training Loss: 1.102, Validation Accuracy: 56.48%\n",
        "Epoch [1/10], Training Loss: 1.182, Validation Accuracy: 57.33%\n",
        "Epoch [2/10], Training Loss: 1.151, Validation Accuracy: 57.68%\n",
        "Epoch [3/10], Training Loss: 1.137, Validation Accuracy: 57.91%\n",
        "Epoch [4/10], Training Loss: 1.119, Validation Accuracy: 57.68%\n",
        "Epoch [5/10], Training Loss: 1.107, Validation Accuracy: 57.98%\n",
        "Epoch [6/10], Training Loss: 1.094, Validation Accuracy: 57.94%\n",
        "Epoch [7/10], Training Loss: 1.084, Validation Accuracy: 57.55%\n",
        "Epoch [8/10], Training Loss: 1.076, Validation Accuracy: 57.62%\n",
        "Epoch [9/10], Training Loss: 1.073, Validation Accuracy: 56.00%\n",
        "Epoch [10/10], Training Loss: 1.073, Validation Accuracy: 57.69%\n",
        "Epoch [1/10], Training Loss: 1.169, Validation Accuracy: 57.75%\n",
        "Epoch [2/10], Training Loss: 1.141, Validation Accuracy: 58.10%\n",
        "Epoch [3/10], Training Loss: 1.116, Validation Accuracy: 57.15%\n",
        "Epoch [4/10], Training Loss: 1.107, Validation Accuracy: 57.99%\n",
        "Epoch [5/10], Training Loss: 1.096, Validation Accuracy: 58.34%\n",
        "Epoch [6/10], Training Loss: 1.083, Validation Accuracy: 58.27%\n",
        "Epoch [7/10], Training Loss: 1.067, Validation Accuracy: 57.81%\n",
        "Epoch [8/10], Training Loss: 1.059, Validation Accuracy: 58.32%\n",
        "Epoch [9/10], Training Loss: 1.054, Validation Accuracy: 58.00%\n",
        "Epoch [10/10], Training Loss: 1.044, Validation Accuracy: 57.47%\n",
        "Epoch [1/10], Training Loss: 1.115, Validation Accuracy: 58.75%\n",
        "Epoch [2/10], Training Loss: 1.086, Validation Accuracy: 58.98%\n",
        "Epoch [3/10], Training Loss: 1.071, Validation Accuracy: 59.21%\n",
        "Epoch [4/10], Training Loss: 1.056, Validation Accuracy: 58.97%\n",
        "Epoch [5/10], Training Loss: 1.042, Validation Accuracy: 58.33%\n",
        "Epoch [6/10], Training Loss: 1.032, Validation Accuracy: 58.78%\n",
        "Epoch [7/10], Training Loss: 1.019, Validation Accuracy: 58.66%\n",
        "Epoch [8/10], Training Loss: 1.006, Validation Accuracy: 58.97%\n",
        "Epoch [9/10], Training Loss: 1.000, Validation Accuracy: 57.36%\n",
        "Epoch [10/10], Training Loss: 0.998, Validation Accuracy: 57.88%\n",
        "Epoch [1/10], Training Loss: 1.117, Validation Accuracy: 59.28%\n",
        "Epoch [2/10], Training Loss: 1.080, Validation Accuracy: 58.01%\n",
        "Epoch [3/10], Training Loss: 1.074, Validation Accuracy: 59.07%\n",
        "Epoch [4/10], Training Loss: 1.048, Validation Accuracy: 59.23%\n",
        "Epoch [5/10], Training Loss: 1.033, Validation Accuracy: 59.39%\n",
        "Epoch [6/10], Training Loss: 1.016, Validation Accuracy: 59.44%\n",
        "Epoch [7/10], Training Loss: 1.011, Validation Accuracy: 59.20%\n",
        "Epoch [8/10], Training Loss: 0.994, Validation Accuracy: 59.21%\n",
        "Epoch [9/10], Training Loss: 0.981, Validation Accuracy: 59.03%\n",
        "Epoch [10/10], Training Loss: 0.979, Validation Accuracy: 59.34%\n",
        "Epoch [1/10], Training Loss: 1.119, Validation Accuracy: 59.81%\n",
        "Epoch [2/10], Training Loss: 1.079, Validation Accuracy: 58.81%\n",
        "Epoch [3/10], Training Loss: 1.061, Validation Accuracy: 59.75%\n",
        "Epoch [4/10], Training Loss: 1.045, Validation Accuracy: 59.39%\n",
        "Epoch [5/10], Training Loss: 1.027, Validation Accuracy: 59.81%\n",
        "Epoch [6/10], Training Loss: 1.024, Validation Accuracy: 59.56%\n",
        "Epoch [7/10], Training Loss: 1.004, Validation Accuracy: 59.60%\n",
        "Epoch [8/10], Training Loss: 0.987, Validation Accuracy: 59.85%\n",
        "Epoch [9/10], Training Loss: 0.985, Validation Accuracy: 59.78%\n",
        "Epoch [10/10], Training Loss: 0.963, Validation Accuracy: 59.50%\n",
        "Epoch [1/10], Training Loss: 1.086, Validation Accuracy: 59.98%\n",
        "Epoch [2/10], Training Loss: 1.050, Validation Accuracy: 59.18%\n",
        "Epoch [3/10], Training Loss: 1.031, Validation Accuracy: 60.33%\n",
        "Epoch [4/10], Training Loss: 1.018, Validation Accuracy: 60.49%\n",
        "Epoch [5/10], Training Loss: 0.994, Validation Accuracy: 59.89%\n",
        "Epoch [6/10], Training Loss: 0.982, Validation Accuracy: 59.23%\n",
        "Epoch [7/10], Training Loss: 0.970, Validation Accuracy: 60.72%\n",
        "Epoch [8/10], Training Loss: 0.954, Validation Accuracy: 59.97%\n",
        "Epoch [9/10], Training Loss: 0.941, Validation Accuracy: 59.01%\n",
        "Epoch [10/10], Training Loss: 0.927, Validation Accuracy: 60.00%\n",
        "Epoch [1/10], Training Loss: 1.080, Validation Accuracy: 59.98%\n",
        "Epoch [2/10], Training Loss: 1.044, Validation Accuracy: 60.24%\n",
        "Epoch [3/10], Training Loss: 1.019, Validation Accuracy: 60.55%\n",
        "Epoch [4/10], Training Loss: 0.989, Validation Accuracy: 60.77%\n",
        "Epoch [5/10], Training Loss: 0.982, Validation Accuracy: 59.94%\n",
        "Epoch [6/10], Training Loss: 0.968, Validation Accuracy: 60.14%\n",
        "Epoch [7/10], Training Loss: 0.961, Validation Accuracy: 59.85%\n",
        "Epoch [8/10], Training Loss: 0.946, Validation Accuracy: 58.95%\n",
        "Epoch [9/10], Training Loss: 0.927, Validation Accuracy: 59.42%\n",
        "Epoch [10/10], Training Loss: 0.916, Validation Accuracy: 60.84%\n",
        "Epoch [1/10], Training Loss: 1.042, Validation Accuracy: 59.78%\n",
        "Epoch [2/10], Training Loss: 0.999, Validation Accuracy: 60.12%\n",
        "Epoch [3/10], Training Loss: 0.979, Validation Accuracy: 60.28%\n",
        "Epoch [4/10], Training Loss: 0.954, Validation Accuracy: 60.79%\n",
        "Epoch [5/10], Training Loss: 0.940, Validation Accuracy: 60.07%\n",
        "Epoch [6/10], Training Loss: 0.926, Validation Accuracy: 60.27%\n",
        "Epoch [7/10], Training Loss: 0.913, Validation Accuracy: 59.44%\n",
        "Epoch [8/10], Training Loss: 0.897, Validation Accuracy: 61.15%\n",
        "Epoch [9/10], Training Loss: 0.877, Validation Accuracy: 60.50%\n",
        "Epoch [10/10], Training Loss: 0.876, Validation Accuracy: 60.23%\n",
        "Epoch [1/10], Training Loss: 1.040, Validation Accuracy: 60.70%\n",
        "Epoch [2/10], Training Loss: 0.994, Validation Accuracy: 60.94%\n",
        "Epoch [3/10], Training Loss: 0.972, Validation Accuracy: 61.05%\n",
        "Epoch [4/10], Training Loss: 0.947, Validation Accuracy: 60.53%\n",
        "Epoch [5/10], Training Loss: 0.932, Validation Accuracy: 61.31%\n",
        "Epoch [6/10], Training Loss: 0.914, Validation Accuracy: 60.56%\n",
        "Epoch [7/10], Training Loss: 0.899, Validation Accuracy: 60.94%\n",
        "Epoch [8/10], Training Loss: 0.882, Validation Accuracy: 60.89%\n",
        "Epoch [9/10], Training Loss: 0.873, Validation Accuracy: 59.55%\n",
        "Epoch [10/10], Training Loss: 0.869, Validation Accuracy: 60.91%\n",
        "Epoch [1/10], Training Loss: 1.046, Validation Accuracy: 61.31%\n",
        "Epoch [2/10], Training Loss: 1.004, Validation Accuracy: 61.77%\n",
        "Epoch [3/10], Training Loss: 0.975, Validation Accuracy: 61.61%\n",
        "Epoch [4/10], Training Loss: 0.950, Validation Accuracy: 61.15%\n",
        "Epoch [5/10], Training Loss: 0.922, Validation Accuracy: 61.35%\n",
        "Epoch [6/10], Training Loss: 0.912, Validation Accuracy: 60.90%\n",
        "Epoch [7/10], Training Loss: 0.894, Validation Accuracy: 61.88%\n",
        "Epoch [8/10], Training Loss: 0.874, Validation Accuracy: 61.71%\n",
        "Epoch [9/10], Training Loss: 0.865, Validation Accuracy: 61.25%\n",
        "Epoch [10/10], Training Loss: 0.846, Validation Accuracy: 61.17%\n",
        "Epoch [1/10], Training Loss: 1.026, Validation Accuracy: 61.36%\n",
        "Epoch [2/10], Training Loss: 0.974, Validation Accuracy: 61.74%\n",
        "Epoch [3/10], Training Loss: 0.930, Validation Accuracy: 60.86%\n",
        "Epoch [4/10], Training Loss: 0.913, Validation Accuracy: 61.20%\n",
        "Epoch [5/10], Training Loss: 0.907, Validation Accuracy: 60.93%\n",
        "Epoch [6/10], Training Loss: 0.882, Validation Accuracy: 61.64%\n",
        "Epoch [7/10], Training Loss: 0.873, Validation Accuracy: 61.39%\n",
        "Epoch [8/10], Training Loss: 0.849, Validation Accuracy: 61.24%\n",
        "Epoch [9/10], Training Loss: 0.828, Validation Accuracy: 61.33%\n",
        "Epoch [10/10], Training Loss: 0.817, Validation Accuracy: 61.02%\n",
        "Epoch [1/10], Training Loss: 1.018, Validation Accuracy: 61.08%\n",
        "Epoch [2/10], Training Loss: 0.961, Validation Accuracy: 61.25%\n",
        "Epoch [3/10], Training Loss: 0.934, Validation Accuracy: 61.20%\n",
        "Epoch [4/10], Training Loss: 0.913, Validation Accuracy: 61.89%\n",
        "Epoch [5/10], Training Loss: 0.881, Validation Accuracy: 61.66%\n",
        "Epoch [6/10], Training Loss: 0.869, Validation Accuracy: 61.63%\n",
        "Epoch [7/10], Training Loss: 0.852, Validation Accuracy: 61.39%\n",
        "Epoch [8/10], Training Loss: 0.838, Validation Accuracy: 61.56%\n",
        "Epoch [9/10], Training Loss: 0.831, Validation Accuracy: 61.28%\n",
        "Epoch [10/10], Training Loss: 0.809, Validation Accuracy: 61.71%\n",
        "Epoch [1/10], Training Loss: 0.975, Validation Accuracy: 61.37%\n",
        "Epoch [2/10], Training Loss: 0.933, Validation Accuracy: 62.03%\n",
        "Epoch [3/10], Training Loss: 0.893, Validation Accuracy: 62.50%\n",
        "Epoch [4/10], Training Loss: 0.861, Validation Accuracy: 62.30%\n",
        "Epoch [5/10], Training Loss: 0.846, Validation Accuracy: 61.76%\n",
        "Epoch [6/10], Training Loss: 0.824, Validation Accuracy: 61.54%\n",
        "Epoch [7/10], Training Loss: 0.813, Validation Accuracy: 61.39%\n",
        "Epoch [8/10], Training Loss: 0.797, Validation Accuracy: 61.42%\n",
        "Epoch [9/10], Training Loss: 0.779, Validation Accuracy: 61.78%\n",
        "Epoch [10/10], Training Loss: 0.772, Validation Accuracy: 62.17%\n",
        "Epoch [1/10], Training Loss: 0.962, Validation Accuracy: 62.01%\n",
        "Epoch [2/10], Training Loss: 0.909, Validation Accuracy: 62.07%\n",
        "Epoch [3/10], Training Loss: 0.881, Validation Accuracy: 61.96%\n",
        "Epoch [4/10], Training Loss: 0.852, Validation Accuracy: 62.36%\n",
        "Epoch [5/10], Training Loss: 0.830, Validation Accuracy: 62.06%\n",
        "Epoch [6/10], Training Loss: 0.814, Validation Accuracy: 60.31%\n",
        "Epoch [7/10], Training Loss: 0.802, Validation Accuracy: 61.94%\n",
        "Epoch [8/10], Training Loss: 0.783, Validation Accuracy: 61.65%\n",
        "Epoch [9/10], Training Loss: 0.760, Validation Accuracy: 61.27%\n",
        "Epoch [10/10], Training Loss: 0.761, Validation Accuracy: 61.31%\n",
        "Epoch [1/10], Training Loss: 0.984, Validation Accuracy: 62.82%\n",
        "Epoch [2/10], Training Loss: 0.913, Validation Accuracy: 61.88%\n",
        "Epoch [3/10], Training Loss: 0.875, Validation Accuracy: 62.51%\n",
        "Epoch [4/10], Training Loss: 0.856, Validation Accuracy: 61.77%\n",
        "Epoch [5/10], Training Loss: 0.833, Validation Accuracy: 61.87%\n",
        "Epoch [6/10], Training Loss: 0.806, Validation Accuracy: 62.11%\n",
        "Epoch [7/10], Training Loss: 0.794, Validation Accuracy: 62.11%\n",
        "Epoch [8/10], Training Loss: 0.777, Validation Accuracy: 62.24%\n",
        "Epoch [9/10], Training Loss: 0.761, Validation Accuracy: 61.71%\n",
        "Epoch [10/10], Training Loss: 0.747, Validation Accuracy: 61.55%\n",
        "Epoch [1/10], Training Loss: 0.964, Validation Accuracy: 61.15%\n",
        "Epoch [2/10], Training Loss: 0.900, Validation Accuracy: 61.98%\n",
        "Epoch [3/10], Training Loss: 0.868, Validation Accuracy: 62.19%\n",
        "Epoch [4/10], Training Loss: 0.830, Validation Accuracy: 61.46%\n",
        "Epoch [5/10], Training Loss: 0.801, Validation Accuracy: 61.92%\n",
        "Epoch [6/10], Training Loss: 0.780, Validation Accuracy: 62.14%\n",
        "Epoch [7/10], Training Loss: 0.771, Validation Accuracy: 61.97%\n",
        "Epoch [8/10], Training Loss: 0.757, Validation Accuracy: 62.40%\n",
        "Epoch [9/10], Training Loss: 0.733, Validation Accuracy: 61.76%\n",
        "Epoch [10/10], Training Loss: 0.728, Validation Accuracy: 61.65%\n",
        "Epoch [1/10], Training Loss: 0.957, Validation Accuracy: 61.02%\n",
        "Epoch [2/10], Training Loss: 0.894, Validation Accuracy: 62.18%\n",
        "Epoch [3/10], Training Loss: 0.851, Validation Accuracy: 62.01%\n",
        "Epoch [4/10], Training Loss: 0.836, Validation Accuracy: 61.51%\n",
        "Epoch [5/10], Training Loss: 0.803, Validation Accuracy: 61.93%\n",
        "Epoch [6/10], Training Loss: 0.778, Validation Accuracy: 62.08%\n",
        "Epoch [7/10], Training Loss: 0.764, Validation Accuracy: 61.96%\n",
        "Epoch [8/10], Training Loss: 0.748, Validation Accuracy: 62.61%\n",
        "Epoch [9/10], Training Loss: 0.732, Validation Accuracy: 62.16%\n",
        "Epoch [10/10], Training Loss: 0.716, Validation Accuracy: 62.02%\n",
        "Epoch [1/10], Training Loss: 0.926, Validation Accuracy: 62.14%\n",
        "Epoch [2/10], Training Loss: 0.853, Validation Accuracy: 62.81%\n",
        "Epoch [3/10], Training Loss: 0.821, Validation Accuracy: 62.08%\n",
        "Epoch [4/10], Training Loss: 0.785, Validation Accuracy: 62.62%\n",
        "Epoch [5/10], Training Loss: 0.757, Validation Accuracy: 62.62%\n",
        "Epoch [6/10], Training Loss: 0.732, Validation Accuracy: 62.68%\n",
        "Epoch [7/10], Training Loss: 0.715, Validation Accuracy: 62.16%\n",
        "Epoch [8/10], Training Loss: 0.704, Validation Accuracy: 62.47%\n",
        "Epoch [9/10], Training Loss: 0.680, Validation Accuracy: 61.38%\n",
        "Epoch [10/10], Training Loss: 0.666, Validation Accuracy: 62.46%\n",
        "Epoch [1/10], Training Loss: 0.901, Validation Accuracy: 62.48%\n",
        "Epoch [2/10], Training Loss: 0.840, Validation Accuracy: 62.62%\n",
        "Epoch [3/10], Training Loss: 0.804, Validation Accuracy: 61.85%\n",
        "Epoch [4/10], Training Loss: 0.769, Validation Accuracy: 62.37%\n",
        "Epoch [5/10], Training Loss: 0.742, Validation Accuracy: 62.50%\n",
        "Epoch [6/10], Training Loss: 0.716, Validation Accuracy: 61.66%\n",
        "Epoch [7/10], Training Loss: 0.698, Validation Accuracy: 62.00%\n",
        "Epoch [8/10], Training Loss: 0.691, Validation Accuracy: 62.00%\n",
        "Epoch [9/10], Training Loss: 0.671, Validation Accuracy: 61.97%\n",
        "Epoch [10/10], Training Loss: 0.653, Validation Accuracy: 61.91%\n",
        "Epoch [1/10], Training Loss: 0.933, Validation Accuracy: 59.38%\n",
        "Epoch [2/10], Training Loss: 0.844, Validation Accuracy: 62.10%\n",
        "Epoch [3/10], Training Loss: 0.795, Validation Accuracy: 62.88%\n",
        "Epoch [4/10], Training Loss: 0.767, Validation Accuracy: 61.25%\n",
        "Epoch [5/10], Training Loss: 0.751, Validation Accuracy: 62.06%\n",
        "Epoch [6/10], Training Loss: 0.720, Validation Accuracy: 62.89%\n",
        "Epoch [7/10], Training Loss: 0.691, Validation Accuracy: 62.56%\n",
        "Epoch [8/10], Training Loss: 0.679, Validation Accuracy: 62.20%\n",
        "Epoch [9/10], Training Loss: 0.664, Validation Accuracy: 61.96%\n",
        "Epoch [10/10], Training Loss: 0.640, Validation Accuracy: 61.56%\n",
        "Epoch [1/10], Training Loss: 0.920, Validation Accuracy: 62.30%\n",
        "Epoch [2/10], Training Loss: 0.841, Validation Accuracy: 61.76%\n",
        "Epoch [3/10], Training Loss: 0.784, Validation Accuracy: 62.60%\n",
        "Epoch [4/10], Training Loss: 0.744, Validation Accuracy: 62.27%\n",
        "Epoch [5/10], Training Loss: 0.725, Validation Accuracy: 62.12%\n",
        "Epoch [6/10], Training Loss: 0.705, Validation Accuracy: 62.26%\n",
        "Epoch [7/10], Training Loss: 0.676, Validation Accuracy: 62.73%\n",
        "Epoch [8/10], Training Loss: 0.657, Validation Accuracy: 62.36%\n",
        "Epoch [9/10], Training Loss: 0.637, Validation Accuracy: 62.41%\n",
        "Epoch [10/10], Training Loss: 0.626, Validation Accuracy: 60.60%\n",
        "Epoch [1/10], Training Loss: 0.914, Validation Accuracy: 62.22%\n",
        "Epoch [2/10], Training Loss: 0.819, Validation Accuracy: 61.65%\n",
        "Epoch [3/10], Training Loss: 0.782, Validation Accuracy: 62.38%\n",
        "Epoch [4/10], Training Loss: 0.744, Validation Accuracy: 62.31%\n",
        "Epoch [5/10], Training Loss: 0.723, Validation Accuracy: 60.94%\n",
        "Epoch [6/10], Training Loss: 0.696, Validation Accuracy: 62.36%\n",
        "Epoch [7/10], Training Loss: 0.672, Validation Accuracy: 61.94%\n",
        "Epoch [8/10], Training Loss: 0.651, Validation Accuracy: 61.31%\n",
        "Epoch [9/10], Training Loss: 0.636, Validation Accuracy: 62.41%\n",
        "Epoch [10/10], Training Loss: 0.613, Validation Accuracy: 62.07%\n",
        "Epoch [1/10], Training Loss: 0.879, Validation Accuracy: 62.84%\n",
        "Epoch [2/10], Training Loss: 0.779, Validation Accuracy: 62.94%\n",
        "Epoch [3/10], Training Loss: 0.739, Validation Accuracy: 62.57%\n",
        "Epoch [4/10], Training Loss: 0.707, Validation Accuracy: 62.28%\n",
        "Epoch [5/10], Training Loss: 0.673, Validation Accuracy: 62.85%\n",
        "Epoch [6/10], Training Loss: 0.647, Validation Accuracy: 62.39%\n",
        "Epoch [7/10], Training Loss: 0.624, Validation Accuracy: 62.36%\n",
        "Epoch [8/10], Training Loss: 0.616, Validation Accuracy: 61.94%\n",
        "Epoch [9/10], Training Loss: 0.587, Validation Accuracy: 61.37%\n",
        "Epoch [10/10], Training Loss: 0.568, Validation Accuracy: 61.22%\n",
        "Epoch [1/10], Training Loss: 0.845, Validation Accuracy: 62.47%\n",
        "Epoch [2/10], Training Loss: 0.778, Validation Accuracy: 62.24%\n",
        "Epoch [3/10], Training Loss: 0.722, Validation Accuracy: 62.19%\n",
        "Epoch [4/10], Training Loss: 0.689, Validation Accuracy: 62.25%\n",
        "Epoch [5/10], Training Loss: 0.660, Validation Accuracy: 61.55%\n",
        "Epoch [6/10], Training Loss: 0.640, Validation Accuracy: 62.41%\n",
        "Epoch [7/10], Training Loss: 0.607, Validation Accuracy: 62.02%\n",
        "Epoch [8/10], Training Loss: 0.583, Validation Accuracy: 61.86%\n",
        "Epoch [9/10], Training Loss: 0.568, Validation Accuracy: 61.82%\n",
        "Epoch [10/10], Training Loss: 0.543, Validation Accuracy: 62.03%\n",
        "Epoch [1/10], Training Loss: 0.866, Validation Accuracy: 61.28%\n",
        "Epoch [2/10], Training Loss: 0.772, Validation Accuracy: 62.00%\n",
        "Epoch [3/10], Training Loss: 0.725, Validation Accuracy: 62.71%\n",
        "Epoch [4/10], Training Loss: 0.674, Validation Accuracy: 62.20%\n",
        "Epoch [5/10], Training Loss: 0.655, Validation Accuracy: 62.34%\n",
        "Epoch [6/10], Training Loss: 0.624, Validation Accuracy: 61.64%\n",
        "Epoch [7/10], Training Loss: 0.606, Validation Accuracy: 62.33%\n",
        "Epoch [8/10], Training Loss: 0.578, Validation Accuracy: 61.62%\n",
        "Epoch [9/10], Training Loss: 0.555, Validation Accuracy: 61.96%\n",
        "Epoch [10/10], Training Loss: 0.535, Validation Accuracy: 61.76%\n",
        "Epoch [1/10], Training Loss: 0.867, Validation Accuracy: 61.26%\n",
        "Epoch [2/10], Training Loss: 0.764, Validation Accuracy: 61.98%\n",
        "Epoch [3/10], Training Loss: 0.715, Validation Accuracy: 61.67%\n",
        "Epoch [4/10], Training Loss: 0.669, Validation Accuracy: 62.42%\n",
        "Epoch [5/10], Training Loss: 0.646, Validation Accuracy: 62.57%\n",
        "Epoch [6/10], Training Loss: 0.609, Validation Accuracy: 62.40%\n",
        "Epoch [7/10], Training Loss: 0.592, Validation Accuracy: 62.25%\n",
        "Epoch [8/10], Training Loss: 0.571, Validation Accuracy: 61.84%\n",
        "Epoch [9/10], Training Loss: 0.544, Validation Accuracy: 61.90%\n",
        "Epoch [10/10], Training Loss: 0.532, Validation Accuracy: 62.21%\n",
        "Epoch [1/10], Training Loss: 0.889, Validation Accuracy: 61.69%\n",
        "Epoch [2/10], Training Loss: 0.766, Validation Accuracy: 61.84%\n",
        "Epoch [3/10], Training Loss: 0.714, Validation Accuracy: 62.00%\n",
        "Epoch [4/10], Training Loss: 0.681, Validation Accuracy: 62.58%\n",
        "Epoch [5/10], Training Loss: 0.637, Validation Accuracy: 61.48%\n",
        "Epoch [6/10], Training Loss: 0.607, Validation Accuracy: 62.14%\n",
        "Epoch [7/10], Training Loss: 0.578, Validation Accuracy: 62.17%\n",
        "Epoch [8/10], Training Loss: 0.555, Validation Accuracy: 62.04%\n",
        "Epoch [9/10], Training Loss: 0.549, Validation Accuracy: 61.94%\n",
        "Epoch [10/10], Training Loss: 0.519, Validation Accuracy: 61.31%\n",
        "Epoch [1/10], Training Loss: 0.824, Validation Accuracy: 61.41%\n",
        "Epoch [2/10], Training Loss: 0.720, Validation Accuracy: 62.61%\n",
        "Epoch [3/10], Training Loss: 0.661, Validation Accuracy: 62.41%\n",
        "Epoch [4/10], Training Loss: 0.622, Validation Accuracy: 62.09%\n",
        "Epoch [5/10], Training Loss: 0.594, Validation Accuracy: 62.43%\n",
        "Epoch [6/10], Training Loss: 0.566, Validation Accuracy: 62.50%\n",
        "Epoch [7/10], Training Loss: 0.539, Validation Accuracy: 62.33%\n",
        "Epoch [8/10], Training Loss: 0.515, Validation Accuracy: 62.54%\n",
        "Epoch [9/10], Training Loss: 0.498, Validation Accuracy: 62.14%\n",
        "Epoch [10/10], Training Loss: 0.474, Validation Accuracy: 62.02%\n",
        "Epoch [1/10], Training Loss: 0.813, Validation Accuracy: 62.09%\n",
        "Epoch [2/10], Training Loss: 0.704, Validation Accuracy: 62.24%\n",
        "Epoch [3/10], Training Loss: 0.650, Validation Accuracy: 61.97%\n",
        "Epoch [4/10], Training Loss: 0.615, Validation Accuracy: 61.10%\n",
        "Epoch [5/10], Training Loss: 0.582, Validation Accuracy: 61.58%\n",
        "Epoch [6/10], Training Loss: 0.544, Validation Accuracy: 62.18%\n",
        "Epoch [7/10], Training Loss: 0.527, Validation Accuracy: 61.91%\n",
        "Epoch [8/10], Training Loss: 0.495, Validation Accuracy: 62.12%\n",
        "Epoch [9/10], Training Loss: 0.479, Validation Accuracy: 62.02%\n",
        "Epoch [10/10], Training Loss: 0.456, Validation Accuracy: 61.96%\n",
        "Epoch [1/10], Training Loss: 0.833, Validation Accuracy: 60.07%\n",
        "Epoch [2/10], Training Loss: 0.709, Validation Accuracy: 62.37%\n",
        "Epoch [3/10], Training Loss: 0.641, Validation Accuracy: 62.13%\n",
        "Epoch [4/10], Training Loss: 0.593, Validation Accuracy: 62.20%\n",
        "Epoch [5/10], Training Loss: 0.564, Validation Accuracy: 62.38%\n",
        "Epoch [6/10], Training Loss: 0.542, Validation Accuracy: 62.29%\n",
        "Epoch [7/10], Training Loss: 0.509, Validation Accuracy: 62.03%\n",
        "Epoch [8/10], Training Loss: 0.480, Validation Accuracy: 62.12%\n",
        "Epoch [9/10], Training Loss: 0.463, Validation Accuracy: 61.53%\n",
        "Epoch [10/10], Training Loss: 0.442, Validation Accuracy: 61.38%\n",
        "Epoch [1/10], Training Loss: 0.836, Validation Accuracy: 61.01%\n",
        "Epoch [2/10], Training Loss: 0.711, Validation Accuracy: 61.97%\n",
        "Epoch [3/10], Training Loss: 0.638, Validation Accuracy: 61.92%\n",
        "Epoch [4/10], Training Loss: 0.592, Validation Accuracy: 61.95%\n",
        "Epoch [5/10], Training Loss: 0.567, Validation Accuracy: 61.84%\n",
        "Epoch [6/10], Training Loss: 0.525, Validation Accuracy: 61.86%\n",
        "Epoch [7/10], Training Loss: 0.495, Validation Accuracy: 62.05%\n",
        "Epoch [8/10], Training Loss: 0.483, Validation Accuracy: 61.44%\n",
        "Epoch [9/10], Training Loss: 0.458, Validation Accuracy: 61.32%\n",
        "Epoch [10/10], Training Loss: 0.433, Validation Accuracy: 61.93%\n",
        "Epoch [1/10], Training Loss: 0.831, Validation Accuracy: 61.10%\n",
        "Epoch [2/10], Training Loss: 0.693, Validation Accuracy: 61.29%\n",
        "Epoch [3/10], Training Loss: 0.638, Validation Accuracy: 61.46%\n",
        "Epoch [4/10], Training Loss: 0.594, Validation Accuracy: 62.03%\n",
        "Epoch [5/10], Training Loss: 0.555, Validation Accuracy: 61.52%\n",
        "Epoch [6/10], Training Loss: 0.523, Validation Accuracy: 61.88%\n",
        "Epoch [7/10], Training Loss: 0.494, Validation Accuracy: 61.80%\n",
        "Epoch [8/10], Training Loss: 0.472, Validation Accuracy: 60.82%\n",
        "Epoch [9/10], Training Loss: 0.462, Validation Accuracy: 61.37%\n",
        "Epoch [10/10], Training Loss: 0.432, Validation Accuracy: 60.73%\n",
        "Epoch [1/10], Training Loss: 0.810, Validation Accuracy: 61.07%\n",
        "Epoch [2/10], Training Loss: 0.676, Validation Accuracy: 61.70%\n",
        "Epoch [3/10], Training Loss: 0.604, Validation Accuracy: 61.66%\n",
        "Epoch [4/10], Training Loss: 0.551, Validation Accuracy: 62.01%\n",
        "Epoch [5/10], Training Loss: 0.510, Validation Accuracy: 62.14%\n",
        "Epoch [6/10], Training Loss: 0.484, Validation Accuracy: 62.45%\n",
        "Epoch [7/10], Training Loss: 0.456, Validation Accuracy: 62.15%\n",
        "Epoch [8/10], Training Loss: 0.428, Validation Accuracy: 62.43%\n",
        "Epoch [9/10], Training Loss: 0.404, Validation Accuracy: 61.46%\n",
        "Epoch [10/10], Training Loss: 0.385, Validation Accuracy: 62.23%\n",
        "\"\"\"\n",
        "\n",
        "# Regular expression to find validation accuracies\n",
        "accuracies = re.findall(r'Validation Accuracy: (\\d+\\.\\d+)%', log)\n",
        "\n",
        "# Convert accuracies from string to float\n",
        "accuracies = [float(acc) for acc in accuracies]\n",
        "\n",
        "# Print accuracies\n",
        "print(\"Accuracies:\", accuracies)\n",
        "\n",
        "# Print size of the array\n",
        "print(\"Size of array:\", len(accuracies))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Rahad31/Kl-FedDis-Research-.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jya9BqNNZ7qB",
        "outputId": "b9dba334-dc2f-40a1-a878-a7fadec82acd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Kl-FedDis-Research-'...\n",
            "warning: You appear to have cloned an empty repository.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git init\n",
        "!git add README.md\n",
        "!git commit -m \"first commit\"\n",
        "!git branch -M main\n",
        "!git remote add origin https://github.com/Rahad31/Kl-FedDis-Research-.git\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSFW2dqbPLO",
        "outputId": "cd92fdbe-7498-4a88-89da-7f5fe4e6b6d9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reinitialized existing Git repository in /content/Kl-FedDis-Research-/.git/\n",
            "fatal: pathspec 'README.md' did not match any files\n",
            "On branch main\n",
            "\n",
            "Initial commit\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mKl-FedDis-Research-/\u001b[m\n",
            "\n",
            "nothing added to commit but untracked files present (use \"git add\" to track)\n",
            "error: remote origin already exists.\n",
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/Rahad31/Kl-FedDis-Research-.git'\n",
            "\u001b[m"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}